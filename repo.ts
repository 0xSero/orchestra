// OpenCode Orchestra Repository Bundle
// Generated: 2025-12-28T19:08:11.463Z
// Total files: 132
// This file contains the entire codebase in a single document
// Use this for reference or analysis purposes

import * as fs from 'fs'
import * as path from 'path'

export const RepositoryBundle = {
  version: '1.0.0',
  generatedAt: new Date().toISOString(),
  files: [
  {
    "path": "api/db-router.ts",
    "content": "import type { IncomingMessage, ServerResponse } from \"node:http\";\nimport type { DatabaseService, User, WorkerConfig, WorkerState } from \"../db\";\n\ntype JsonValue = string | number | boolean | null | JsonValue[] | { [key: string]: JsonValue };\n\ntype DbRouterDeps = {\n  db: DatabaseService;\n  onWorkerConfigChanged?: (workerId?: string) => void;\n  onPreferencesChanged?: (key?: string) => void;\n};\n\nconst asRecord = (value: unknown): value is Record<string, unknown> => typeof value === \"object\" && value !== null;\n\nfunction setCors(res: ServerResponse) {\n  res.setHeader(\"Access-Control-Allow-Origin\", \"*\");\n  res.setHeader(\"Access-Control-Allow-Methods\", \"GET,POST,PUT,DELETE,OPTIONS\");\n  res.setHeader(\"Access-Control-Allow-Headers\", \"Content-Type\");\n}\n\nasync function readJson(req: IncomingMessage): Promise<unknown> {\n  const chunks: Buffer[] = [];\n  for await (const chunk of req) {\n    chunks.push(Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk));\n  }\n  if (chunks.length === 0) return {};\n  const raw = Buffer.concat(chunks).toString(\"utf8\");\n  if (!raw.trim()) return {};\n  return JSON.parse(raw);\n}\n\nfunction sendJson(res: ServerResponse, status: number, body: JsonValue) {\n  setCors(res);\n  res.statusCode = status;\n  res.setHeader(\"Content-Type\", \"application/json\");\n  res.end(JSON.stringify(body));\n}\n\nfunction serializeUser(user: User | null): JsonValue {\n  if (!user) return null;\n  return {\n    id: user.id,\n    onboarded: user.onboarded,\n    onboardedAt: user.onboardedAt ? user.onboardedAt.toISOString() : null,\n    createdAt: user.createdAt.toISOString(),\n    updatedAt: user.updatedAt.toISOString(),\n  };\n}\n\nfunction serializeWorkerConfig(config: WorkerConfig): JsonValue {\n  return {\n    id: config.id,\n    userId: config.userId,\n    workerId: config.workerId,\n    model: config.model,\n    temperature: config.temperature,\n    maxTokens: config.maxTokens,\n    enabled: config.enabled,\n    updatedAt: config.updatedAt.toISOString(),\n  };\n}\n\nfunction serializeWorkerState(state: WorkerState): JsonValue {\n  return {\n    id: state.id,\n    userId: state.userId,\n    workerId: state.workerId,\n    profileName: state.profileName,\n    model: state.model,\n    serverUrl: state.serverUrl,\n    sessionId: state.sessionId,\n    uiSessionId: state.uiSessionId,\n    status: state.status,\n    sessionMode: state.sessionMode,\n    parentSessionId: state.parentSessionId,\n    startedAt: state.startedAt ? state.startedAt.toISOString() : null,\n    lastActivity: state.lastActivity ? state.lastActivity.toISOString() : null,\n    currentTask: state.currentTask,\n    lastResult: state.lastResult,\n    lastResultAt: state.lastResultAt ? state.lastResultAt.toISOString() : null,\n    lastResultJobId: state.lastResultJobId,\n    lastResultDurationMs: state.lastResultDurationMs,\n    error: state.error,\n    warning: state.warning,\n    updatedAt: state.updatedAt.toISOString(),\n  };\n}\n\nexport function createDbRouter(deps: DbRouterDeps) {\n  const subscribers = new Set<ServerResponse>();\n\n  const buildSnapshot = (): JsonValue => ({\n    dbPath: deps.db.getDbPath(),\n    user: serializeUser(deps.db.getUser()),\n    preferences: deps.db.getAllPreferences(),\n    workerConfigs: deps.db.getAllWorkerConfigs().map(serializeWorkerConfig),\n    workerStates: deps.db.getAllWorkerStates().map(serializeWorkerState),\n  });\n\n  const broadcastSnapshot = () => {\n    const payload = `event: db.snapshot\\ndata: ${JSON.stringify(buildSnapshot())}\\n\\n`;\n    for (const res of subscribers) {\n      res.write(payload);\n    }\n  };\n\n  return async function handle(req: IncomingMessage, res: ServerResponse) {\n    if (!req.url) {\n      sendJson(res, 400, { error: \"Missing URL\" });\n      return;\n    }\n\n    if (req.method === \"OPTIONS\") {\n      setCors(res);\n      res.statusCode = 204;\n      res.end();\n      return;\n    }\n\n    const url = new URL(req.url, \"http://localhost\");\n    const path = url.pathname;\n    const segments = path.split(\"/\").filter(Boolean);\n\n    if (segments[0] !== \"api\" || segments[1] !== \"db\") {\n      sendJson(res, 404, { error: \"Not found\" });\n      return;\n    }\n\n    if (segments.length === 2 && req.method === \"GET\") {\n      sendJson(res, 200, buildSnapshot());\n      return;\n    }\n\n    if (segments.length === 3 && segments[2] === \"events\" && req.method === \"GET\") {\n      setCors(res);\n      res.writeHead(200, {\n        \"Content-Type\": \"text/event-stream\",\n        \"Cache-Control\": \"no-cache\",\n        Connection: \"keep-alive\",\n      });\n      res.flushHeaders?.();\n      res.write(`event: db.snapshot\\ndata: ${JSON.stringify(buildSnapshot())}\\n\\n`);\n      subscribers.add(res);\n      req.on(\"close\", () => {\n        subscribers.delete(res);\n      });\n      return;\n    }\n\n    if (segments.length >= 3 && segments[2] === \"preferences\") {\n      let handled = false;\n      if (segments.length === 3 && req.method === \"GET\") {\n        sendJson(res, 200, deps.db.getAllPreferences());\n        return;\n      }\n\n      if (segments.length === 3 && req.method === \"PUT\") {\n        try {\n          const body = await readJson(req);\n          if (asRecord(body) && body.updates && typeof body.updates === \"object\") {\n            for (const [key, value] of Object.entries(body.updates as Record<string, string | null>)) {\n              deps.db.setPreference(key, value ?? null);\n              deps.onPreferencesChanged?.(key);\n            }\n          } else if (asRecord(body) && typeof body.key === \"string\") {\n            const rawValue = body.value;\n            if (rawValue !== undefined && rawValue !== null && typeof rawValue !== \"string\") {\n              sendJson(res, 400, { error: \"Preference value must be a string or null\" });\n              return;\n            }\n            const value = typeof rawValue === \"string\" ? rawValue : null;\n            deps.db.setPreference(body.key, value);\n            deps.onPreferencesChanged?.(body.key);\n          } else {\n            sendJson(res, 400, { error: \"Invalid preference update payload\" });\n            return;\n          }\n          broadcastSnapshot();\n          sendJson(res, 200, buildSnapshot());\n        } catch (err) {\n          sendJson(res, 400, { error: err instanceof Error ? err.message : \"Failed to update preferences\" });\n        }\n        return;\n      }\n\n      if (segments.length === 4 && req.method === \"DELETE\") {\n        const key = segments[3];\n        deps.db.deletePreference(key);\n        deps.onPreferencesChanged?.(key);\n        broadcastSnapshot();\n        sendJson(res, 200, { success: true });\n        handled = true;\n      }\n      if (handled) return;\n    }\n\n    if (segments.length >= 3 && segments[2] === \"worker-config\") {\n      let handled = false;\n      if (segments.length === 3 && req.method === \"GET\") {\n        sendJson(res, 200, deps.db.getAllWorkerConfigs().map(serializeWorkerConfig));\n        return;\n      }\n\n      const workerId = segments[3];\n      if (!workerId) {\n        sendJson(res, 404, { error: \"Worker ID not provided\" });\n        return;\n      }\n\n      if (segments.length === 4 && req.method === \"GET\") {\n        const config = deps.db.getWorkerConfig(workerId);\n        if (!config) {\n          sendJson(res, 404, { error: \"Not found\" });\n          return;\n        }\n        sendJson(res, 200, serializeWorkerConfig(config));\n        return;\n      }\n\n      if (segments.length === 4 && req.method === \"PUT\") {\n        try {\n          const body = await readJson(req);\n          if (!asRecord(body)) {\n            sendJson(res, 400, { error: \"Invalid worker config payload\" });\n            return;\n          }\n          const updates: {\n            model?: string | null;\n            temperature?: number | null;\n            maxTokens?: number | null;\n            enabled?: boolean;\n          } = {};\n\n          if (\"model\" in body) {\n            updates.model = typeof body.model === \"string\" && body.model.trim() ? body.model.trim() : null;\n          }\n          if (\"temperature\" in body) {\n            updates.temperature = body.temperature === null ? null : Number(body.temperature);\n            if (Number.isNaN(updates.temperature as number)) delete updates.temperature;\n          }\n          if (\"maxTokens\" in body) {\n            updates.maxTokens = body.maxTokens === null ? null : Number(body.maxTokens);\n            if (Number.isNaN(updates.maxTokens as number)) delete updates.maxTokens;\n          }\n          if (typeof body.enabled === \"boolean\") {\n            updates.enabled = body.enabled;\n          }\n\n          deps.db.setWorkerConfig(workerId, updates);\n          deps.onWorkerConfigChanged?.(workerId);\n          broadcastSnapshot();\n          const config = deps.db.getWorkerConfig(workerId);\n          sendJson(res, 200, config ? serializeWorkerConfig(config) : { workerId });\n        } catch (err) {\n          sendJson(res, 400, { error: err instanceof Error ? err.message : \"Failed to update worker config\" });\n        }\n        return;\n      }\n\n      if (segments.length === 4 && req.method === \"DELETE\") {\n        deps.db.clearWorkerConfig(workerId);\n        deps.onWorkerConfigChanged?.(workerId);\n        broadcastSnapshot();\n        sendJson(res, 200, { success: true });\n        handled = true;\n      }\n      if (handled) return;\n    }\n\n    const handleOnboarded = () => {\n      const user = deps.db.markOnboarded();\n      broadcastSnapshot();\n      sendJson(res, 200, serializeUser(user));\n    };\n\n    if (segments.length === 3 && segments[2] === \"onboarded\" && req.method === \"POST\") return handleOnboarded();\n\n    sendJson(res, 404, { error: \"Not found\" });\n  };\n}\n"
  },
  {
    "path": "api/index.ts",
    "content": "import { createOpencode, createOpencodeClient } from \"@opencode-ai/sdk\";\nimport type { Factory, ServiceLifecycle } from \"../types\";\n\nexport * from \"./skills-server\";\n\nexport type ApiConfig = {\n  baseUrl?: string;\n  directory?: string;\n};\n\nexport type ApiDeps = {\n  client?: ReturnType<typeof createOpencodeClient>;\n};\n\n/**\n * Simplified API service interface for OpenCode SDK operations.\n *\n * Note: This interface uses `unknown` for args/return types instead of the SDK's\n * complex generic types. This is intentional - the SDK types have deeply nested\n * generics with conditional types that would require complex type gymnastics to\n * properly expose. Using `unknown` provides a clean interface while the actual\n * implementation delegates to the properly-typed SDK client.\n *\n * Callers should refer to SDK documentation for the actual request/response shapes.\n */\nexport type ApiService = ServiceLifecycle & {\n  client: ReturnType<typeof createOpencodeClient>;\n  createClient: (input: { baseUrl: string; directory?: string }) => ReturnType<typeof createOpencodeClient>;\n  createServer: typeof createOpencode;\n  session: {\n    create: (args: unknown) => Promise<unknown>;\n    list: (args: unknown) => Promise<unknown>;\n    get: (args: unknown) => Promise<unknown>;\n    prompt: (args: unknown) => Promise<unknown>;\n    promptAsync: (args: unknown) => Promise<unknown>;\n    messages: (args: unknown) => Promise<unknown>;\n    messageDelete: (args: unknown) => Promise<unknown>;\n    abort: (args: unknown) => Promise<unknown>;\n  };\n  event: {\n    subscribe: (args: unknown) => unknown;\n  };\n  file: {\n    read: (args: unknown) => Promise<unknown>;\n  };\n  find: {\n    text: (args: unknown) => Promise<unknown>;\n    files: (args: unknown) => Promise<unknown>;\n  };\n  project: {\n    list: (args: unknown) => Promise<unknown>;\n    current: (args: unknown) => Promise<unknown>;\n  };\n  path: {\n    get: (args: unknown) => Promise<unknown>;\n  };\n  config: {\n    get: (args: unknown) => Promise<unknown>;\n    providers: (args: unknown) => Promise<unknown>;\n  };\n  app: {\n    agents: (args: unknown) => Promise<unknown>;\n    log: (args: unknown) => Promise<unknown>;\n  };\n  tui: {\n    appendPrompt: (args: unknown) => Promise<unknown>;\n    showToast: (args: unknown) => Promise<unknown>;\n    submitPrompt: (args: unknown) => Promise<unknown>;\n    publish: (args: unknown) => Promise<unknown>;\n  };\n  auth: {\n    set: (args: unknown) => Promise<unknown>;\n  };\n};\n\n/**\n * SDK request arguments shape - simplified for type checking.\n */\ntype SdkArgs = { query?: Record<string, unknown> } & Record<string, unknown>;\n\n/**\n * Helper to inject directory into SDK request arguments.\n *\n * The SDK uses complex generics; we normalize to a simple shape here and cast\n * back to the SDK's expected types at call sites.\n */\nfunction withDirectory(directory: string | undefined, args: unknown): SdkArgs {\n  if (!directory) {\n    if (!args || typeof args !== \"object\") return {};\n    return args as SdkArgs;\n  }\n  if (!args || typeof args !== \"object\") return { query: { directory } };\n  const typedArgs = args as SdkArgs;\n  return { ...typedArgs, query: { ...(typedArgs.query ?? {}), directory } };\n}\n\nexport const createApi: Factory<ApiConfig, ApiDeps, ApiService> = ({ config, deps }) => {\n  const client = deps.client ?? createOpencodeClient({ baseUrl: config.baseUrl });\n  const directory = config.directory;\n  const withDirectoryArgs = <T>(args: unknown): T => withDirectory(directory, args) as T;\n\n  return {\n    client,\n    createClient: ({ baseUrl, directory: dir }) => createOpencodeClient({ baseUrl, directory: dir }),\n    createServer: createOpencode,\n    session: {\n      create: (args) => client.session.create(withDirectoryArgs<Parameters<typeof client.session.create>[0]>(args)),\n      list: (args) => client.session.list(withDirectoryArgs<Parameters<typeof client.session.list>[0]>(args)),\n      get: (args) => client.session.get(withDirectoryArgs<Parameters<typeof client.session.get>[0]>(args)),\n      prompt: (args) => client.session.prompt(withDirectoryArgs<Parameters<typeof client.session.prompt>[0]>(args)),\n      promptAsync: (args) =>\n        client.session.promptAsync(withDirectoryArgs<Parameters<typeof client.session.promptAsync>[0]>(args)),\n      messages: (args) =>\n        client.session.messages(withDirectoryArgs<Parameters<typeof client.session.messages>[0]>(args)),\n      messageDelete: (args) =>\n        client.session.delete(withDirectoryArgs<Parameters<typeof client.session.delete>[0]>(args)),\n      abort: (args) => client.session.abort(withDirectoryArgs<Parameters<typeof client.session.abort>[0]>(args)),\n    },\n    event: {\n      subscribe: (args) =>\n        client.event.subscribe(withDirectoryArgs<Parameters<typeof client.event.subscribe>[0]>(args)),\n    },\n    file: {\n      read: (args) => client.file.read(withDirectoryArgs<Parameters<typeof client.file.read>[0]>(args)),\n    },\n    find: {\n      text: (args) => client.find.text(withDirectoryArgs<Parameters<typeof client.find.text>[0]>(args)),\n      files: (args) => client.find.files(withDirectoryArgs<Parameters<typeof client.find.files>[0]>(args)),\n    },\n    project: {\n      list: (args) => client.project.list(withDirectoryArgs<Parameters<typeof client.project.list>[0]>(args)),\n      current: (args) => client.project.current(withDirectoryArgs<Parameters<typeof client.project.current>[0]>(args)),\n    },\n    path: {\n      get: (args) => client.path.get(withDirectoryArgs<Parameters<typeof client.path.get>[0]>(args)),\n    },\n    config: {\n      get: (args) => client.config.get(withDirectoryArgs<Parameters<typeof client.config.get>[0]>(args)),\n      providers: (args) =>\n        client.config.providers(withDirectoryArgs<Parameters<typeof client.config.providers>[0]>(args)),\n    },\n    app: {\n      agents: (args) => client.app.agents(withDirectoryArgs<Parameters<typeof client.app.agents>[0]>(args)),\n      log: (args) => client.app.log(withDirectoryArgs<Parameters<typeof client.app.log>[0]>(args)),\n    },\n    tui: {\n      appendPrompt: (args) =>\n        client.tui.appendPrompt(withDirectoryArgs<Parameters<typeof client.tui.appendPrompt>[0]>(args)),\n      showToast: (args) => client.tui.showToast(withDirectoryArgs<Parameters<typeof client.tui.showToast>[0]>(args)),\n      submitPrompt: (args) =>\n        client.tui.submitPrompt(withDirectoryArgs<Parameters<typeof client.tui.submitPrompt>[0]>(args)),\n      publish: (args) => client.tui.publish(withDirectoryArgs<Parameters<typeof client.tui.publish>[0]>(args)),\n    },\n    auth: {\n      set: (args) => client.auth.set(withDirectoryArgs<Parameters<typeof client.auth.set>[0]>(args)),\n    },\n    start: async () => {},\n    stop: async () => {},\n    health: async () => ({ ok: true }),\n  };\n};\n"
  },
  {
    "path": "api/sessions-router.ts",
    "content": "import type { IncomingMessage, ServerResponse } from \"node:http\";\nimport type { SessionManagerEvent, TrackedSession, WorkerManager, WorkerSessionManager } from \"../workers\";\n\ntype JsonValue = string | number | boolean | null | JsonValue[] | { [key: string]: JsonValue };\n\nexport type SessionsRouterDeps = {\n  sessionManager: WorkerSessionManager;\n  workers: WorkerManager;\n};\n\nfunction setCors(res: ServerResponse) {\n  res.setHeader(\"Access-Control-Allow-Origin\", \"*\");\n  res.setHeader(\"Access-Control-Allow-Methods\", \"GET,POST,DELETE,OPTIONS\");\n  res.setHeader(\"Access-Control-Allow-Headers\", \"Content-Type\");\n}\n\nfunction sendJson(res: ServerResponse, status: number, body: JsonValue) {\n  setCors(res);\n  res.statusCode = status;\n  res.setHeader(\"Content-Type\", \"application/json\");\n  res.end(JSON.stringify(body));\n}\n\nfunction serializeSession(session: TrackedSession): JsonValue {\n  return {\n    workerId: session.workerId,\n    sessionId: session.sessionId,\n    mode: session.mode,\n    parentSessionId: session.parentSessionId ?? null,\n    serverUrl: session.serverUrl ?? null,\n    createdAt: session.createdAt.toISOString(),\n    lastActivity: session.lastActivity.toISOString(),\n    status: session.status,\n    messageCount: session.messageCount,\n    toolCount: session.toolCount,\n    recentActivity: session.recentActivity.map((activity) => ({\n      id: activity.id,\n      type: activity.type,\n      timestamp: activity.timestamp.toISOString(),\n      summary: activity.summary,\n    })),\n    error: session.error ?? null,\n  };\n}\n\n/**\n * Create a router for the sessions API.\n * Provides endpoints for viewing worker sessions and their activity.\n */\nexport function createSessionsRouter(deps: SessionsRouterDeps) {\n  const eventSubscribers = new Set<ServerResponse>();\n\n  // Subscribe to session manager events and broadcast to SSE clients\n  deps.sessionManager.on((event: SessionManagerEvent) => {\n    const payload = `event: ${event.type}\\ndata: ${JSON.stringify({\n      type: event.type,\n      session: serializeSession(event.session),\n      activity: event.activity\n        ? {\n            id: event.activity.id,\n            type: event.activity.type,\n            timestamp: event.activity.timestamp.toISOString(),\n            summary: event.activity.summary,\n          }\n        : null,\n    })}\\n\\n`;\n    for (const res of eventSubscribers) {\n      res.write(payload);\n    }\n  });\n\n  return async function handle(req: IncomingMessage, res: ServerResponse) {\n    if (!req.url) {\n      sendJson(res, 400, { error: \"Missing URL\" });\n      return;\n    }\n\n    if (req.method === \"OPTIONS\") {\n      setCors(res);\n      res.statusCode = 204;\n      res.end();\n      return;\n    }\n\n    const url = new URL(req.url, \"http://localhost\");\n    const path = url.pathname;\n    const segments = path.split(\"/\").filter(Boolean);\n\n    // Require /api/sessions prefix\n    if (segments[0] !== \"api\" || segments[1] !== \"sessions\") {\n      sendJson(res, 404, { error: \"Not found\" });\n      return;\n    }\n\n    // GET /api/sessions - List all sessions with summary\n    if (segments.length === 2 && req.method === \"GET\") {\n      try {\n        const summary = deps.sessionManager.getSummary();\n        sendJson(res, 200, {\n          total: summary.total,\n          byMode: summary.byMode,\n          byStatus: summary.byStatus,\n          sessions: summary.sessions as unknown as JsonValue,\n        });\n      } catch (err) {\n        sendJson(res, 500, { error: err instanceof Error ? err.message : \"Failed to get sessions\" });\n      }\n      return;\n    }\n\n    // GET /api/sessions/events - SSE stream of session events\n    if (segments.length === 3 && segments[2] === \"events\" && req.method === \"GET\") {\n      setCors(res);\n      res.writeHead(200, {\n        \"Content-Type\": \"text/event-stream\",\n        \"Cache-Control\": \"no-cache\",\n        Connection: \"keep-alive\",\n      });\n      res.flushHeaders?.();\n\n      // Send initial state\n      const summary = deps.sessionManager.getSummary();\n      res.write(\n        `event: init\\ndata: ${JSON.stringify({\n          total: summary.total,\n          sessions: summary.sessions,\n        })}\\n\\n`,\n      );\n\n      eventSubscribers.add(res);\n      req.on(\"close\", () => {\n        eventSubscribers.delete(res);\n      });\n      return;\n    }\n\n    // GET /api/sessions/active - List only active sessions\n    if (segments.length === 3 && segments[2] === \"active\" && req.method === \"GET\") {\n      try {\n        const sessions = deps.sessionManager.getActiveSessions();\n        sendJson(res, 200, sessions.map(serializeSession) as unknown as JsonValue);\n      } catch (err) {\n        sendJson(res, 500, { error: err instanceof Error ? err.message : \"Failed to get active sessions\" });\n      }\n      return;\n    }\n\n    // GET /api/sessions/by-mode/:mode - List sessions by mode\n    if (segments.length === 4 && segments[2] === \"by-mode\" && req.method === \"GET\") {\n      const mode = segments[3];\n      if (mode !== \"child\" && mode !== \"isolated\" && mode !== \"linked\") {\n        sendJson(res, 400, { error: \"Invalid mode. Must be: child, isolated, or linked\" });\n        return;\n      }\n      try {\n        const sessions = deps.sessionManager.getSessionsByMode(mode);\n        sendJson(res, 200, sessions.map(serializeSession) as unknown as JsonValue);\n      } catch (err) {\n        sendJson(res, 500, { error: err instanceof Error ? err.message : \"Failed to get sessions by mode\" });\n      }\n      return;\n    }\n\n    // GET /api/sessions/worker/:workerId - Get session for a specific worker\n    if (segments.length === 4 && segments[2] === \"worker\" && req.method === \"GET\") {\n      const workerId = segments[3];\n      try {\n        const session = deps.sessionManager.getSessionByWorker(workerId);\n        if (!session) {\n          sendJson(res, 404, { error: `No session found for worker: ${workerId}` });\n          return;\n        }\n        sendJson(res, 200, serializeSession(session) as unknown as JsonValue);\n      } catch (err) {\n        sendJson(res, 500, { error: err instanceof Error ? err.message : \"Failed to get worker session\" });\n      }\n      return;\n    }\n\n    // GET /api/sessions/:sessionId - Get specific session\n    if (segments.length === 3 && req.method === \"GET\") {\n      const sessionId = segments[2];\n      try {\n        const session = deps.sessionManager.getSession(sessionId);\n        if (!session) {\n          sendJson(res, 404, { error: `Session not found: ${sessionId}` });\n          return;\n        }\n        sendJson(res, 200, serializeSession(session) as unknown as JsonValue);\n      } catch (err) {\n        sendJson(res, 500, { error: err instanceof Error ? err.message : \"Failed to get session\" });\n      }\n      return;\n    }\n\n    // GET /api/sessions/:sessionId/activity - Get session activity log\n    if (segments.length === 4 && segments[3] === \"activity\" && req.method === \"GET\") {\n      const sessionId = segments[2];\n      try {\n        const session = deps.sessionManager.getSession(sessionId);\n        if (!session) {\n          sendJson(res, 404, { error: `Session not found: ${sessionId}` });\n          return;\n        }\n\n        // Parse query params for pagination\n        const limit = parseInt(url.searchParams.get(\"limit\") ?? \"50\", 10);\n        const offset = parseInt(url.searchParams.get(\"offset\") ?? \"0\", 10);\n\n        const activity = session.recentActivity.slice(offset, offset + limit);\n        sendJson(res, 200, {\n          sessionId,\n          workerId: session.workerId,\n          total: session.recentActivity.length,\n          offset,\n          limit,\n          activity: activity.map((a) => ({\n            id: a.id,\n            type: a.type as string,\n            timestamp: a.timestamp.toISOString(),\n            summary: a.summary,\n            details: (a.details as JsonValue) ?? null,\n          })),\n        } as unknown as JsonValue);\n      } catch (err) {\n        sendJson(res, 500, { error: err instanceof Error ? err.message : \"Failed to get session activity\" });\n      }\n      return;\n    }\n\n    const handleCloseSession = async (sessionId: string) => {\n      try {\n        const session = deps.sessionManager.getSession(sessionId);\n        if (!session) {\n          sendJson(res, 404, { error: `Session not found: ${sessionId}` });\n          return;\n        }\n\n        // Stop the worker to close the session\n        const stopped = await deps.workers.stopWorker(session.workerId);\n        if (!stopped) {\n          sendJson(res, 500, { error: \"Failed to stop worker\" });\n          return;\n        }\n\n        deps.sessionManager.closeSession(sessionId);\n        sendJson(res, 200, { success: true, sessionId, workerId: session.workerId });\n      } catch (err) {\n        sendJson(res, 500, { error: err instanceof Error ? err.message : \"Failed to close session\" });\n      }\n    };\n\n    // DELETE /api/sessions/:sessionId - Close a session\n    if (segments.length === 3 && req.method === \"DELETE\") return await handleCloseSession(segments[2]);\n\n    sendJson(res, 404, { error: \"Not found\" });\n  };\n}\n"
  },
  {
    "path": "api/skills-router.ts",
    "content": "import type { IncomingMessage, ServerResponse } from \"node:http\";\nimport type { SkillsService } from \"../skills/service\";\nimport type { SkillInput, SkillScope } from \"../types\";\nimport type { WorkerManager } from \"../workers\";\n\ntype JsonValue = string | number | boolean | null | JsonValue[] | { [key: string]: JsonValue };\n\ntype SkillsRouterDeps = {\n  skills: SkillsService;\n  workers?: WorkerManager;\n};\n\nconst asRecord = (value: unknown): value is Record<string, unknown> => typeof value === \"object\" && value !== null;\n\nfunction setCors(res: ServerResponse) {\n  res.setHeader(\"Access-Control-Allow-Origin\", \"*\");\n  res.setHeader(\"Access-Control-Allow-Methods\", \"GET,POST,PUT,DELETE,OPTIONS\");\n  res.setHeader(\"Access-Control-Allow-Headers\", \"Content-Type\");\n}\n\nasync function readJson(req: IncomingMessage): Promise<unknown> {\n  const chunks: Buffer[] = [];\n  for await (const chunk of req) {\n    chunks.push(Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk));\n  }\n  if (chunks.length === 0) return {};\n  const raw = Buffer.concat(chunks).toString(\"utf8\");\n  if (!raw.trim()) return {};\n  return JSON.parse(raw);\n}\n\nfunction sendJson(res: ServerResponse, status: number, body: JsonValue) {\n  setCors(res);\n  res.statusCode = status;\n  res.setHeader(\"Content-Type\", \"application/json\");\n  res.end(JSON.stringify(body));\n}\n\nfunction normalizeScope(value: unknown): SkillScope {\n  return value === \"global\" ? \"global\" : \"project\";\n}\n\nexport function createSkillsRouter(deps: SkillsRouterDeps) {\n  const subscribers = new Set<ServerResponse>();\n  deps.skills.events.on((event) => {\n    const payload = `event: ${event.type}\\ndata: ${JSON.stringify(event)}\\n\\n`;\n    for (const res of subscribers) {\n      res.write(payload);\n    }\n  });\n\n  return async function handle(req: IncomingMessage, res: ServerResponse) {\n    if (!req.url) {\n      sendJson(res, 400, { error: \"Missing URL\" });\n      return;\n    }\n\n    if (req.method === \"OPTIONS\") {\n      setCors(res);\n      res.statusCode = 204;\n      res.end();\n      return;\n    }\n\n    const url = new URL(req.url, \"http://localhost\");\n    const path = url.pathname;\n    const segments = path.split(\"/\").filter(Boolean);\n\n    if (segments[0] !== \"api\" || segments[1] !== \"skills\") {\n      sendJson(res, 404, { error: \"Not found\" });\n      return;\n    }\n\n    if (segments.length === 2 && req.method === \"GET\") {\n      try {\n        const skills = await deps.skills.list();\n        sendJson(res, 200, skills as unknown as JsonValue);\n      } catch (err) {\n        sendJson(res, 500, { error: err instanceof Error ? err.message : \"Failed to list skills\" });\n      }\n      return;\n    }\n\n    if (segments.length === 3 && segments[2] === \"events\" && req.method === \"GET\") {\n      setCors(res);\n      res.writeHead(200, {\n        \"Content-Type\": \"text/event-stream\",\n        \"Cache-Control\": \"no-cache\",\n        Connection: \"keep-alive\",\n      });\n      res.flushHeaders?.();\n      res.write(\": connected\\n\\n\");\n      subscribers.add(res);\n      req.on(\"close\", () => {\n        subscribers.delete(res);\n      });\n      return;\n    }\n\n    if (segments.length === 2 && req.method === \"POST\") {\n      try {\n        const body = await readJson(req);\n        const record = asRecord(body) ? body : {};\n        const input = (asRecord(record.input) ? (record.input as unknown) : {}) as SkillInput;\n        const skill = await deps.skills.create(input, normalizeScope(record.scope));\n        sendJson(res, 201, skill as unknown as JsonValue);\n      } catch (err) {\n        sendJson(res, 400, { error: err instanceof Error ? err.message : \"Failed to create skill\" });\n      }\n      return;\n    }\n\n    const skillId = segments[2];\n    if (!skillId) {\n      sendJson(res, 404, { error: \"Skill ID not provided\" });\n      return;\n    }\n\n    if (segments.length === 3 && req.method === \"GET\") {\n      try {\n        const skill = await deps.skills.get(skillId);\n        if (!skill) {\n          sendJson(res, 404, { error: \"Not found\" });\n          return;\n        }\n        sendJson(res, 200, skill as unknown as JsonValue);\n      } catch (err) {\n        sendJson(res, 500, { error: err instanceof Error ? err.message : \"Failed to load skill\" });\n      }\n      return;\n    }\n\n    if (segments.length === 3 && req.method === \"PUT\") {\n      try {\n        const body = await readJson(req);\n        const record = asRecord(body) ? body : {};\n        const updates = (asRecord(record.updates) ? record.updates : {}) as Partial<SkillInput>;\n        const skill = await deps.skills.update(skillId, updates, normalizeScope(record.scope));\n        sendJson(res, 200, skill as unknown as JsonValue);\n      } catch (err) {\n        sendJson(res, 400, { error: err instanceof Error ? err.message : \"Failed to update skill\" });\n      }\n      return;\n    }\n\n    if (segments.length === 3 && req.method === \"DELETE\") {\n      try {\n        const body = await readJson(req);\n        const record = asRecord(body) ? body : {};\n        await deps.skills.delete(skillId, normalizeScope(record.scope));\n        sendJson(res, 200, { success: true });\n      } catch (err) {\n        sendJson(res, 400, { error: err instanceof Error ? err.message : \"Failed to delete skill\" });\n      }\n      return;\n    }\n\n    if (segments.length === 4 && segments[3] === \"duplicate\" && req.method === \"POST\") {\n      try {\n        const body = await readJson(req);\n        const record = asRecord(body) ? body : {};\n        const newId = typeof record.newId === \"string\" ? record.newId : \"\";\n        if (!newId) {\n          sendJson(res, 400, { error: \"Missing newId\" });\n          return;\n        }\n        const skill = await deps.skills.duplicate(skillId, newId, normalizeScope(record.scope));\n        sendJson(res, 201, skill as unknown as JsonValue);\n      } catch (err) {\n        sendJson(res, 400, { error: err instanceof Error ? err.message : \"Failed to duplicate skill\" });\n      }\n      return;\n    }\n\n    const handleSpawn = async () => {\n      if (!deps.workers) {\n        sendJson(res, 501, { error: \"Worker manager not available\" });\n        return;\n      }\n      try {\n        const worker = await deps.workers.spawnById(skillId);\n        sendJson(res, 201, {\n          id: worker.profile.id,\n          status: worker.status,\n          port: worker.port,\n          model: worker.profile.model,\n        });\n      } catch (err) {\n        sendJson(res, 400, { error: err instanceof Error ? err.message : \"Failed to spawn worker\" });\n      }\n    };\n\n    if (segments.length === 4 && segments[3] === \"spawn\" && req.method === \"POST\") return await handleSpawn();\n\n    sendJson(res, 404, { error: \"Not found\" });\n  };\n}\n"
  },
  {
    "path": "api/skills-server.ts",
    "content": "import { createServer as createHttpServer, type Server } from \"node:http\";\nimport type { DatabaseService } from \"../db\";\nimport type { SkillsService } from \"../skills/service\";\nimport type { Factory, ServiceLifecycle } from \"../types\";\nimport type { WorkerManager } from \"../workers\";\nimport { createDbRouter } from \"./db-router\";\nimport { createSessionsRouter } from \"./sessions-router\";\nimport { createSkillsRouter } from \"./skills-router\";\nimport { createSystemRouter } from \"./system-router\";\n\nexport type SkillsApiConfig = {\n  enabled?: boolean;\n  host?: string;\n  port?: number;\n};\n\nexport type SkillsApiDeps = {\n  skills: SkillsService;\n  workers?: WorkerManager;\n  db?: DatabaseService;\n  onWorkerConfigChanged?: (workerId?: string) => void;\n  onPreferencesChanged?: (key?: string) => void;\n  createServer?: typeof createHttpServer;\n};\n\nexport type SkillsApiServer = ServiceLifecycle & {\n  url?: string;\n};\n\nexport const createSkillsApiServer: Factory<SkillsApiConfig, SkillsApiDeps, SkillsApiServer> = ({ config, deps }) => {\n  let server: Server | undefined;\n  let url: string | undefined;\n\n  const enabled = config.enabled !== false;\n  const host = config.host ?? \"127.0.0.1\";\n  const port = config.port ?? Number(process.env.OPENCODE_SKILLS_PORT ?? process.env.OPENCODE_SKILLS_API_PORT ?? 4097);\n\n  const start = async () => {\n    if (!enabled || server) return;\n\n    // Create routers\n    const skillsHandler = createSkillsRouter({ skills: deps.skills, workers: deps.workers });\n    const dbHandler = deps.db\n      ? createDbRouter({\n          db: deps.db,\n          onWorkerConfigChanged: deps.onWorkerConfigChanged,\n          onPreferencesChanged: deps.onPreferencesChanged,\n        })\n      : null;\n\n    // Sessions router needs workers with session manager\n    const sessionsHandler = deps.workers\n      ? createSessionsRouter({\n          sessionManager: deps.workers.sessionManager,\n          workers: deps.workers,\n        })\n      : null;\n\n    // System router for process management\n    const systemHandler = createSystemRouter();\n\n    const createServer = deps.createServer ?? createHttpServer;\n    server = createServer((req, res) => {\n      const url = req.url ?? \"\";\n\n      // Route to system API\n      if (url.startsWith(\"/api/system\")) {\n        void systemHandler(req, res);\n        return;\n      }\n\n      // Route to DB API\n      if (url.startsWith(\"/api/db\")) {\n        if (dbHandler) {\n          void dbHandler(req, res);\n        } else {\n          res.statusCode = 501;\n          res.setHeader(\"Content-Type\", \"application/json\");\n          res.end(JSON.stringify({ error: \"DB API not available\" }));\n        }\n        return;\n      }\n\n      // Route to sessions API\n      if (url.startsWith(\"/api/sessions\")) {\n        if (sessionsHandler) {\n          void sessionsHandler(req, res);\n        } else {\n          res.statusCode = 501;\n          res.setHeader(\"Content-Type\", \"application/json\");\n          res.end(JSON.stringify({ error: \"Sessions API not available\" }));\n        }\n        return;\n      }\n\n      // Route to skills API\n      void skillsHandler(req, res);\n    });\n\n    try {\n      await new Promise<void>((resolve, reject) => {\n        server!.once(\"error\", (err: NodeJS.ErrnoException) => {\n          if (err.code === \"EADDRINUSE\") {\n            // Port in use, try auto-assign\n            server!.listen(0, host, () => resolve());\n          } else {\n            reject(err);\n          }\n        });\n        server!.listen(port, host, () => resolve());\n      });\n    } catch {\n      // Failed to start server (non-fatal)\n      server = undefined;\n      return;\n    }\n\n    const address = server.address();\n    url =\n      address && typeof address === \"object\" ? `http://${address.address}:${address.port}` : `http://${host}:${port}`;\n  };\n\n  const stop = async () => {\n    if (!server) return;\n    await new Promise<void>((resolve) => server!.close(() => resolve()));\n    server = undefined;\n  };\n\n  return {\n    get url() {\n      return url;\n    },\n    start,\n    stop,\n    health: async () => ({ ok: true }),\n  };\n};\n"
  },
  {
    "path": "api/system-router.ts",
    "content": "import { exec } from \"node:child_process\";\nimport type { IncomingMessage, ServerResponse } from \"node:http\";\nimport { promisify } from \"node:util\";\n\ntype ExecAsync = (command: string) => Promise<{ stdout: string; stderr: string }>;\n\nconst defaultExecAsync = promisify(exec) as ExecAsync;\n\nexport type ProcessInfo = {\n  pid: number;\n  cpu: number;\n  memory: number;\n  started: string;\n  command: string;\n  type: \"opencode-serve\" | \"opencode-main\" | \"vite\" | \"bun\" | \"other\";\n};\n\nexport type SystemStats = {\n  processes: ProcessInfo[];\n  totalMemory: number;\n  totalCpu: number;\n  count: number;\n};\n\nasync function getOpencodeProcesses(execAsync: ExecAsync): Promise<SystemStats> {\n  try {\n    const { stdout } = await execAsync(\n      `/bin/ps aux | /usr/bin/grep -E 'opencode|node.*vite|bun.*serve' | /usr/bin/grep -v grep`,\n    );\n\n    const lines = stdout.trim().split(\"\\n\").filter(Boolean);\n    const processes: ProcessInfo[] = [];\n    let totalMemory = 0;\n    let totalCpu = 0;\n\n    for (const line of lines) {\n      const parts = line.split(/\\s+/);\n      if (parts.length < 11) continue;\n\n      const pid = parseInt(parts[1], 10);\n      const cpu = parseFloat(parts[2]) || 0;\n      const memKb = parseInt(parts[5], 10) || 0;\n      const memory = memKb / 1024; // Convert to MB\n      const started = parts[8] || \"\";\n      const command = parts.slice(10).join(\" \");\n\n      // Determine process type\n      let type: ProcessInfo[\"type\"] = \"other\";\n      if (command.includes(\"opencode serve\")) {\n        type = \"opencode-serve\";\n      } else if (command.includes(\"opencode\") && !command.includes(\"serve\")) {\n        type = \"opencode-main\";\n      } else if (command.includes(\"vite\")) {\n        type = \"vite\";\n      } else if (command.includes(\"bun\")) {\n        type = \"bun\";\n      }\n\n      processes.push({ pid, cpu, memory, started, command, type });\n      totalMemory += memory;\n      totalCpu += cpu;\n    }\n\n    // Sort by memory usage descending\n    processes.sort((a, b) => b.memory - a.memory);\n\n    return {\n      processes,\n      totalMemory,\n      totalCpu,\n      count: processes.length,\n    };\n  } catch {\n    return { processes: [], totalMemory: 0, totalCpu: 0, count: 0 };\n  }\n}\n\nasync function killProcess(execAsync: ExecAsync, pid: number): Promise<{ success: boolean; error?: string }> {\n  try {\n    await execAsync(`kill ${pid}`);\n    return { success: true };\n  } catch (err) {\n    return { success: false, error: String(err) };\n  }\n}\n\nasync function killAllOpencodeServe(\n  execAsync: ExecAsync,\n  getProcesses: (execAsync: ExecAsync) => Promise<SystemStats> = getOpencodeProcesses,\n): Promise<{ killed: number; errors: string[] }> {\n  try {\n    const stats = await getProcesses(execAsync);\n    const servePids = stats.processes.filter((p) => p.type === \"opencode-serve\").map((p) => p.pid);\n\n    let killed = 0;\n    const errors: string[] = [];\n\n    for (const pid of servePids) {\n      const result = await killProcess(execAsync, pid);\n      if (result.success) {\n        killed++;\n      } else if (result.error) {\n        errors.push(`PID ${pid}: ${result.error}`);\n      }\n    }\n\n    return { killed, errors };\n  } catch (err) {\n    return { killed: 0, errors: [String(err)] };\n  }\n}\n\nfunction sendJson(res: ServerResponse, status: number, data: unknown) {\n  res.statusCode = status;\n  res.setHeader(\"Content-Type\", \"application/json\");\n  res.setHeader(\"Access-Control-Allow-Origin\", \"*\");\n  res.setHeader(\"Access-Control-Allow-Methods\", \"GET, POST, DELETE, OPTIONS\");\n  res.setHeader(\"Access-Control-Allow-Headers\", \"Content-Type\");\n  res.end(JSON.stringify(data));\n}\n\nexport function createSystemRouter(\n  deps: { execAsync?: ExecAsync; getOpencodeProcesses?: (execAsync: ExecAsync) => Promise<SystemStats> } = {},\n) {\n  const execAsync = deps.execAsync ?? defaultExecAsync;\n  const getProcesses = deps.getOpencodeProcesses ?? getOpencodeProcesses;\n  return async (req: IncomingMessage, res: ServerResponse): Promise<void> => {\n    const url = req.url ?? \"\";\n    const method = req.method ?? \"GET\";\n\n    // Handle CORS preflight\n    if (method === \"OPTIONS\") {\n      res.statusCode = 204;\n      res.setHeader(\"Access-Control-Allow-Origin\", \"*\");\n      res.setHeader(\"Access-Control-Allow-Methods\", \"GET, POST, DELETE, OPTIONS\");\n      res.setHeader(\"Access-Control-Allow-Headers\", \"Content-Type\");\n      res.end();\n      return;\n    }\n\n    // GET /api/system/processes - List all opencode processes\n    if (url === \"/api/system/processes\" && method === \"GET\") {\n      const stats = await getProcesses(execAsync);\n      sendJson(res, 200, stats);\n      return;\n    }\n\n    // DELETE /api/system/processes/:pid - Kill a specific process\n    const killMatch = url.match(/^\\/api\\/system\\/processes\\/(\\d+)$/);\n    if (killMatch && method === \"DELETE\") {\n      const pid = parseInt(killMatch[1], 10);\n      const result = await killProcess(execAsync, pid);\n      if (result.success) {\n        sendJson(res, 200, { success: true, pid });\n      } else {\n        sendJson(res, 500, { success: false, error: result.error });\n      }\n      return;\n    }\n\n    // POST /api/system/processes/kill-all-serve - Kill all opencode serve processes\n    if (url === \"/api/system/processes/kill-all-serve\" && method === \"POST\") {\n      const result = await killAllOpencodeServe(execAsync, getProcesses);\n      sendJson(res, 200, result);\n      return;\n    }\n\n    // 404 for unknown routes\n    sendJson(res, 404, { error: \"Not found\" });\n  };\n}\n"
  },
  {
    "path": "commands/index.ts",
    "content": "import type { ApiService } from \"../api\";\nimport type { MemoryService } from \"../memory\";\nimport type { OrchestratorService } from \"../orchestrator\";\nimport type { OrchestratorConfig } from \"../types\";\nimport type { WorkerManager } from \"../workers\";\nimport { createMemoryCommands } from \"./memory\";\nimport { createOrchestratorCommands } from \"./orchestrator\";\nimport { createVisionCommands } from \"./vision\";\n\nexport type CommandDeps = {\n  api: ApiService;\n  orchestrator: OrchestratorService;\n  workers: WorkerManager;\n  memory: MemoryService;\n  config: OrchestratorConfig;\n  projectDir: string;\n};\n\nexport type CommandInput = {\n  command: string;\n  args?: unknown;\n  text?: string;\n  raw?: string;\n  sessionID?: string;\n  agent?: string;\n};\n\nexport type ParsedCommandInput = {\n  raw: string;\n  tokens: string[];\n  positional: string[];\n  named: Record<string, string | string[]>;\n};\n\nexport type CommandContext = {\n  deps: CommandDeps;\n  input: CommandInput;\n  parsed: ParsedCommandInput;\n};\n\nexport type CommandDefinition = {\n  description: string;\n  usage?: string;\n  execute: (ctx: CommandContext) => Promise<string>;\n};\n\nexport type CommandRouter = {\n  execute: (input: CommandInput) => Promise<string | undefined>;\n  list: () => Array<{ name: string; description: string; usage?: string }>;\n  commandConfig: () => Record<string, { template: string; description?: string }>;\n};\n\nfunction tokenize(input: string): string[] {\n  const tokens: string[] = [];\n  const matcher = /\"([^\"]*)\"|'([^']*)'|(\\S+)/g;\n  let match = matcher.exec(input);\n  while (match !== null) {\n    tokens.push(match[1] ?? match[2] ?? match[3]);\n    match = matcher.exec(input);\n  }\n  return tokens;\n}\n\nfunction addNamedValue(named: Record<string, string | string[]>, key: string, value: string) {\n  if (!key) return;\n  const existing = named[key];\n  if (!existing) {\n    named[key] = value;\n    return;\n  }\n  if (Array.isArray(existing)) {\n    existing.push(value);\n    return;\n  }\n  named[key] = [existing, value];\n}\n\nexport function normalizeCommandName(raw: string): string {\n  return raw.trim().replace(/^\\/+/, \"\");\n}\n\nexport function parseCommandInput(input: CommandInput): ParsedCommandInput {\n  const named: Record<string, string | string[]> = {};\n  let raw = \"\";\n  let tokens: string[] = [];\n\n  if (typeof input.args === \"string\") {\n    raw = input.args;\n    tokens = tokenize(raw);\n  } else if (Array.isArray(input.args)) {\n    tokens = input.args.map((value) => String(value));\n    raw = tokens.join(\" \");\n  } else if (typeof input.text === \"string\") {\n    raw = input.text;\n    tokens = tokenize(raw);\n  } else if (typeof input.raw === \"string\") {\n    raw = input.raw;\n    tokens = tokenize(raw);\n  }\n\n  if (input.args && typeof input.args === \"object\" && !Array.isArray(input.args)) {\n    for (const [key, value] of Object.entries(input.args as Record<string, unknown>)) {\n      if (value === undefined || value === null) continue;\n      if (Array.isArray(value)) {\n        named[key] = value.map((item) => String(item));\n        continue;\n      }\n      if (typeof value === \"string\" || typeof value === \"number\" || typeof value === \"boolean\") {\n        named[key] = String(value);\n      }\n    }\n    const extras = (input.args as Record<string, unknown>)._;\n    if (Array.isArray(extras) && tokens.length === 0) {\n      tokens = extras.map((value) => String(value));\n      raw = tokens.join(\" \");\n    }\n  }\n\n  if (!raw && tokens.length > 0) raw = tokens.join(\" \");\n\n  const positional: string[] = [];\n  for (let i = 0; i < tokens.length; i += 1) {\n    const token = tokens[i];\n    if (!token.startsWith(\"--\")) {\n      positional.push(token);\n      continue;\n    }\n\n    const trimmed = token.slice(2);\n    if (!trimmed) continue;\n    const eqIndex = trimmed.indexOf(\"=\");\n    if (eqIndex !== -1) {\n      const key = trimmed.slice(0, eqIndex);\n      const value = trimmed.slice(eqIndex + 1);\n      if (!(key in named)) addNamedValue(named, key, value);\n      continue;\n    }\n\n    const next = tokens[i + 1];\n    if (next && !next.startsWith(\"--\")) {\n      if (!(trimmed in named)) addNamedValue(named, trimmed, next);\n      i += 1;\n      continue;\n    }\n\n    if (!(trimmed in named)) named[trimmed] = \"true\";\n  }\n\n  return { raw, tokens, positional, named };\n}\n\nexport function createCommandRouter(deps: CommandDeps): CommandRouter {\n  const enabled = deps.config.commands?.enabled !== false;\n  const rawPrefix = (deps.config.commands?.prefix ?? \"orchestrator.\").trim();\n  const prefix = rawPrefix && !rawPrefix.endsWith(\".\") ? `${rawPrefix}.` : rawPrefix;\n\n  const commands: Record<string, CommandDefinition> = {\n    ...createOrchestratorCommands({ prefix }),\n    ...createVisionCommands(),\n    ...createMemoryCommands(),\n  };\n\n  return {\n    execute: async (input: CommandInput) => {\n      if (!enabled) return undefined;\n      const commandName = normalizeCommandName(String(input.command ?? \"\"));\n      const command = commands[commandName];\n      if (!command) return undefined;\n      const parsed = parseCommandInput(input);\n      return await command.execute({ deps, input, parsed });\n    },\n    list: () =>\n      Object.entries(commands).map(([name, def]) => ({\n        name,\n        description: def.description,\n        usage: def.usage,\n      })),\n    commandConfig: () => {\n      if (!enabled) return {};\n      const config: Record<string, { template: string; description?: string }> = {};\n      for (const [name, def] of Object.entries(commands)) {\n        config[name] = {\n          template: `Command ${name} handled by orchestrator plugin.`,\n          description: def.description,\n        };\n      }\n      return config;\n    },\n  };\n}\n"
  },
  {
    "path": "commands/memory.ts",
    "content": "import type { ApiService } from \"../api\";\nimport {\n  getMemoryBackend,\n  type MemoryNode,\n  type MemoryScope,\n  recentMemory,\n  searchMemory,\n  upsertMemory,\n} from \"../memory/store\";\nimport type { CommandDefinition } from \"./index\";\n\nfunction pickFirstString(value: string | string[] | undefined): string | undefined {\n  if (!value) return undefined;\n  return Array.isArray(value) ? value[0] : value;\n}\n\nfunction parseTags(value: string | string[] | undefined): string[] {\n  if (!value) return [];\n  const tags = Array.isArray(value) ? value : value.split(\",\");\n  return tags.map((tag) => tag.trim()).filter(Boolean);\n}\n\nasync function resolveProjectId(api: ApiService): Promise<string | undefined> {\n  try {\n    const res = await api.project.current({});\n    const data = res && typeof res === \"object\" && \"data\" in res ? (res as { data?: unknown }).data : (res as unknown);\n    if (data && typeof data === \"object\" && \"id\" in data) {\n      const idValue = (data as { id?: unknown }).id;\n      if (idValue) return String(idValue);\n    }\n  } catch {\n    // ignore\n  }\n  return undefined;\n}\n\nasync function resolveScope(input: {\n  api: ApiService;\n  requested: MemoryScope;\n  requireProject: boolean;\n  projectId?: string;\n}): Promise<{ scope: MemoryScope; projectId?: string }> {\n  if (input.requested !== \"project\") return { scope: input.requested };\n  const projectId = input.projectId ?? (await resolveProjectId(input.api));\n  if (!projectId) {\n    if (input.requireProject) {\n      throw new Error(\"Project scope requested but project ID is unavailable.\");\n    }\n    return { scope: \"global\" };\n  }\n  return { scope: \"project\", projectId };\n}\n\nfunction formatNode(node: MemoryNode): string {\n  const tags = node.tags.length > 0 ? ` tags=[${node.tags.join(\", \")}]` : \"\";\n  const scope = node.projectId ? `project:${node.projectId}` : node.scope;\n  return `- ${node.key}: ${node.value}${tags} (${scope})`;\n}\n\nexport function createMemoryCommands(): Record<string, CommandDefinition> {\n  return {\n    \"memory.record\": {\n      description: \"Record a memory entry in the knowledge graph\",\n      usage: \"<key> <value> [--tags tag1,tag2]\",\n      async execute(ctx) {\n        if (!ctx.deps.memory.enabled) return \"Memory is disabled.\";\n\n        const named = ctx.parsed.named;\n        const positional = ctx.parsed.positional;\n        const raw = ctx.parsed.raw;\n\n        let key = pickFirstString(named.key ?? named.k);\n        let value = pickFirstString(named.value ?? named.v);\n\n        if ((!key || !value) && raw.includes(\":\")) {\n          const [head, ...rest] = raw.split(\":\");\n          const candidateKey = head.trim();\n          const candidateValue = rest.join(\":\").trim();\n          if (candidateKey && candidateValue) {\n            key = candidateKey;\n            value = candidateValue;\n          }\n        }\n\n        if (!key && positional.length >= 2) {\n          key = positional[0];\n          value = positional.slice(1).join(\" \");\n        }\n\n        if (!key || !value) {\n          return \"Usage: /memory.record <key> <value> [--tags tag1,tag2]\";\n        }\n\n        const tags = parseTags(pickFirstString(named.tags ?? named.tag));\n        const scopeOverride = pickFirstString(named.scope) as MemoryScope | undefined;\n        const requested =\n          scopeOverride === \"global\" || scopeOverride === \"project\" ? scopeOverride : ctx.deps.memory.getScope();\n\n        const { scope, projectId } = await resolveScope({\n          api: ctx.deps.api,\n          requested,\n          requireProject: scopeOverride === \"project\",\n          projectId: ctx.deps.memory.getProjectId(),\n        });\n\n        const node = await upsertMemory({\n          scope,\n          projectId,\n          key,\n          value,\n          tags,\n        });\n\n        const backend = getMemoryBackend();\n        return `Stored (${backend})\\n${formatNode(node)}`;\n      },\n    },\n    \"memory.query\": {\n      description: \"Query the memory graph\",\n      usage: \"<query> [--limit 10]\",\n      async execute(ctx) {\n        if (!ctx.deps.memory.enabled) return \"Memory is disabled.\";\n\n        const named = ctx.parsed.named;\n        const positional = ctx.parsed.positional;\n        const query = pickFirstString(named.query) ?? positional.join(\" \");\n        const limitRaw = pickFirstString(named.limit);\n        const parsedLimit = limitRaw ? Number(limitRaw) : undefined;\n        const limit =\n          Number.isFinite(parsedLimit ?? NaN) && (parsedLimit as number) > 0 ? (parsedLimit as number) : undefined;\n\n        const scopeOverride = pickFirstString(named.scope) as MemoryScope | undefined;\n        const requested =\n          scopeOverride === \"global\" || scopeOverride === \"project\" ? scopeOverride : ctx.deps.memory.getScope();\n\n        const { scope, projectId } = await resolveScope({\n          api: ctx.deps.api,\n          requested,\n          requireProject: scopeOverride === \"project\",\n          projectId: ctx.deps.memory.getProjectId(),\n        });\n\n        const results = query\n          ? await searchMemory({ scope, projectId, query, limit })\n          : await recentMemory({ scope, projectId, limit });\n\n        if (results.length === 0) {\n          return \"No memory entries found.\";\n        }\n\n        const backend = getMemoryBackend();\n        const header = query ? `Results (${backend}) for \"${query}\"` : `Recent entries (${backend})`;\n        return [header, ...results.map(formatNode)].join(\"\\n\");\n      },\n    },\n  };\n}\n"
  },
  {
    "path": "commands/orchestrator-constants.ts",
    "content": "export const DEMO_WORKER_ID = \"glm47-vision-demo\";\nexport const DEFAULT_WORKFLOW_ID = \"bug-triage\";\nexport const COUNCIL_TIMEBOX = \"2 minutes\";\nexport const MULTIMODAL_TIMEBOX = \"2 minutes\";\n\nexport const DEFAULT_COUNCIL_TOPIC =\n  \"Design a 5-minute onboarding path for new users. Focus on immediate value, not exhaustive coverage.\";\n\nexport const DEFAULT_WORKFLOW_TASK =\n  \"Triage: Settings page shows an empty state during loading; suggest a fix and risks.\";\n"
  },
  {
    "path": "commands/orchestrator-council.ts",
    "content": "import type { WorkerInstance, WorkerProfile } from \"../types\";\nimport { COUNCIL_TIMEBOX } from \"./orchestrator-constants\";\nimport { pickCouncilWorkers, pickSummaryWorkerId, truncateText } from \"./orchestrator-utils\";\n\ntype CouncilResponse = {\n  workerId: string;\n  response?: string;\n  error?: string;\n};\n\nconst formatCouncilResponses = (responses: CouncilResponse[]): string =>\n  responses\n    .map((result) => {\n      if (result.error) {\n        return `- ${result.workerId}: error (${result.error})`;\n      }\n      return `- ${result.workerId}: ${truncateText(result.response ?? \"No response\")}`;\n    })\n    .join(\"\\n\");\n\n/** Run a short parallel \"workers council\" demo and summarize the results. */\nexport const runWorkersCouncil = async (input: {\n  deps: {\n    workers: {\n      listProfiles: () => WorkerProfile[];\n      send: (\n        workerId: string,\n        message: string,\n        options?: { timeout?: number; from?: string },\n      ) => Promise<{ success: boolean; response?: string; error?: string }>;\n    };\n    orchestrator: { ensureWorker: (input: { workerId: string; reason: \"manual\" }) => Promise<WorkerInstance> };\n  };\n  topic: string;\n  timeoutMs: number;\n}) => {\n  const profiles = input.deps.workers.listProfiles();\n  if (profiles.length === 0) {\n    return \"No worker profiles are available yet. Create a few skills to run the council.\";\n  }\n\n  const councilIds = pickCouncilWorkers(profiles, 3);\n  const prompt = [\n    `Workers Council (${COUNCIL_TIMEBOX} timebox)`,\n    `Topic: ${input.topic}`,\n    \"\",\n    \"Return:\",\n    \"- 2 bullet insights\",\n    \"- 1 risk or assumption\",\n    \"- 1 next step\",\n    \"Keep it under 120 words.\",\n  ].join(\"\\n\");\n\n  const settled = await Promise.allSettled(\n    councilIds.map(async (workerId) => {\n      await input.deps.orchestrator.ensureWorker({ workerId, reason: \"manual\" });\n      const res = await input.deps.workers.send(workerId, prompt, { timeout: input.timeoutMs, from: \"onboarding\" });\n      if (!res.success) {\n        return { workerId, error: res.error ?? \"worker error\" } satisfies CouncilResponse;\n      }\n      return { workerId, response: res.response ?? \"\" } satisfies CouncilResponse;\n    }),\n  );\n\n  const responses: CouncilResponse[] = settled.map((result, index) => {\n    const workerId = councilIds[index] ?? `worker-${index + 1}`;\n    if (result.status === \"fulfilled\") return result.value;\n    return { workerId, error: result.reason instanceof Error ? result.reason.message : String(result.reason) };\n  });\n\n  const summaryWorkerId = pickSummaryWorkerId(profiles, [\"reviewer\", \"product\", \"architect\", \"docs\", \"coder\"]);\n  let summaryText = \"\";\n  if (summaryWorkerId) {\n    try {\n      await input.deps.orchestrator.ensureWorker({ workerId: summaryWorkerId, reason: \"manual\" });\n      const summaryPrompt = [\n        \"Summarize the council responses into two short sections:\",\n        \"Consensus Summary: 2-3 bullets.\",\n        \"Next Steps: 2-3 bullets.\",\n        \"\",\n        \"Council responses:\",\n        formatCouncilResponses(responses),\n      ].join(\"\\n\");\n      const res = await input.deps.workers.send(summaryWorkerId, summaryPrompt, {\n        timeout: Math.min(45_000, input.timeoutMs),\n        from: \"onboarding\",\n      });\n      if (res.success && res.response) summaryText = res.response;\n    } catch {\n      summaryText = \"\";\n    }\n  }\n\n  const fallbackNextSteps = [\n    \"Pick one worker to dive deeper on the highest-confidence insight.\",\n    \"Run a built-in workflow to see multi-step orchestration.\",\n    \"Tune worker profiles in Settings (model, temperature, enabled).\",\n  ];\n\n  const summaryBlock =\n    summaryText.trim().length > 0\n      ? summaryText.trim()\n      : `Consensus Summary:\\n- The council produced ${responses.length} viewpoints on the onboarding focus.\\n\\nNext Steps:\\n${fallbackNextSteps.map((s) => `- ${s}`).join(\"\\n\")}`;\n\n  return [\"Workers Council Output\", formatCouncilResponses(responses), \"\", summaryBlock].join(\"\\n\");\n};\n"
  },
  {
    "path": "commands/orchestrator-image.ts",
    "content": "import { deflateSync } from \"node:zlib\";\n\nexport type ImageAttachment = { type: \"image\"; base64: string; mimeType: string };\n\n// Build a minimal in-memory PNG without external dependencies.\nconst createSolidPngBase64 = (width: number, height: number, rgba: [number, number, number, number]): string => {\n  const rowSize = 1 + width * 4;\n  const raw = Buffer.alloc(rowSize * height);\n  for (let y = 0; y < height; y += 1) {\n    const rowStart = y * rowSize;\n    raw[rowStart] = 0;\n    for (let x = 0; x < width; x += 1) {\n      const offset = rowStart + 1 + x * 4;\n      raw[offset] = rgba[0];\n      raw[offset + 1] = rgba[1];\n      raw[offset + 2] = rgba[2];\n      raw[offset + 3] = rgba[3];\n    }\n  }\n\n  const crcTable = new Uint32Array(256).map((_, i) => {\n    let c = i;\n    for (let k = 0; k < 8; k += 1) {\n      c = c & 1 ? 0xedb88320 ^ (c >>> 1) : c >>> 1;\n    }\n    return c >>> 0;\n  });\n  const crc32 = (buf: Buffer) => {\n    let crc = 0xffffffff;\n    for (const b of buf) {\n      crc = (crc >>> 8) ^ crcTable[(crc ^ b) & 0xff];\n    }\n    return (crc ^ 0xffffffff) >>> 0;\n  };\n  const chunk = (type: string, data: Buffer) => {\n    const len = Buffer.alloc(4);\n    len.writeUInt32BE(data.length, 0);\n    const typeBuf = Buffer.from(type, \"ascii\");\n    const crc = Buffer.alloc(4);\n    crc.writeUInt32BE(crc32(Buffer.concat([typeBuf, data])), 0);\n    return Buffer.concat([len, typeBuf, data, crc]);\n  };\n\n  const signature = Buffer.from([0x89, 0x50, 0x4e, 0x47, 0x0d, 0x0a, 0x1a, 0x0a]);\n  const ihdr = Buffer.alloc(13);\n  ihdr.writeUInt32BE(width, 0);\n  ihdr.writeUInt32BE(height, 4);\n  ihdr[8] = 8;\n  ihdr[9] = 6;\n  ihdr[10] = 0;\n  ihdr[11] = 0;\n  ihdr[12] = 0;\n\n  const idat = deflateSync(raw);\n  return Buffer.concat([signature, chunk(\"IHDR\", ihdr), chunk(\"IDAT\", idat), chunk(\"IEND\", Buffer.alloc(0))]).toString(\n    \"base64\",\n  );\n};\n\n/** Create a small red PNG payload for the vision demo when no image is provided. */\nexport const buildFallbackImage = (): ImageAttachment => {\n  const base64 = createSolidPngBase64(64, 64, [220, 61, 45, 255]);\n  return { type: \"image\", base64, mimeType: \"image/png\" };\n};\n"
  },
  {
    "path": "commands/orchestrator-multimodal.ts",
    "content": "import { existsSync } from \"node:fs\";\nimport { resolve as resolvePath } from \"node:path\";\nimport type { WorkerInstance, WorkerProfile } from \"../types\";\nimport { DEMO_WORKER_ID, MULTIMODAL_TIMEBOX } from \"./orchestrator-constants\";\nimport { buildFallbackImage, type ImageAttachment } from \"./orchestrator-image\";\nimport { truncateText } from \"./orchestrator-utils\";\n\n/** Run the multimodal demo (vision analysis + workflow run) for onboarding. */\nexport const runMultimodalDemo = async (input: {\n  deps: {\n    workers: {\n      listProfiles: () => WorkerProfile[];\n      send: (\n        workerId: string,\n        message: string,\n        options?: {\n          timeout?: number;\n          from?: string;\n          attachments?: Array<{ type: \"image\"; base64?: string; path?: string; mimeType?: string }>;\n        },\n      ) => Promise<{ success: boolean; response?: string; error?: string }>;\n    };\n    orchestrator: {\n      ensureWorker: (input: { workerId: string; reason: \"manual\" }) => Promise<WorkerInstance>;\n      runWorkflow: (input: { workflowId: string; task: string }) => Promise<{\n        workflowId: string;\n        workflowName: string;\n        steps: Array<{\n          id: string;\n          title: string;\n          workerId: string;\n          status: string;\n          response?: string;\n          error?: string;\n        }>;\n      }>;\n    };\n  };\n  imagePath?: string;\n  base64?: string;\n  mimeType?: string;\n  workflowId: string;\n  workflowTask: string;\n  timeoutMs: number;\n}) => {\n  const profiles = input.deps.workers.listProfiles();\n  const byId = new Map(profiles.map((profile) => [profile.id, profile]));\n  const visionProfile =\n    byId.get(DEMO_WORKER_ID) ?? profiles.find((profile) => profile.supportsVision) ?? byId.get(\"vision\");\n\n  if (!visionProfile) {\n    return \"No vision-capable worker is available. Add a vision profile to run the multimodal demo.\";\n  }\n\n  const attachment: ImageAttachment | { type: \"image\"; path: string; mimeType?: string } =\n    input.imagePath && existsSync(input.imagePath)\n      ? { type: \"image\" as const, path: resolvePath(input.imagePath), mimeType: input.mimeType }\n      : input.base64\n        ? { type: \"image\" as const, base64: input.base64, mimeType: input.mimeType ?? \"image/png\" }\n        : buildFallbackImage();\n\n  await input.deps.orchestrator.ensureWorker({ workerId: visionProfile.id, reason: \"manual\" });\n  const visionPrompt = [\n    `Multimodal Demo (${MULTIMODAL_TIMEBOX} timebox)`,\n    \"Describe the image, call out any text, and give one actionable insight.\",\n  ].join(\"\\n\");\n  const visionRes = await input.deps.workers.send(visionProfile.id, visionPrompt, {\n    timeout: input.timeoutMs,\n    from: \"onboarding\",\n    attachments: [attachment],\n  });\n\n  let workflowOutput = \"Workflow demo unavailable.\";\n  try {\n    const workflowResult = await input.deps.orchestrator.runWorkflow({\n      workflowId: input.workflowId,\n      task: input.workflowTask,\n    });\n    const stepLines = workflowResult.steps.map((step) => {\n      if (step.status === \"error\") {\n        return `- ${step.title} (${step.workerId}): error (${step.error ?? \"unknown\"})`;\n      }\n      return `- ${step.title} (${step.workerId}): ${truncateText(step.response ?? \"\")}`;\n    });\n    workflowOutput = [`Workflow: ${workflowResult.workflowName} (${workflowResult.workflowId})`, ...stepLines].join(\n      \"\\n\",\n    );\n  } catch (err) {\n    workflowOutput = `Workflow demo failed: ${err instanceof Error ? err.message : String(err)}`;\n  }\n\n  const visionOutput = visionRes.success\n    ? truncateText(visionRes.response ?? \"No vision response returned.\")\n    : `Vision demo failed: ${visionRes.error ?? \"unknown error\"}`;\n\n  const modelLabel = visionProfile.model ? ` (model: ${visionProfile.model})` : \"\";\n\n  return [`Vision Output${modelLabel}`, visionOutput, \"\", workflowOutput].join(\"\\n\");\n};\n"
  },
  {
    "path": "commands/orchestrator-utils.ts",
    "content": "import type { WorkerInstance, WorkerProfile } from \"../types\";\n\n/** Format a single line describing a running worker. */\nexport const formatWorkerLine = (worker: WorkerInstance): string => {\n  const name = worker.profile.name ? ` (${worker.profile.name})` : \"\";\n  const port = worker.port ? ` port=${worker.port}` : \"\";\n  const status = worker.status ? ` status=${worker.status}` : \"\";\n  return `- ${worker.profile.id}${name}${status}${port} model=${worker.profile.model}`;\n};\n\n/** Format a profile summary line with running state. */\nexport const formatProfileLine = (profile: WorkerProfile, running: boolean): string => {\n  const state = running ? \"running\" : \"idle\";\n  return `- ${profile.id} (${state}) model=${profile.model}`;\n};\n\n/** Return the first string in a flag value that may be a string or string list. */\nexport const pickFirstString = (value: string | string[] | undefined): string | undefined => {\n  if (!value) return undefined;\n  return Array.isArray(value) ? value[0] : value;\n};\n\n/** Clamp long text output to a fixed number of characters. */\nexport const truncateText = (input: string, maxChars = 600): string => {\n  if (input.length <= maxChars) return input;\n  return `${input.slice(0, Math.max(0, maxChars - 3))}...`;\n};\n\n/** Choose a short list of preferred worker IDs for the council demo. */\nexport const pickCouncilWorkers = (profiles: WorkerProfile[], limit = 3): string[] => {\n  const preferred = [\"product\", \"architect\", \"coder\", \"reviewer\", \"analyst\", \"docs\", \"qa\"];\n  const available = new Set(profiles.map((profile) => profile.id));\n  const picked = preferred.filter((id) => available.has(id)).slice(0, limit);\n  if (picked.length >= limit) return picked;\n\n  const fallback = profiles.map((profile) => profile.id).filter((id) => !picked.includes(id));\n  return [...picked, ...fallback].slice(0, limit);\n};\n\n/** Pick a worker ID to summarize council responses. */\nexport const pickSummaryWorkerId = (profiles: WorkerProfile[], candidates: string[]): string | undefined => {\n  const byId = new Map(profiles.map((profile) => [profile.id, profile]));\n  for (const id of candidates) {\n    if (byId.has(id)) return id;\n  }\n  return profiles[0]?.id;\n};\n\n/** Build the status output for the orchestrator status command. */\nexport const buildStatusOutput = (input: {\n  workers: WorkerInstance[];\n  profiles: WorkerProfile[];\n  autoSpawn: string[];\n}): string => {\n  const runningIds = new Set(input.workers.map((worker) => worker.profile.id));\n  const lines: string[] = [];\n\n  lines.push(`Workers: ${input.workers.length} running / ${input.profiles.length} profiles`);\n\n  if (input.workers.length > 0) {\n    lines.push(\"Running workers:\");\n    for (const worker of input.workers) {\n      lines.push(formatWorkerLine(worker));\n    }\n  }\n\n  if (input.profiles.length > 0) {\n    lines.push(\"Profiles:\");\n    for (const profile of input.profiles) {\n      lines.push(formatProfileLine(profile, runningIds.has(profile.id)));\n    }\n  }\n\n  if (input.autoSpawn.length > 0) {\n    lines.push(`Auto-spawn: ${input.autoSpawn.join(\", \")}`);\n  }\n\n  return lines.join(\"\\n\");\n};\n\n/** Resolve a worker ID from parsed command arguments. */\nexport const pickWorkerId = (positional: string[], named: Record<string, string | string[]>): string | undefined => {\n  const namedId = named.workerId ?? named.profileId ?? named.id;\n  if (Array.isArray(namedId)) return namedId[0];\n  if (typeof namedId === \"string\" && namedId.trim()) return namedId.trim();\n  if (positional.length > 0) return positional[0];\n  return undefined;\n};\n"
  },
  {
    "path": "commands/orchestrator.ts",
    "content": "import type { CommandDefinition } from \"./index\";\nimport { DEFAULT_COUNCIL_TOPIC, DEFAULT_WORKFLOW_ID, DEFAULT_WORKFLOW_TASK } from \"./orchestrator-constants\";\nimport { runWorkersCouncil } from \"./orchestrator-council\";\nimport { runMultimodalDemo } from \"./orchestrator-multimodal\";\nimport { buildStatusOutput, pickFirstString, pickWorkerId } from \"./orchestrator-utils\";\n\n/** Build the orchestrator command table using the configured command prefix. */\nexport function createOrchestratorCommands(input: { prefix: string }): Record<string, CommandDefinition> {\n  const prefix = input.prefix;\n  const baseName = prefix.endsWith(\".\") ? prefix.slice(0, -1) : prefix;\n  const statusName = `${prefix}status`;\n  const spawnName = `${prefix}spawn`;\n  const stopName = `${prefix}stop`;\n  const demoName = `${prefix}demo`;\n  const onboardName = `${prefix}onboard`;\n  const helpName = `${prefix}help`;\n  const listName = `${prefix}list`;\n  const listWorkersName = `${prefix}list_workers`;\n\n  const helpTarget = baseName || helpName;\n  const listTarget = baseName || listName;\n  const statusTarget = baseName || statusName;\n  const spawnTarget = baseName || spawnName;\n  const stopTarget = baseName || stopName;\n  const demoTarget = baseName || demoName;\n  const onboardTarget = baseName || onboardName;\n\n  const helpCommand: CommandDefinition = {\n    description: \"Show available orchestrator commands\",\n    async execute(_ctx) {\n      const lines: string[] = [\n        \"Orchestrator Commands\",\n        \"\",\n        `/${helpTarget} help`,\n        \"  Show this help message\",\n        \"\",\n        `/${listTarget} list`,\n        \"  List all running workers with their status\",\n        \"\",\n        `/${statusTarget} status`,\n        \"  Show orchestrator status (workers + profiles)\",\n        \"\",\n        `/${spawnTarget} spawn <profileId>`,\n        \"  Spawn a worker by profile ID\",\n        \"\",\n        `/${stopTarget} stop <profileId|all>`,\n        \"  Stop a running worker (or all workers)\",\n        \"\",\n        `/${demoTarget} demo`,\n        \"  Run a short orchestrator demo\",\n        \"\",\n        `/${onboardTarget} onboard [council|multimodal|all]`,\n        \"  Run the 5-minute onboarding flow\",\n        \"\",\n        \"/vision.analyze [--path <file>] [--prompt <text>]\",\n        \"  Analyze an image from clipboard or file\",\n        \"\",\n        \"/memory.record <key> <value> [--tags tag1,tag2]\",\n        \"  Record a memory entry\",\n        \"\",\n        \"/memory.query <query> [--limit 10]\",\n        \"  Query the memory graph\",\n      ];\n      return lines.join(\"\\n\");\n    },\n  };\n\n  const listCommand: CommandDefinition = {\n    description: \"List all running workers\",\n    async execute(ctx) {\n      const workers = ctx.deps.workers.listWorkers();\n\n      if (workers.length === 0) {\n        return \"No workers are currently running.\";\n      }\n\n      const lines: string[] = [`Running Workers (${workers.length})`, \"\"];\n\n      for (const worker of workers) {\n        const name = worker.profile.name || worker.profile.id;\n        const model = worker.profile.model;\n        const port = worker.port ? `port ${worker.port}` : \"no port\";\n        const status = worker.status || \"unknown\";\n        const vision = worker.profile.supportsVision ? \" [vision]\" : \"\";\n\n        lines.push(`${name}`);\n        lines.push(`  ID: ${worker.profile.id}`);\n        lines.push(`  Model: ${model}${vision}`);\n        lines.push(`  Status: ${status}`);\n        lines.push(`  Port: ${port}`);\n        lines.push(\"\");\n      }\n\n      return lines.join(\"\\n\").trimEnd();\n    },\n  };\n\n  const statusCommand: CommandDefinition = {\n    description: \"Show orchestrator worker status\",\n    async execute(ctx) {\n      const workers = ctx.deps.workers.listWorkers();\n      const profiles = ctx.deps.workers.listProfiles();\n      const autoSpawn = ctx.deps.config.spawn ?? [];\n      return buildStatusOutput({ workers, profiles, autoSpawn });\n    },\n  };\n\n  const spawnCommand: CommandDefinition = {\n    description: \"Spawn a worker by profile ID\",\n    usage: \"<profileId>\",\n    async execute(ctx) {\n      const workerId = pickWorkerId(ctx.parsed.positional, ctx.parsed.named);\n      if (!workerId) {\n        return `Usage: /${spawnName} <profileId>`;\n      }\n\n      const profile = ctx.deps.workers.getProfile(workerId);\n      if (!profile) {\n        const available = ctx.deps.workers\n          .listProfiles()\n          .map((p) => p.id)\n          .join(\", \");\n        return `Unknown profile \"${workerId}\". Available: ${available || \"none\"}.`;\n      }\n\n      const worker = await ctx.deps.orchestrator.ensureWorker({ workerId, reason: \"manual\" });\n      return `Spawned ${worker.profile.id} (${worker.profile.model}) on port ${worker.port}.`;\n    },\n  };\n\n  const stopCommand: CommandDefinition = {\n    description: \"Stop a running worker\",\n    usage: \"<profileId|all>\",\n    async execute(ctx) {\n      const workerId = pickWorkerId(ctx.parsed.positional, ctx.parsed.named);\n      if (!workerId || workerId === \"all\") {\n        const workers = ctx.deps.workers.listWorkers();\n        if (workers.length === 0) {\n          return \"No workers are currently running.\";\n        }\n        const results = await Promise.allSettled(\n          workers.map((worker) => ctx.deps.workers.stopWorker(worker.profile.id)),\n        );\n        const stopped = results.filter((result) => result.status === \"fulfilled\" && result.value).length;\n        const failed = results.length - stopped;\n        if (failed > 0) {\n          return `Stopped ${stopped}/${results.length} workers. ${failed} failed to stop.`;\n        }\n        return `Stopped ${stopped} workers.`;\n      }\n\n      try {\n        const stopped = await ctx.deps.workers.stopWorker(workerId);\n        if (!stopped) return `Worker \"${workerId}\" is not running.`;\n        return `Stopped ${workerId}.`;\n      } catch (err) {\n        const error = err instanceof Error ? err.message : String(err);\n        return `Failed to stop ${workerId}: ${error}`;\n      }\n    },\n  };\n\n  const demoCommand: CommandDefinition = {\n    description: \"Run a short orchestrator demo\",\n    async execute(ctx) {\n      const targets = [\"vision\", \"docs\", \"memory\"].filter((id) => ctx.deps.workers.getProfile(id));\n      const results = await Promise.allSettled(\n        targets.map((id) => ctx.deps.orchestrator.ensureWorker({ workerId: id, reason: \"manual\" })),\n      );\n\n      const lines: string[] = [\"Spawning workers...\"];\n      results.forEach((result, index) => {\n        const id = targets[index];\n        if (!id) return;\n        if (result.status === \"fulfilled\") {\n          const name = result.value.profile.name || id;\n          lines.push(`OK ${name} ready`);\n        } else {\n          const error = result.reason instanceof Error ? result.reason.message : String(result.reason);\n          lines.push(`ERROR ${id}: ${error}`);\n        }\n      });\n\n      lines.push(\"\");\n      lines.push(\"Try these:\");\n      lines.push(\"1. Paste a screenshot to analyze\");\n      lines.push(\"2. Ask: What does the useState hook do?\");\n      lines.push(\"3. Say: Remember that we prefer TypeScript\");\n\n      return lines.join(\"\\n\");\n    },\n  };\n\n  const onboardCommand: CommandDefinition = {\n    description: \"Run the 5-minute onboarding flow (council + multimodal demo)\",\n    usage: \"[council|multimodal|all] [--topic <text>] [--image <path>] [--workflow <id>]\",\n    async execute(ctx) {\n      const modeRaw = ctx.parsed.positional[0] ?? pickFirstString(ctx.parsed.named.mode) ?? \"all\";\n      const mode = modeRaw.toLowerCase();\n      const topic =\n        pickFirstString(ctx.parsed.named.topic) ??\n        pickFirstString(ctx.parsed.named.task) ??\n        DEFAULT_COUNCIL_TOPIC;\n      const workflowId = pickFirstString(ctx.parsed.named.workflow) ?? DEFAULT_WORKFLOW_ID;\n      const workflowTask =\n        pickFirstString(ctx.parsed.named.workflowTask) ??\n        pickFirstString(ctx.parsed.named[\"workflow-task\"]) ??\n        DEFAULT_WORKFLOW_TASK;\n      const imagePath = pickFirstString(ctx.parsed.named.image);\n      const base64 = pickFirstString(ctx.parsed.named.base64);\n      const mimeType =\n        pickFirstString(ctx.parsed.named.mime) ??\n        pickFirstString(ctx.parsed.named.mimeType) ??\n        pickFirstString(ctx.parsed.named[\"mime-type\"]);\n\n      const timeoutMs = 75_000;\n\n      if (mode === \"council\") {\n        return await runWorkersCouncil({ deps: ctx.deps, topic, timeoutMs });\n      }\n      if (mode === \"multimodal\") {\n        return await runMultimodalDemo({\n          deps: ctx.deps,\n          imagePath,\n          base64,\n          mimeType,\n          workflowId,\n          workflowTask,\n          timeoutMs,\n        });\n      }\n\n      const council = await runWorkersCouncil({ deps: ctx.deps, topic, timeoutMs });\n      const multimodal = await runMultimodalDemo({\n        deps: ctx.deps,\n        imagePath,\n        base64,\n        mimeType,\n        workflowId,\n        workflowTask,\n        timeoutMs,\n      });\n\n      return [\"Onboarding Flow (<=5 minutes)\", \"\", council, \"\", multimodal].join(\"\\n\");\n    },\n  };\n\n  const commands: Record<string, CommandDefinition> = {\n    [helpName]: helpCommand,\n    [listName]: listCommand,\n    [listWorkersName]: listCommand,\n    [statusName]: statusCommand,\n    [spawnName]: spawnCommand,\n    [stopName]: stopCommand,\n    [demoName]: demoCommand,\n    [onboardName]: onboardCommand,\n  };\n\n  if (baseName) {\n    const aliasMap: Record<string, string> = {\n      help: helpName,\n      list: listName,\n      workers: listName,\n      status: statusName,\n      spawn: spawnName,\n      stop: stopName,\n      demo: demoName,\n      onboard: onboardName,\n      onboarding: onboardName,\n      council: onboardName,\n      multimodal: onboardName,\n    };\n\n    commands[baseName] = {\n      description: \"Orchestrator command router (verb-based)\",\n      usage: \"<action> [args]\",\n      async execute(ctx) {\n        const [verbRaw, ...rest] = ctx.parsed.positional;\n        if (!verbRaw) {\n          return commands[helpName].execute(ctx);\n        }\n\n        const verb = verbRaw.toLowerCase();\n        const target = aliasMap[verb];\n        if (!target) {\n          return `Unknown action \"${verb}\". Try /${helpTarget} help.`;\n        }\n\n        const nextPositional = verb === \"council\" || verb === \"multimodal\" ? [verb, ...rest] : rest;\n        const nextParsed = {\n          ...ctx.parsed,\n          positional: nextPositional,\n          tokens: nextPositional,\n          raw: nextPositional.join(\" \"),\n        };\n\n        return commands[target].execute({ ...ctx, parsed: nextParsed });\n      },\n    };\n  }\n\n  return commands;\n}\n"
  },
  {
    "path": "commands/vision.ts",
    "content": "import { existsSync } from \"node:fs\";\nimport { isAbsolute, resolve as resolvePath } from \"node:path\";\nimport { extractVisionAttachments, formatVisionAnalysis, type VisionPart } from \"../ux/vision-routing\";\nimport type { CommandDefinition } from \"./index\";\n\nconst DEFAULT_PROMPT =\n  \"Analyze this image and describe what you see. Focus on any text, code, UI elements, errors, or relevant details.\";\n\nfunction resolveCandidatePath(projectDir: string, inputPath: string): string {\n  if (isAbsolute(inputPath)) return inputPath;\n  return resolvePath(projectDir, inputPath);\n}\n\nfunction pickFirstString(value: string | string[] | undefined): string | undefined {\n  if (!value) return undefined;\n  return Array.isArray(value) ? value[0] : value;\n}\n\nexport function createVisionCommands(): Record<string, CommandDefinition> {\n  return {\n    \"vision.analyze\": {\n      description: \"Analyze an image from the clipboard or a file\",\n      usage: \"[--path <file>] [--prompt <text>]\",\n      async execute(ctx) {\n        const named = ctx.parsed.named;\n        const positional = ctx.parsed.positional;\n\n        const explicitPath = pickFirstString(named.path ?? named.file);\n        let candidatePath: string | undefined;\n        let remainingPositional = positional;\n\n        if (explicitPath) {\n          candidatePath = resolveCandidatePath(ctx.deps.projectDir, explicitPath);\n        } else if (positional.length > 0) {\n          const guess = resolveCandidatePath(ctx.deps.projectDir, positional[0]);\n          if (existsSync(guess)) {\n            candidatePath = guess;\n            remainingPositional = positional.slice(1);\n          }\n        }\n\n        if (candidatePath && !existsSync(candidatePath)) {\n          return `File not found: ${candidatePath}`;\n        }\n\n        const promptOverride =\n          pickFirstString(named.prompt ?? named.question) ||\n          (remainingPositional.length > 0 ? remainingPositional.join(\" \") : undefined);\n        const prompt = promptOverride?.trim() || process.env.OPENCODE_VISION_PROMPT?.trim() || DEFAULT_PROMPT;\n\n        if (!ctx.deps.workers.getProfile(\"vision\")) {\n          return \"Vision profile is not available.\";\n        }\n\n        const mimeType = pickFirstString(named.mime ?? named.mimeType);\n        const base64 = pickFirstString(named.base64);\n        const parts: VisionPart[] = [];\n\n        if (base64) {\n          parts.push({ type: \"image\", base64, ...(mimeType ? { mimeType } : {}) });\n        } else if (candidatePath) {\n          parts.push({ type: \"image\", url: candidatePath, ...(mimeType ? { mimeType } : {}) });\n        } else {\n          parts.push({ type: \"image\", url: \"clipboard\" });\n        }\n\n        const attachments = await extractVisionAttachments(parts);\n        if (attachments.length === 0) {\n          return \"No image was found in the clipboard or provided file.\";\n        }\n\n        await ctx.deps.orchestrator.ensureWorker({ workerId: \"vision\", reason: \"manual\" });\n\n        const timeoutMsRaw = pickFirstString(named.timeoutMs ?? named.timeout);\n        const parsedTimeout = timeoutMsRaw ? Number(timeoutMsRaw) : undefined;\n        const timeoutMs =\n          Number.isFinite(parsedTimeout ?? NaN) && (parsedTimeout as number) > 0\n            ? (parsedTimeout as number)\n            : undefined;\n\n        const res = await ctx.deps.workers.send(\"vision\", prompt, {\n          attachments,\n          ...(timeoutMs ? { timeout: timeoutMs } : {}),\n          from: ctx.input.agent ?? \"orchestrator\",\n        });\n\n        const analysis = formatVisionAnalysis({ response: res.response, error: res.error });\n        return analysis;\n      },\n    },\n  };\n}\n"
  },
  {
    "path": "communication/events.ts",
    "content": "import type { Event as OpenCodeEvent } from \"@opencode-ai/sdk\";\nimport type { Skill, SkillScope, WorkerForwardEvent, WorkerInstance, WorkerSessionMode } from \"../types\";\nimport type { WorkerJob } from \"../workers/jobs\";\n\nexport type OrchestraEventMeta = {\n  source: \"orchestrator\" | \"worker\" | \"sdk\" | \"session-manager\" | \"event-forwarding\" | \"vision\";\n  sessionId?: string;\n  workerId?: string;\n  jobId?: string;\n};\n\n// Session-related event payloads\nexport type SessionCreatedPayload = {\n  session: {\n    workerId: string;\n    sessionId: string;\n    mode: WorkerSessionMode;\n    parentSessionId?: string;\n    serverUrl?: string;\n    createdAt: string;\n    lastActivity: string;\n    status: string;\n    messageCount: number;\n    toolCount: number;\n    recentActivityCount: number;\n    error?: string;\n  };\n};\n\nexport type SessionActivityPayload = {\n  sessionId: string;\n  workerId: string;\n  activity: {\n    id: string;\n    type: WorkerForwardEvent;\n    timestamp: string;\n    summary: string;\n  };\n};\n\nexport type SessionStatusPayload = {\n  sessionId: string;\n  workerId: string;\n  status: string;\n  error?: string;\n};\n\nexport type SessionClosedPayload = {\n  sessionId: string;\n  workerId: string;\n};\n\nexport type SessionErrorPayload = {\n  workerId: string;\n  sessionId?: string;\n  error: string;\n};\n\nexport type StreamChunk = {\n  workerId: string;\n  jobId?: string;\n  chunk: string;\n  timestamp: number;\n  final?: boolean;\n};\n\nexport type SubagentSessionInfo = {\n  workerId: string;\n  sessionId: string;\n  parentSessionId?: string;\n  profile?: { id: string; name: string; model?: string };\n  serverUrl?: string;\n  status?: string;\n};\n\nexport type SubagentActivePayload = {\n  subagent: SubagentSessionInfo;\n};\n\nexport type SubagentClosedPayload = {\n  subagent: SubagentSessionInfo;\n  result?: { summary?: string; error?: string };\n};\n\nexport type ModelResolution = {\n  profileId: string;\n  from: string;\n  to: string;\n  reason: string;\n};\n\nexport type OrchestraEventMap = {\n  \"orchestra.server.event\": { event: OpenCodeEvent };\n  \"orchestra.started\": { profileCount: number; autoSpawn: string[]; fallbackModel?: string };\n  \"orchestra.model.resolved\": { resolution: ModelResolution };\n  \"orchestra.model.fallback\": { profileId: string; model: string; reason: string };\n  \"orchestra.worker.spawned\": { worker: WorkerInstance };\n  \"orchestra.worker.created\": { worker: WorkerInstance };\n  \"orchestra.worker.reused\": { worker: WorkerInstance };\n  \"orchestra.worker.ready\": { worker: WorkerInstance };\n  \"orchestra.worker.busy\": { worker: WorkerInstance };\n  \"orchestra.worker.error\": { worker: WorkerInstance; error: string };\n  \"orchestra.worker.completed\": { worker: WorkerInstance; jobId?: string; response?: string };\n  \"orchestra.worker.stopped\": { worker: WorkerInstance };\n  \"orchestra.worker.job\": { job: WorkerJob; status: \"created\" | \"succeeded\" | \"failed\" };\n  \"orchestra.worker.stream\": { chunk: StreamChunk };\n  \"orchestra.worker.response\": { worker: WorkerInstance; response: string; jobId?: string };\n  \"orchestra.worker.wakeup\": { workerId: string; jobId?: string; reason: string; summary?: string };\n  \"orchestra.vision.started\": { sessionId: string; messageId?: string; jobId?: string };\n  \"orchestra.vision.completed\": { success: boolean; error?: string; durationMs?: number; jobId?: string };\n  // Session events\n  \"orchestra.session.created\": SessionCreatedPayload;\n  \"orchestra.session.activity\": SessionActivityPayload;\n  \"orchestra.session.status\": SessionStatusPayload;\n  \"orchestra.session.closed\": SessionClosedPayload;\n  \"orchestra.session.error\": SessionErrorPayload;\n  // Subagent events\n  \"orchestra.subagent.active\": SubagentActivePayload;\n  \"orchestra.subagent.closed\": SubagentClosedPayload;\n  // Skill events\n  \"skill.created\": { skill: Skill };\n  \"skill.updated\": { skill: Skill };\n  \"skill.deleted\": { id: string; scope: SkillScope };\n};\n\nexport type OrchestraEventName = keyof OrchestraEventMap;\n\nexport type OrchestraEvent<T extends OrchestraEventName> = {\n  type: T;\n  meta: OrchestraEventMeta;\n  data: OrchestraEventMap[T];\n};\n"
  },
  {
    "path": "communication/index.ts",
    "content": "import { EventEmitter } from \"node:events\";\nimport type { Event as OpenCodeEvent } from \"@opencode-ai/sdk\";\nimport type { ApiService } from \"../api\";\nimport type { Factory, ServiceLifecycle } from \"../types\";\nimport type { OrchestraEvent, OrchestraEventMap, OrchestraEventMeta, OrchestraEventName } from \"./events\";\n\nexport type CommunicationConfig = {\n  maxListeners?: number;\n  enableSdkEvents?: boolean;\n};\n\nexport type CommunicationDeps = {\n  api: ApiService;\n};\n\nexport type CommunicationService = ServiceLifecycle & {\n  emit: <T extends OrchestraEventName>(type: T, data: OrchestraEventMap[T], meta: OrchestraEventMeta) => void;\n  on: <T extends OrchestraEventName>(type: T, handler: (event: OrchestraEvent<T>) => void) => () => void;\n  off: <T extends OrchestraEventName>(type: T, handler: (event: OrchestraEvent<T>) => void) => void;\n};\n\nexport const createCommunication: Factory<CommunicationConfig, CommunicationDeps, CommunicationService> = ({\n  config,\n  deps,\n}) => {\n  const emitter = new EventEmitter();\n  emitter.setMaxListeners(config.maxListeners ?? 50);\n  const enableSdkEvents = config.enableSdkEvents !== false;\n\n  type AnyOrchestraEventHandler = (event: OrchestraEvent<OrchestraEventName>) => void;\n  type EventStreamResult = {\n    stream: AsyncGenerator<OpenCodeEvent, unknown, unknown>;\n  };\n\n  let abortController: AbortController | undefined;\n  let streamTask: Promise<void> | undefined;\n\n  // Forward orchestra events to the SSE stream for frontend visibility\n  const forwardToSse = <T extends OrchestraEventName>(\n    type: T,\n    data: OrchestraEventMap[T],\n    meta: OrchestraEventMeta,\n  ) => {\n    // Forward worker events, session events, orchestrator lifecycle, and model events\n    if (\n      type.startsWith(\"orchestra.worker.\") ||\n      type.startsWith(\"orchestra.session.\") ||\n      type.startsWith(\"orchestra.subagent.\") ||\n      type.startsWith(\"orchestra.model.\") ||\n      type === \"orchestra.started\" ||\n      type.startsWith(\"skill.\")\n    ) {\n      deps.api.tui\n        .publish({\n          body: {\n            type: \"orchestra.event\",\n            payload: { type, data, meta },\n          },\n        })\n        .catch(() => {});\n    }\n  };\n\n  const emit = <T extends OrchestraEventName>(type: T, data: OrchestraEventMap[T], meta: OrchestraEventMeta) => {\n    emitter.emit(type, { type, data, meta } satisfies OrchestraEvent<T>);\n    forwardToSse(type, data, meta);\n  };\n\n  const on = <T extends OrchestraEventName>(type: T, handler: (event: OrchestraEvent<T>) => void) => {\n    emitter.on(type, handler as AnyOrchestraEventHandler);\n    return () => emitter.off(type, handler as AnyOrchestraEventHandler);\n  };\n\n  const off = <T extends OrchestraEventName>(type: T, handler: (event: OrchestraEvent<T>) => void) => {\n    emitter.off(type, handler as AnyOrchestraEventHandler);\n  };\n\n  return {\n    emit,\n    on,\n    off,\n    start: async () => {\n      if (!enableSdkEvents) return;\n      if (abortController) return;\n      abortController = new AbortController();\n\n      try {\n        const result = (await deps.api.event.subscribe({ signal: abortController.signal })) as EventStreamResult;\n        streamTask = (async () => {\n          try {\n            for await (const event of result.stream) {\n              emit(\"orchestra.server.event\", { event }, { source: \"sdk\" });\n            }\n          } catch {\n            // ignore stream errors\n          }\n        })();\n      } catch {\n        // event subscription failed (non-fatal)\n        abortController = undefined;\n      }\n    },\n    stop: async () => {\n      abortController?.abort();\n      abortController = undefined;\n      if (streamTask) {\n        try {\n          await streamTask;\n        } catch {\n          // ignore stream errors\n        }\n        streamTask = undefined;\n      }\n      emitter.removeAllListeners();\n    },\n    health: async () => ({ ok: true }),\n  };\n};\n"
  },
  {
    "path": "config/opencode.ts",
    "content": "import { existsSync } from \"node:fs\";\nimport { readFile } from \"node:fs/promises\";\nimport { join } from \"node:path\";\nimport { deepMerge, getUserConfigDir, isPlainObject } from \"../helpers/format\";\n\nconst ORCHESTRATOR_PLUGIN_SUFFIXES = [\"orchestrator.js\", \"orchestrator.mjs\", \"orchestrator.cjs\", \"orchestrator.ts\"];\nconst ORCHESTRATOR_PLUGIN_PACKAGE = \"@open-orchestra/opencode-orchestrator\";\n\nfunction isOrchestratorPlugin(entry: string): boolean {\n  const normalized = entry.toLowerCase();\n  if (normalized.includes(ORCHESTRATOR_PLUGIN_PACKAGE)) return true;\n  return ORCHESTRATOR_PLUGIN_SUFFIXES.some((suffix) => normalized.includes(suffix));\n}\n\nfunction normalizePlugins(value: unknown, dropOrchestrator: boolean): string[] {\n  if (!Array.isArray(value)) return [];\n  return value\n    .filter((entry) => typeof entry === \"string\")\n    .filter((entry) => {\n      if (!dropOrchestrator) return true;\n      return !isOrchestratorPlugin(entry);\n    });\n}\n\nfunction mergePlugins(\n  base: unknown,\n  override: unknown,\n  options?: { dropOrchestrator?: boolean; append?: string[] },\n): string[] {\n  const dropOrchestrator = options?.dropOrchestrator ?? false;\n  const baseList = normalizePlugins(base, dropOrchestrator);\n  const overrideList = normalizePlugins(override, dropOrchestrator);\n  const appendList = normalizePlugins(options?.append, dropOrchestrator);\n  const merged = [...baseList, ...overrideList, ...appendList];\n  return [...new Set(merged)];\n}\n\nexport async function loadOpenCodeConfig(): Promise<Record<string, unknown>> {\n  const configPath = join(getUserConfigDir(), \"opencode\", \"opencode.json\");\n  if (!existsSync(configPath)) return {};\n  try {\n    const raw = await readFile(configPath, \"utf8\");\n    const parsed = JSON.parse(raw) as unknown;\n    return isPlainObject(parsed) ? parsed : {};\n  } catch {\n    return {};\n  }\n}\n\nexport function extractIntegrationsFromOpenCodeConfig(\n  config: Record<string, unknown>,\n): Record<string, unknown> | undefined {\n  if (!isPlainObject(config.integrations)) return undefined;\n  return config.integrations as Record<string, unknown>;\n}\n\nexport async function mergeOpenCodeConfig(\n  override?: Record<string, unknown>,\n  options?: { dropOrchestratorPlugin?: boolean; appendPlugins?: string[]; baseConfig?: unknown },\n): Promise<Record<string, unknown>> {\n  const base = options?.baseConfig ?? (await loadOpenCodeConfig());\n  const baseRecord = isPlainObject(base) ? base : undefined;\n  if (!override || Object.keys(override).length === 0) {\n    if (options?.dropOrchestratorPlugin || (options?.appendPlugins?.length ?? 0) > 0) {\n      const merged = baseRecord ? { ...baseRecord } : {};\n      merged.plugin = mergePlugins(baseRecord?.plugin, undefined, {\n        dropOrchestrator: options?.dropOrchestratorPlugin,\n        append: options?.appendPlugins,\n      });\n      return merged;\n    }\n    return baseRecord ? baseRecord : {};\n  }\n  if (!baseRecord) {\n    const merged = { ...override };\n    merged.plugin = mergePlugins(undefined, override?.plugin, {\n      dropOrchestrator: options?.dropOrchestratorPlugin,\n      append: options?.appendPlugins,\n    });\n    return merged;\n  }\n  const merged = deepMerge(baseRecord, override);\n  merged.plugin = mergePlugins(baseRecord?.plugin, override?.plugin, {\n    dropOrchestrator: options?.dropOrchestratorPlugin,\n    append: options?.appendPlugins,\n  });\n  return merged;\n}\n"
  },
  {
    "path": "config/orchestrator.ts",
    "content": "import { existsSync } from \"node:fs\";\nimport { readFile } from \"node:fs/promises\";\nimport { join } from \"node:path\";\nimport { canAutoSpawn, canSpawnOnDemand, canWarmPool } from \"../core/spawn-policy\";\nimport { deepMerge } from \"../helpers/format\";\nimport type { OrchestratorConfig, OrchestratorConfigFile } from \"../types\";\nimport { extractIntegrationsFromOpenCodeConfig, loadOpenCodeConfig } from \"./opencode\";\nimport { buildDefaultOrchestratorConfigFile } from \"./orchestrator/defaults\";\nimport { collectProfilesAndSpawn, parseOrchestratorConfigFile } from \"./orchestrator/parse\";\nimport {\n  getDefaultGlobalOpenCodeConfigPath,\n  getDefaultGlobalOrchestratorConfigPath,\n  getDefaultProjectOrchestratorConfigPath,\n} from \"./orchestrator/paths\";\n\nconst mergeOpenCodeIntegrations = (\n  defaults: Record<string, unknown> | undefined,\n  openCode: Record<string, unknown> | undefined,\n  orchestrator: Record<string, unknown> | undefined,\n): Record<string, unknown> => {\n  const base = defaults ?? {};\n  const mergedOpenCode = openCode ? deepMerge(base, openCode) : base;\n  return orchestrator ? deepMerge(mergedOpenCode, orchestrator) : mergedOpenCode;\n};\n\nexport type LoadedOrchestratorConfig = {\n  config: OrchestratorConfig;\n  sources: { global?: string; project?: string };\n};\n\nexport {\n  getDefaultGlobalOrchestratorConfigPath,\n  getDefaultGlobalOpenCodeConfigPath,\n  getDefaultProjectOrchestratorConfigPath,\n};\n\nexport async function loadOrchestratorConfig(input: {\n  directory: string;\n  worktree?: string;\n}): Promise<LoadedOrchestratorConfig> {\n  const defaultsFile = buildDefaultOrchestratorConfigFile();\n\n  const globalPath = getDefaultGlobalOrchestratorConfigPath();\n  const projectCandidates = [\n    getDefaultProjectOrchestratorConfigPath(input.directory),\n    input.worktree ? getDefaultProjectOrchestratorConfigPath(input.worktree) : undefined,\n    // Fallback to orchestra/ subdirectory (for monorepo development setups)\n    join(input.directory, \"orchestra\", \".opencode\", \"orchestrator.json\"),\n    input.worktree ? join(input.worktree, \"orchestra\", \".opencode\", \"orchestrator.json\") : undefined,\n    join(input.directory, \"orchestrator.json\"),\n    input.worktree ? join(input.worktree, \"orchestrator.json\") : undefined,\n  ].filter(Boolean) as string[];\n\n  const sources: LoadedOrchestratorConfig[\"sources\"] = {};\n\n  const globalPartial = await (async () => {\n    if (!existsSync(globalPath)) return {};\n    sources.global = globalPath;\n    try {\n      const raw = JSON.parse(await readFile(globalPath, \"utf8\")) as unknown;\n      return parseOrchestratorConfigFile(raw);\n    } catch {\n      return {};\n    }\n  })();\n\n  const projectPath = projectCandidates.find((p) => existsSync(p));\n  const projectPartial = await (async () => {\n    if (!projectPath) return {};\n    sources.project = projectPath;\n    try {\n      const raw = JSON.parse(await readFile(projectPath, \"utf8\")) as unknown;\n      return parseOrchestratorConfigFile(raw);\n    } catch {\n      return {};\n    }\n  })();\n\n  const openCodeConfig = await loadOpenCodeConfig();\n  const openCodeIntegrations = extractIntegrationsFromOpenCodeConfig(openCodeConfig);\n\n  const mergedFile = deepMerge(\n    deepMerge(defaultsFile as unknown as Record<string, unknown>, globalPartial as unknown as Record<string, unknown>),\n    projectPartial as unknown as Record<string, unknown>,\n  ) as unknown as OrchestratorConfigFile;\n  const orchestratorIntegrations = deepMerge(\n    (globalPartial.integrations ?? {}) as Record<string, unknown>,\n    (projectPartial.integrations ?? {}) as Record<string, unknown>,\n  );\n  const mergedIntegrations = mergeOpenCodeIntegrations(\n    defaultsFile.integrations as Record<string, unknown> | undefined,\n    openCodeIntegrations,\n    orchestratorIntegrations,\n  );\n\n  const { profiles, spawn } = collectProfilesAndSpawn(mergedFile);\n  const spawnPolicy = (mergedFile.spawnPolicy ?? defaultsFile.spawnPolicy) as OrchestratorConfig[\"spawnPolicy\"];\n  const spawnList = spawn.filter((id) => canAutoSpawn(spawnPolicy, id));\n  const spawnOnDemand = (mergedFile.spawnOnDemand ?? defaultsFile.spawnOnDemand ?? []).filter((id) =>\n    canSpawnOnDemand(spawnPolicy, id),\n  );\n\n  const warmPool = (() => {\n    const base = (mergedFile.warmPool ?? defaultsFile.warmPool) as OrchestratorConfig[\"warmPool\"];\n    if (!base?.profiles) return base;\n    const nextProfiles: Record<string, { size?: number; idleTimeoutMs?: number }> = {};\n    for (const [id, cfg] of Object.entries(base.profiles)) {\n      if (!canWarmPool(spawnPolicy, id)) continue;\n      nextProfiles[id] = cfg ?? {};\n    }\n    return { ...base, profiles: nextProfiles };\n  })();\n\n  const config: OrchestratorConfig = {\n    basePort: mergedFile.basePort ?? defaultsFile.basePort ?? 14096,\n    autoSpawn: mergedFile.autoSpawn ?? defaultsFile.autoSpawn ?? false,\n    spawnOnDemand,\n    spawnPolicy,\n    startupTimeout: mergedFile.startupTimeout ?? defaultsFile.startupTimeout ?? 30000,\n    healthCheckInterval: mergedFile.healthCheckInterval ?? defaultsFile.healthCheckInterval ?? 30000,\n    healthCheck: (mergedFile.healthCheck ?? defaultsFile.healthCheck) as OrchestratorConfig[\"healthCheck\"],\n    warmPool,\n    modelSelection: (mergedFile.modelSelection ?? defaultsFile.modelSelection) as OrchestratorConfig[\"modelSelection\"],\n    modelAliases: (mergedFile.modelAliases ?? defaultsFile.modelAliases) as OrchestratorConfig[\"modelAliases\"],\n    ui: (mergedFile.ui ?? defaultsFile.ui) as OrchestratorConfig[\"ui\"],\n    notifications: (mergedFile.notifications ?? defaultsFile.notifications) as OrchestratorConfig[\"notifications\"],\n    agent: (mergedFile.agent ?? defaultsFile.agent) as OrchestratorConfig[\"agent\"],\n    commands: (mergedFile.commands ?? defaultsFile.commands) as OrchestratorConfig[\"commands\"],\n    pruning: (mergedFile.pruning ?? defaultsFile.pruning) as OrchestratorConfig[\"pruning\"],\n    workflows: (mergedFile.workflows ?? defaultsFile.workflows) as OrchestratorConfig[\"workflows\"],\n    security: (mergedFile.security ?? defaultsFile.security) as OrchestratorConfig[\"security\"],\n    memory: (mergedFile.memory ?? defaultsFile.memory) as OrchestratorConfig[\"memory\"],\n    integrations: mergedIntegrations as OrchestratorConfig[\"integrations\"],\n    telemetry: (mergedFile.telemetry ?? defaultsFile.telemetry) as OrchestratorConfig[\"telemetry\"],\n    profiles,\n    spawn: spawnList,\n  };\n\n  return { config: applyEnvOverrides(config), sources };\n}\n\nfunction parseBoolean(value: string | undefined): boolean | undefined {\n  if (!value) return undefined;\n  const normalized = value.trim().toLowerCase();\n  if ([\"1\", \"true\", \"yes\", \"on\"].includes(normalized)) return true;\n  if ([\"0\", \"false\", \"no\", \"off\"].includes(normalized)) return false;\n  return undefined;\n}\n\nfunction parseNumber(value: string | undefined): number | undefined {\n  if (!value) return undefined;\n  const parsed = Number(value);\n  return Number.isFinite(parsed) ? parsed : undefined;\n}\n\nfunction parseList(value: string | undefined): string[] | undefined {\n  if (!value) return undefined;\n  const items = value\n    .split(\",\")\n    .map((entry) => entry.trim())\n    .filter(Boolean);\n  return items.length > 0 ? items : [];\n}\n\nfunction applyEnvOverrides(config: OrchestratorConfig): OrchestratorConfig {\n  const autoSpawn = parseBoolean(process.env.OPENCODE_ORCH_AUTO_SPAWN);\n  const spawnOnDemand = parseList(process.env.OPENCODE_ORCH_SPAWN_ON_DEMAND);\n  const basePort = parseNumber(process.env.OPENCODE_ORCH_BASE_PORT);\n  const startupTimeout = parseNumber(process.env.OPENCODE_ORCH_STARTUP_TIMEOUT_MS);\n  const healthCheckInterval = parseNumber(process.env.OPENCODE_ORCH_HEALTH_INTERVAL_MS);\n\n  const commandsEnabled = parseBoolean(process.env.OPENCODE_ORCH_COMMANDS);\n  const commandPrefix = process.env.OPENCODE_ORCH_COMMAND_PREFIX?.trim();\n\n  const uiToasts = parseBoolean(process.env.OPENCODE_ORCH_UI_TOASTS);\n  const uiWakeup = parseBoolean(process.env.OPENCODE_ORCH_UI_WAKEUP);\n  const uiFirstRunDemo = parseBoolean(process.env.OPENCODE_ORCH_UI_FIRST_RUN_DEMO);\n\n  const memoryEnabled = parseBoolean(process.env.OPENCODE_ORCH_MEMORY);\n  const workflowsEnabled = parseBoolean(process.env.OPENCODE_ORCH_WORKFLOWS);\n  const pruningEnabled = parseBoolean(process.env.OPENCODE_ORCH_PRUNING);\n  const telemetryEnabled = parseBoolean(process.env.OPENCODE_ORCH_TELEMETRY);\n\n  return {\n    ...config,\n    ...(autoSpawn !== undefined ? { autoSpawn } : {}),\n    ...(spawnOnDemand !== undefined ? { spawnOnDemand } : {}),\n    ...(basePort !== undefined ? { basePort } : {}),\n    ...(startupTimeout !== undefined ? { startupTimeout } : {}),\n    ...(healthCheckInterval !== undefined ? { healthCheckInterval } : {}),\n    ...(commandsEnabled !== undefined || commandPrefix\n      ? {\n          commands: {\n            ...config.commands,\n            ...(commandsEnabled !== undefined ? { enabled: commandsEnabled } : {}),\n            ...(commandPrefix ? { prefix: commandPrefix } : {}),\n          },\n        }\n      : {}),\n    ...(uiToasts !== undefined || uiWakeup !== undefined || uiFirstRunDemo !== undefined\n      ? {\n          ui: {\n            ...config.ui,\n            ...(uiToasts !== undefined ? { toasts: uiToasts } : {}),\n            ...(uiWakeup !== undefined ? { wakeupInjection: uiWakeup } : {}),\n            ...(uiFirstRunDemo !== undefined ? { firstRunDemo: uiFirstRunDemo } : {}),\n          },\n        }\n      : {}),\n    ...(memoryEnabled !== undefined\n      ? { memory: { ...config.memory, enabled: memoryEnabled } }\n      : {}),\n    ...(workflowsEnabled !== undefined\n      ? { workflows: { ...config.workflows, enabled: workflowsEnabled } }\n      : {}),\n    ...(pruningEnabled !== undefined ? { pruning: { ...config.pruning, enabled: pruningEnabled } } : {}),\n    ...(telemetryEnabled !== undefined ? { telemetry: { ...config.telemetry, enabled: telemetryEnabled } } : {}),\n  };\n}\n"
  },
  {
    "path": "config/orchestrator/defaults.ts",
    "content": "import type { OrchestratorConfigFile } from \"../../types\";\n\nexport function buildDefaultOrchestratorConfigFile(): OrchestratorConfigFile {\n  return {\n    basePort: 14096,\n    autoSpawn: false, // Workers spawn on-demand, not automatically\n    spawnOnDemand: [\"vision\"],\n    spawnPolicy: {\n      default: {\n        autoSpawn: false, // Don't auto-spawn on plugin init\n        onDemand: true, // Allow on-demand spawning via tools\n        allowManual: true,\n        warmPool: false, // Don't pre-warm workers\n        reuseExisting: true,\n      },\n      profiles: {},\n    },\n    startupTimeout: 30000,\n    healthCheckInterval: 30000,\n    healthCheck: {\n      enabled: true,\n      intervalMs: 30000,\n      timeoutMs: 3000,\n      maxRetries: 3,\n    },\n    warmPool: {\n      enabled: false,\n      profiles: {},\n    },\n    modelSelection: {\n      mode: \"performance\",\n    },\n    modelAliases: {},\n    ui: {\n      toasts: true,\n      injectSystemContext: true,\n      systemContextMaxWorkers: 12,\n      defaultListFormat: \"markdown\",\n      debug: false,\n      logToConsole: false,\n      firstRunDemo: true,\n    },\n    notifications: {\n      idle: { enabled: false, title: \"OpenCode\", message: \"Session is idle\", delayMs: 1500 },\n    },\n    agent: {\n      enabled: true,\n      name: \"orchestrator\",\n      mode: \"primary\",\n      applyToBuild: false,\n    },\n    commands: { enabled: true, prefix: \"orchestrator.\" },\n    pruning: {\n      enabled: false,\n      maxToolOutputChars: 12000,\n      maxToolInputChars: 4000,\n      protectedTools: [\"task\", \"todowrite\", \"todoread\"],\n    },\n    workflows: {\n      enabled: true,\n      roocodeBoomerang: {\n        enabled: true,\n        maxSteps: 4,\n        maxTaskChars: 12000,\n        maxCarryChars: 24000,\n        perStepTimeoutMs: 120_000,\n      },\n    },\n    security: {\n      workflows: {\n        maxSteps: 4,\n        maxTaskChars: 12000,\n        maxCarryChars: 24000,\n        perStepTimeoutMs: 120_000,\n      },\n    },\n    memory: {\n      enabled: true,\n      autoSpawn: true,\n      autoRecord: true,\n      autoInject: true,\n      scope: \"project\",\n      maxChars: 2000,\n      summaries: {\n        enabled: true,\n        sessionMaxChars: 2000,\n        projectMaxChars: 2000,\n      },\n      trim: {\n        maxMessagesPerSession: 60,\n        maxMessagesPerProject: 400,\n        maxMessagesGlobal: 2000,\n        maxProjectsGlobal: 25,\n      },\n      inject: {\n        maxChars: 2000,\n        maxEntries: 8,\n        includeMessages: false,\n        includeSessionSummary: true,\n        includeProjectSummary: true,\n        includeGlobal: true,\n        maxGlobalEntries: 3,\n      },\n    },\n    integrations: {\n      linear: { enabled: true },\n      neo4j: { enabled: false },\n      monitoring: { enabled: false },\n    },\n    telemetry: {\n      enabled: false,\n    },\n    profiles: [\n      {\n        id: \"glm47-vision-demo\",\n        name: \"GLM-4.7 Vision Demo\",\n        model: \"zhipu/glm-4.7v\",\n        purpose: \"Multimodal onboarding demo (vision + workflow).\",\n        whenToUse: \"Use for the onboarding multimodal demo flow.\",\n        supportsVision: true,\n        enabled: true,\n      },\n    ],\n    workers: [], // No auto-spawn - orchestrator decides when to spawn workers\n  };\n}\n"
  },
  {
    "path": "config/orchestrator/parse-extra.ts",
    "content": "import { isPlainObject } from \"../../helpers/format\";\nimport type { OrchestratorConfig, OrchestratorConfigFile } from \"../../types\";\n\n/**\n * Schema field definition for validation.\n * Each field specifies its expected type and optional allowed values for enums.\n */\ntype FieldSchema =\n  | { type: \"boolean\" }\n  | { type: \"string\" }\n  | { type: \"number\" }\n  | { type: \"enum\"; values: readonly string[] };\n\n/**\n * Schema definition for an object with optional nested objects.\n */\ntype ObjectSchema = {\n  fields?: Record<string, FieldSchema>;\n  nested?: Record<string, ObjectSchema>;\n};\n\n/**\n * Validates and extracts fields from a source object based on a schema definition.\n * Only copies values that match the expected type.\n *\n * @param source - The source object to extract values from\n * @param schema - The schema defining expected fields and nested objects\n * @returns A validated object with only the fields that passed type checks\n */\nfunction validateObject(source: Record<string, unknown>, schema: ObjectSchema): Record<string, unknown> {\n  const result: Record<string, unknown> = {};\n\n  // Validate simple fields\n  if (schema.fields) {\n    for (const [key, fieldSchema] of Object.entries(schema.fields)) {\n      const value = source[key];\n\n      if (fieldSchema.type === \"boolean\" && typeof value === \"boolean\") {\n        result[key] = value;\n      } else if (fieldSchema.type === \"string\" && typeof value === \"string\") {\n        result[key] = value;\n      } else if (fieldSchema.type === \"number\" && typeof value === \"number\") {\n        result[key] = value;\n      } else if (fieldSchema.type === \"enum\" && fieldSchema.values.includes(value as string)) {\n        result[key] = value;\n      }\n    }\n  }\n\n  // Validate nested objects\n  if (schema.nested) {\n    for (const [key, nestedSchema] of Object.entries(schema.nested)) {\n      if (isPlainObject(source[key])) {\n        const nestedResult = validateObject(source[key], nestedSchema);\n        if (Object.keys(nestedResult).length > 0) {\n          result[key] = nestedResult;\n        }\n      }\n    }\n  }\n\n  return result;\n}\n\n// Schema definitions for each section\n\nconst memorySchema: ObjectSchema = {\n  fields: {\n    enabled: { type: \"boolean\" },\n    autoSpawn: { type: \"boolean\" },\n    autoRecord: { type: \"boolean\" },\n    autoInject: { type: \"boolean\" },\n    scope: { type: \"enum\", values: [\"project\", \"global\"] as const },\n    maxChars: { type: \"number\" },\n  },\n  nested: {\n    summaries: {\n      fields: {\n        enabled: { type: \"boolean\" },\n        sessionMaxChars: { type: \"number\" },\n        projectMaxChars: { type: \"number\" },\n      },\n    },\n    trim: {\n      fields: {\n        maxMessagesPerSession: { type: \"number\" },\n        maxMessagesPerProject: { type: \"number\" },\n        maxMessagesGlobal: { type: \"number\" },\n        maxProjectsGlobal: { type: \"number\" },\n      },\n    },\n    inject: {\n      fields: {\n        maxChars: { type: \"number\" },\n        maxEntries: { type: \"number\" },\n        includeMessages: { type: \"boolean\" },\n        includeSessionSummary: { type: \"boolean\" },\n        includeProjectSummary: { type: \"boolean\" },\n        includeGlobal: { type: \"boolean\" },\n        maxGlobalEntries: { type: \"number\" },\n      },\n    },\n  },\n};\n\nconst integrationsSchema: ObjectSchema = {\n  nested: {\n    linear: {\n      fields: {\n        enabled: { type: \"boolean\" },\n        apiKey: { type: \"string\" },\n        teamId: { type: \"string\" },\n        apiUrl: { type: \"string\" },\n        projectPrefix: { type: \"string\" },\n      },\n    },\n    neo4j: {\n      fields: {\n        enabled: { type: \"boolean\" },\n        uri: { type: \"string\" },\n        username: { type: \"string\" },\n        password: { type: \"string\" },\n        database: { type: \"string\" },\n      },\n    },\n    monitoring: {\n      fields: {\n        enabled: { type: \"boolean\" },\n        port: { type: \"number\" },\n        metricsPath: { type: \"string\" },\n      },\n    },\n  },\n};\n\nconst telemetrySchema: ObjectSchema = {\n  fields: {\n    enabled: { type: \"boolean\" },\n    apiKey: { type: \"string\" },\n    host: { type: \"string\" },\n  },\n};\n\n// Exported functions using the generic validation helpers\n\nexport function parseMemorySection(raw: Record<string, unknown>, partial: Partial<OrchestratorConfigFile>): void {\n  if (!isPlainObject(raw.memory)) return;\n  partial.memory = validateObject(raw.memory, memorySchema) as OrchestratorConfig[\"memory\"];\n}\n\nexport function parseIntegrationsSection(raw: Record<string, unknown>, partial: Partial<OrchestratorConfigFile>): void {\n  if (!isPlainObject(raw.integrations)) return;\n  const validated = validateObject(raw.integrations, integrationsSchema) as Record<string, unknown>;\n  const passthrough = raw.integrations as Record<string, unknown>;\n  const knownKeys = new Set(Object.keys(integrationsSchema.nested ?? {}));\n  for (const [key, value] of Object.entries(passthrough)) {\n    if (!knownKeys.has(key)) {\n      validated[key] = value;\n    }\n  }\n  partial.integrations = validated as OrchestratorConfig[\"integrations\"];\n}\n\nexport function parseTelemetrySection(raw: Record<string, unknown>, partial: Partial<OrchestratorConfigFile>): void {\n  if (!isPlainObject(raw.telemetry)) return;\n  partial.telemetry = validateObject(raw.telemetry, telemetrySchema) as OrchestratorConfig[\"telemetry\"];\n}\n"
  },
  {
    "path": "config/orchestrator/parse-workers.ts",
    "content": "import { asBooleanRecord, asStringArray, isPlainObject } from \"../../helpers/format\";\nimport type { OrchestratorConfigFile, SpawnPolicy, ToolPermissions, WorkerProfile } from \"../../types\";\nimport { resolveProfileInheritance, type WorkerProfileDefinition } from \"../profile-inheritance\";\n\nconst parsePermissions = (value: unknown): ToolPermissions | undefined => {\n  if (!isPlainObject(value)) return undefined;\n  const out: ToolPermissions = {};\n  if (isPlainObject(value.categories)) {\n    out.categories = {};\n    if (\n      value.categories.filesystem === \"full\" ||\n      value.categories.filesystem === \"read\" ||\n      value.categories.filesystem === \"none\"\n    ) {\n      out.categories.filesystem = value.categories.filesystem;\n    }\n    if (\n      value.categories.execution === \"full\" ||\n      value.categories.execution === \"sandboxed\" ||\n      value.categories.execution === \"none\"\n    ) {\n      out.categories.execution = value.categories.execution;\n    }\n    if (\n      value.categories.network === \"full\" ||\n      value.categories.network === \"localhost\" ||\n      value.categories.network === \"none\"\n    ) {\n      out.categories.network = value.categories.network;\n    }\n  }\n  if (isPlainObject(value.tools)) {\n    out.tools = {};\n    for (const [toolName, cfg] of Object.entries(value.tools)) {\n      if (!isPlainObject(cfg)) continue;\n      if (typeof cfg.enabled !== \"boolean\") continue;\n      out.tools[toolName] = {\n        enabled: cfg.enabled,\n        constraints: isPlainObject(cfg.constraints) ? cfg.constraints : undefined,\n      };\n    }\n  }\n  if (isPlainObject(value.paths)) {\n    const allowed = asStringArray(value.paths.allowed);\n    const denied = asStringArray(value.paths.denied);\n    if (allowed || denied) out.paths = { allowed: allowed ?? undefined, denied: denied ?? undefined };\n  }\n  return out;\n};\n\n/** Parse a spawn policy object from config. */\nexport const parseSpawnPolicyEntry = (value: unknown): SpawnPolicy | undefined => {\n  if (!isPlainObject(value)) return undefined;\n  const out: SpawnPolicy = {};\n  if (typeof value.autoSpawn === \"boolean\") out.autoSpawn = value.autoSpawn;\n  if (typeof value.onDemand === \"boolean\") out.onDemand = value.onDemand;\n  if (typeof value.allowManual === \"boolean\") out.allowManual = value.allowManual;\n  if (typeof value.warmPool === \"boolean\") out.warmPool = value.warmPool;\n  if (typeof value.reuseExisting === \"boolean\") out.reuseExisting = value.reuseExisting;\n  return out;\n};\n\nconst resolveWorkerEntry = (\n  entry: unknown,\n  baseProfiles: Record<string, WorkerProfile> = {},\n): WorkerProfileDefinition | undefined => {\n  if (typeof entry === \"string\") {\n    return baseProfiles[entry] ?? ({ id: entry } as WorkerProfileDefinition);\n  }\n  if (!isPlainObject(entry)) return undefined;\n\n  const id = typeof entry.id === \"string\" ? entry.id : undefined;\n  if (!id) return undefined;\n\n  const base = baseProfiles[id];\n  const merged: Record<string, unknown> = { ...(base ?? {}), ...entry };\n\n  if (typeof merged.id !== \"string\") return undefined;\n\n  if (\"tools\" in merged) {\n    const tools = asBooleanRecord(merged.tools);\n    if (!tools) return undefined;\n    merged.tools = tools;\n  }\n\n  if (\"tags\" in merged) {\n    const tags = asStringArray(merged.tags);\n    if (!tags) return undefined;\n    merged.tags = tags;\n  }\n\n  if (\"permissions\" in merged) {\n    merged.permissions = parsePermissions(merged.permissions);\n  }\n\n  if (\"extends\" in merged && typeof merged.extends !== \"string\") delete merged.extends;\n  if (\"compose\" in merged) {\n    const compose = asStringArray(merged.compose);\n    merged.compose = compose;\n  }\n\n  return merged as unknown as WorkerProfileDefinition;\n};\n\n/** Normalize config arrays to a string or object list. */\nexport const asConfigArray = (value: unknown): Array<string | Record<string, unknown>> | undefined => {\n  if (!Array.isArray(value)) return undefined;\n  const out: Array<string | Record<string, unknown>> = [];\n  for (const item of value) {\n    if (typeof item === \"string\") out.push(item);\n    else if (isPlainObject(item)) out.push(item);\n  }\n  return out;\n};\n\n/** Resolve profile overrides and spawn targets from orchestrator config. */\nexport const collectProfilesAndSpawn = (\n  input: OrchestratorConfigFile,\n  baseProfiles: Record<string, WorkerProfile> = {},\n): {\n  profiles: Record<string, WorkerProfile>;\n  spawn: string[];\n} => {\n  const definitions: Record<string, WorkerProfileDefinition> = {};\n  const spawn: string[] = [];\n  const seen = new Set<string>();\n\n  const registerProfile = (entry: unknown): WorkerProfileDefinition | undefined => {\n    const resolved = resolveWorkerEntry(entry, baseProfiles);\n    if (resolved) definitions[resolved.id] = resolved;\n    return resolved;\n  };\n\n  const enqueueSpawn = (id: string | undefined) => {\n    if (!id) return;\n    if (seen.has(id)) return;\n    seen.add(id);\n    spawn.push(id);\n  };\n\n  for (const entry of input.profiles ?? []) {\n    registerProfile(entry);\n  }\n\n  for (const entry of input.workers ?? []) {\n    if (typeof entry === \"string\") {\n      enqueueSpawn(entry);\n      continue;\n    }\n    const resolved = registerProfile(entry);\n    enqueueSpawn(resolved?.id);\n  }\n\n  const profiles = resolveProfileInheritance({ builtIns: baseProfiles, definitions });\n  return { profiles, spawn };\n};\n"
  },
  {
    "path": "config/orchestrator/parse.ts",
    "content": "import { isPlainObject } from \"../../helpers/format\";\nimport type { OrchestratorConfig, OrchestratorConfigFile, SpawnPolicy } from \"../../types\";\nimport { parseIntegrationsSection, parseMemorySection, parseTelemetrySection } from \"./parse-extra\";\nimport { asConfigArray, parseSpawnPolicyEntry } from \"./parse-workers\";\n\nexport { collectProfilesAndSpawn } from \"./parse-workers\";\n\n/** Parse orchestrator.json into a partial typed config. */\nexport function parseOrchestratorConfigFile(raw: unknown): Partial<OrchestratorConfigFile> {\n  if (!isPlainObject(raw)) return {};\n\n  const partial: Partial<OrchestratorConfigFile> = {};\n\n  if (typeof raw.basePort === \"number\") partial.basePort = raw.basePort;\n  if (typeof raw.autoSpawn === \"boolean\") partial.autoSpawn = raw.autoSpawn;\n  if (Array.isArray(raw.spawnOnDemand) && raw.spawnOnDemand.every((id: unknown) => typeof id === \"string\")) {\n    partial.spawnOnDemand = raw.spawnOnDemand;\n  }\n  if (isPlainObject(raw.spawnPolicy)) {\n    const spawnPolicy: Record<string, unknown> = {};\n    if (isPlainObject(raw.spawnPolicy.default)) {\n      const parsed = parseSpawnPolicyEntry(raw.spawnPolicy.default);\n      if (parsed) spawnPolicy.default = parsed;\n    }\n    if (isPlainObject(raw.spawnPolicy.profiles)) {\n      const profiles: Record<string, SpawnPolicy> = {};\n      for (const [id, cfg] of Object.entries(raw.spawnPolicy.profiles)) {\n        const parsed = parseSpawnPolicyEntry(cfg);\n        if (parsed) profiles[id] = parsed;\n      }\n      spawnPolicy.profiles = profiles;\n    }\n    partial.spawnPolicy = spawnPolicy as OrchestratorConfig[\"spawnPolicy\"];\n  }\n  if (typeof raw.startupTimeout === \"number\") partial.startupTimeout = raw.startupTimeout;\n  if (typeof raw.healthCheckInterval === \"number\") partial.healthCheckInterval = raw.healthCheckInterval;\n  if (isPlainObject(raw.healthCheck)) {\n    const healthCheck: Record<string, unknown> = {};\n    if (typeof raw.healthCheck.enabled === \"boolean\") healthCheck.enabled = raw.healthCheck.enabled;\n    if (typeof raw.healthCheck.intervalMs === \"number\") healthCheck.intervalMs = raw.healthCheck.intervalMs;\n    if (typeof raw.healthCheck.timeoutMs === \"number\") healthCheck.timeoutMs = raw.healthCheck.timeoutMs;\n    if (typeof raw.healthCheck.maxRetries === \"number\") healthCheck.maxRetries = raw.healthCheck.maxRetries;\n    partial.healthCheck = healthCheck as OrchestratorConfig[\"healthCheck\"];\n  }\n\n  if (isPlainObject(raw.warmPool)) {\n    const warmPool: Record<string, unknown> = {};\n    if (typeof raw.warmPool.enabled === \"boolean\") warmPool.enabled = raw.warmPool.enabled;\n    if (isPlainObject(raw.warmPool.profiles)) {\n      const profiles: Record<string, unknown> = {};\n      for (const [id, cfg] of Object.entries(raw.warmPool.profiles)) {\n        if (!isPlainObject(cfg)) continue;\n        const entry: Record<string, unknown> = {};\n        if (typeof cfg.size === \"number\") entry.size = cfg.size;\n        if (typeof cfg.idleTimeoutMs === \"number\") entry.idleTimeoutMs = cfg.idleTimeoutMs;\n        profiles[id] = entry;\n      }\n      warmPool.profiles = profiles;\n    }\n    partial.warmPool = warmPool as OrchestratorConfig[\"warmPool\"];\n  }\n\n  if (isPlainObject(raw.modelSelection)) {\n    const modelSelection: Record<string, unknown> = {};\n    if (\n      raw.modelSelection.mode === \"performance\" ||\n      raw.modelSelection.mode === \"balanced\" ||\n      raw.modelSelection.mode === \"economical\"\n    ) {\n      modelSelection.mode = raw.modelSelection.mode;\n    }\n    if (typeof raw.modelSelection.maxCostPer1kTokens === \"number\")\n      modelSelection.maxCostPer1kTokens = raw.modelSelection.maxCostPer1kTokens;\n    if (\n      Array.isArray(raw.modelSelection.preferredProviders) &&\n      raw.modelSelection.preferredProviders.every((p: unknown) => typeof p === \"string\")\n    ) {\n      modelSelection.preferredProviders = raw.modelSelection.preferredProviders;\n    }\n    partial.modelSelection = modelSelection as OrchestratorConfig[\"modelSelection\"];\n  }\n\n  if (isPlainObject(raw.modelAliases)) {\n    const modelAliases: Record<string, string> = {};\n    for (const [key, value] of Object.entries(raw.modelAliases)) {\n      if (typeof value === \"string\") modelAliases[key] = value;\n    }\n    partial.modelAliases = modelAliases;\n  }\n\n  if (\"profiles\" in raw) {\n    const profiles = asConfigArray(raw.profiles);\n    // profiles is Array<string | Record<string, unknown>> which matches OrchestratorConfigFile[\"profiles\"]\n    if (profiles) partial.profiles = profiles as OrchestratorConfigFile[\"profiles\"];\n  }\n\n  if (\"workers\" in raw) {\n    const workers = asConfigArray(raw.workers);\n    // workers is Array<string | Record<string, unknown>> which matches OrchestratorConfigFile[\"workers\"]\n    if (workers) partial.workers = workers as OrchestratorConfigFile[\"workers\"];\n  }\n\n  if (isPlainObject(raw.ui)) {\n    const ui: Record<string, unknown> = {};\n    if (typeof raw.ui.toasts === \"boolean\") ui.toasts = raw.ui.toasts;\n    if (typeof raw.ui.injectSystemContext === \"boolean\") ui.injectSystemContext = raw.ui.injectSystemContext;\n    if (typeof raw.ui.systemContextMaxWorkers === \"number\") ui.systemContextMaxWorkers = raw.ui.systemContextMaxWorkers;\n    if (raw.ui.defaultListFormat === \"markdown\" || raw.ui.defaultListFormat === \"json\") {\n      ui.defaultListFormat = raw.ui.defaultListFormat;\n    }\n    if (typeof raw.ui.debug === \"boolean\") ui.debug = raw.ui.debug;\n    if (typeof raw.ui.logToConsole === \"boolean\") ui.logToConsole = raw.ui.logToConsole;\n    if (typeof raw.ui.firstRunDemo === \"boolean\") ui.firstRunDemo = raw.ui.firstRunDemo;\n    if (typeof raw.ui.wakeupInjection === \"boolean\") ui.wakeupInjection = raw.ui.wakeupInjection;\n    partial.ui = ui as OrchestratorConfig[\"ui\"];\n  }\n\n  if (isPlainObject(raw.notifications) && isPlainObject(raw.notifications.idle)) {\n    const idle: Record<string, unknown> = {};\n    if (typeof raw.notifications.idle.enabled === \"boolean\") idle.enabled = raw.notifications.idle.enabled;\n    if (typeof raw.notifications.idle.title === \"string\") idle.title = raw.notifications.idle.title;\n    if (typeof raw.notifications.idle.message === \"string\") idle.message = raw.notifications.idle.message;\n    if (typeof raw.notifications.idle.delayMs === \"number\") idle.delayMs = raw.notifications.idle.delayMs;\n    partial.notifications = { idle: idle as OrchestratorConfig[\"notifications\"] extends { idle: infer T } ? T : never };\n  }\n\n  if (isPlainObject(raw.agent)) {\n    const agent: Record<string, unknown> = {};\n    if (typeof raw.agent.enabled === \"boolean\") agent.enabled = raw.agent.enabled;\n    if (typeof raw.agent.name === \"string\") agent.name = raw.agent.name;\n    if (typeof raw.agent.model === \"string\") agent.model = raw.agent.model;\n    if (typeof raw.agent.prompt === \"string\") agent.prompt = raw.agent.prompt;\n    if (raw.agent.mode === \"primary\" || raw.agent.mode === \"subagent\") agent.mode = raw.agent.mode;\n    if (typeof raw.agent.color === \"string\") agent.color = raw.agent.color;\n    if (typeof raw.agent.applyToBuild === \"boolean\") agent.applyToBuild = raw.agent.applyToBuild;\n    partial.agent = agent as OrchestratorConfig[\"agent\"];\n  }\n\n  if (isPlainObject(raw.commands)) {\n    const commands: Record<string, unknown> = {};\n    if (typeof raw.commands.enabled === \"boolean\") commands.enabled = raw.commands.enabled;\n    if (typeof raw.commands.prefix === \"string\") commands.prefix = raw.commands.prefix;\n    partial.commands = commands as OrchestratorConfig[\"commands\"];\n  }\n\n  if (isPlainObject(raw.pruning)) {\n    const pruning: Record<string, unknown> = {};\n    if (typeof raw.pruning.enabled === \"boolean\") pruning.enabled = raw.pruning.enabled;\n    if (typeof raw.pruning.maxToolOutputChars === \"number\") pruning.maxToolOutputChars = raw.pruning.maxToolOutputChars;\n    if (typeof raw.pruning.maxToolInputChars === \"number\") pruning.maxToolInputChars = raw.pruning.maxToolInputChars;\n    if (\n      Array.isArray(raw.pruning.protectedTools) &&\n      raw.pruning.protectedTools.every((t: unknown) => typeof t === \"string\")\n    ) {\n      pruning.protectedTools = raw.pruning.protectedTools;\n    }\n    partial.pruning = pruning as OrchestratorConfig[\"pruning\"];\n  }\n\n  if (isPlainObject(raw.workflows)) {\n    const workflows: Record<string, unknown> = {};\n    if (typeof raw.workflows.enabled === \"boolean\") workflows.enabled = raw.workflows.enabled;\n    if (isPlainObject(raw.workflows.roocodeBoomerang)) {\n      const roocode: Record<string, unknown> = {};\n      if (typeof raw.workflows.roocodeBoomerang.enabled === \"boolean\")\n        roocode.enabled = raw.workflows.roocodeBoomerang.enabled;\n      if (typeof raw.workflows.roocodeBoomerang.maxSteps === \"number\")\n        roocode.maxSteps = raw.workflows.roocodeBoomerang.maxSteps;\n      if (typeof raw.workflows.roocodeBoomerang.maxTaskChars === \"number\")\n        roocode.maxTaskChars = raw.workflows.roocodeBoomerang.maxTaskChars;\n      if (typeof raw.workflows.roocodeBoomerang.maxCarryChars === \"number\")\n        roocode.maxCarryChars = raw.workflows.roocodeBoomerang.maxCarryChars;\n      if (typeof raw.workflows.roocodeBoomerang.perStepTimeoutMs === \"number\") {\n        roocode.perStepTimeoutMs = raw.workflows.roocodeBoomerang.perStepTimeoutMs;\n      }\n      if (Array.isArray(raw.workflows.roocodeBoomerang.steps)) {\n        const steps = raw.workflows.roocodeBoomerang.steps\n          .map((s: unknown) => {\n            if (!isPlainObject(s)) return undefined;\n            const id = typeof s.id === \"string\" ? s.id : undefined;\n            if (!id) return undefined;\n            const step: Record<string, unknown> = { id };\n            if (typeof s.title === \"string\") step.title = s.title;\n            if (typeof s.workerId === \"string\") step.workerId = s.workerId;\n            if (typeof s.prompt === \"string\") step.prompt = s.prompt;\n            if (typeof s.carry === \"boolean\") step.carry = s.carry;\n            return step;\n          })\n          .filter(Boolean);\n        if (steps.length > 0) roocode.steps = steps;\n      }\n      workflows.roocodeBoomerang = roocode;\n    }\n    partial.workflows = workflows as OrchestratorConfig[\"workflows\"];\n  }\n\n  if (isPlainObject(raw.security)) {\n    const security: Record<string, unknown> = {};\n    if (isPlainObject(raw.security.workflows)) {\n      const workflows: Record<string, unknown> = {};\n      if (typeof raw.security.workflows.maxSteps === \"number\") workflows.maxSteps = raw.security.workflows.maxSteps;\n      if (typeof raw.security.workflows.maxTaskChars === \"number\")\n        workflows.maxTaskChars = raw.security.workflows.maxTaskChars;\n      if (typeof raw.security.workflows.maxCarryChars === \"number\")\n        workflows.maxCarryChars = raw.security.workflows.maxCarryChars;\n      if (typeof raw.security.workflows.perStepTimeoutMs === \"number\") {\n        workflows.perStepTimeoutMs = raw.security.workflows.perStepTimeoutMs;\n      }\n      security.workflows = workflows;\n    }\n    partial.security = security as OrchestratorConfig[\"security\"];\n  }\n\n  parseMemorySection(raw, partial);\n  parseIntegrationsSection(raw, partial);\n  parseTelemetrySection(raw, partial);\n\n  return partial;\n}\n\n/**\n * Collect profile overrides and spawn list from orchestrator.json config.\n *\n * Profiles are now primarily loaded from SKILL.md files in .opencode/skill/.\n * This function processes config file overrides and determines which workers to spawn.\n *\n * @param input - Parsed orchestrator.json config\n * @param baseProfiles - Profiles loaded from SKILL.md files (optional, for merging)\n */\n"
  },
  {
    "path": "config/orchestrator/paths.ts",
    "content": "import { join } from \"node:path\";\nimport { getUserConfigDir } from \"../../helpers/format\";\n\nexport function getDefaultGlobalOrchestratorConfigPath(): string {\n  return join(getUserConfigDir(), \"opencode\", \"orchestrator.json\");\n}\n\nexport function getDefaultGlobalOpenCodeConfigPath(): string {\n  return join(getUserConfigDir(), \"opencode\", \"opencode.json\");\n}\n\nexport function getDefaultProjectOrchestratorConfigPath(directory: string): string {\n  return join(directory, \".opencode\", \"orchestrator.json\");\n}\n"
  },
  {
    "path": "config/profile-inheritance.ts",
    "content": "import { mergeToolPermissions } from \"../permissions/validator\";\nimport type { ToolPermissions, WorkerProfile } from \"../types\";\n\nexport type WorkerProfileDefinition = Partial<WorkerProfile> & {\n  id: string;\n  extends?: string;\n  compose?: string[];\n};\n\nfunction mergeTags(base?: string[], override?: string[]): string[] | undefined {\n  const merged = [...(base ?? []), ...(override ?? [])].filter((t) => typeof t === \"string\" && t.length > 0);\n  if (merged.length === 0) return undefined;\n  return Array.from(new Set(merged));\n}\n\nfunction mergeTools(\n  base?: Record<string, boolean>,\n  override?: Record<string, boolean>,\n): Record<string, boolean> | undefined {\n  if (!base && !override) return undefined;\n  return { ...(base ?? {}), ...(override ?? {}) };\n}\n\nfunction mergeProfiles(base: WorkerProfile, override: WorkerProfileDefinition): WorkerProfile {\n  return {\n    ...base,\n    ...override,\n    tools: mergeTools(base.tools, override.tools),\n    tags: mergeTags(base.tags, override.tags),\n    permissions: mergeToolPermissions(base.permissions, override.permissions as ToolPermissions | undefined),\n    id: override.id ?? base.id,\n  };\n}\n\nexport function resolveProfileInheritance(input: {\n  builtIns: Record<string, WorkerProfile>;\n  definitions: Record<string, WorkerProfileDefinition>;\n}): Record<string, WorkerProfile> {\n  const resolved = new Map<string, WorkerProfile>();\n  const resolving = new Set<string>();\n\n  const resolve = (id: string): WorkerProfile => {\n    if (resolved.has(id)) return resolved.get(id)!;\n    if (resolving.has(id)) throw new Error(`Profile inheritance cycle detected at \"${id}\"`);\n\n    const def = input.definitions[id] ?? input.builtIns[id];\n    if (!def) throw new Error(`Unknown profile \"${id}\"`);\n\n    resolving.add(id);\n\n    let merged: WorkerProfile | undefined;\n\n    const composeList = Array.isArray(def.compose) ? def.compose : [];\n    if (composeList.length > 0) {\n      for (const baseId of composeList) {\n        const base = resolve(baseId);\n        merged = merged ? mergeProfiles(merged, base) : base;\n      }\n    }\n\n    if (def.extends) {\n      const base = resolve(def.extends);\n      merged = merged ? mergeProfiles(merged, base) : base;\n    }\n\n    if (!merged) {\n      merged = input.builtIns[id] ?? (def as WorkerProfile);\n    }\n\n    const finalProfile = mergeProfiles(merged, def);\n\n    if (\n      typeof finalProfile.id !== \"string\" ||\n      typeof finalProfile.name !== \"string\" ||\n      typeof finalProfile.model !== \"string\" ||\n      typeof finalProfile.purpose !== \"string\" ||\n      typeof finalProfile.whenToUse !== \"string\"\n    ) {\n      throw new Error(`Profile \"${id}\" is missing required fields (id, name, model, purpose, whenToUse).`);\n    }\n\n    resolved.set(id, finalProfile);\n    resolving.delete(id);\n    return finalProfile;\n  };\n\n  const output: Record<string, WorkerProfile> = {};\n  const allIds = new Set<string>([...Object.keys(input.builtIns), ...Object.keys(input.definitions)]);\n  for (const id of allIds) {\n    output[id] = resolve(id);\n  }\n\n  return output;\n}\n"
  },
  {
    "path": "config/profiles.ts",
    "content": "export type { WorkerProfile } from \"../types\";\nexport { builtInProfiles, getAllProfiles, getAllProfilesWithSkills, getProfile } from \"../workers/profiles\";\n"
  },
  {
    "path": "core/container-profiles.ts",
    "content": "import type { createDatabase } from \"../db\";\nimport { applyWorkerConfigOverrides } from \"../db/overrides\";\nimport type { WorkerProfile } from \"../types\";\nimport { getAllProfiles } from \"../workers/profiles\";\n\ntype ProfileMap = Record<string, WorkerProfile>;\n\ninterface ProfileSyncInput {\n  projectDir: string;\n  baseProfiles: ProfileMap;\n  profiles: ProfileMap;\n  database: ReturnType<typeof createDatabase>;\n}\n\n/** Create a profile refresh helper that merges SKILL.md profiles with config overrides. */\nexport const createProfileSync = (input: ProfileSyncInput) => {\n  const syncProfiles = (next: ProfileMap) => {\n    for (const key of Object.keys(input.profiles)) {\n      delete input.profiles[key];\n    }\n    for (const [key, profile] of Object.entries(next)) {\n      input.profiles[key] = profile;\n    }\n  };\n\n  const refreshProfiles = async () => {\n    const configProfilesArray = Object.values(input.baseProfiles).map((profile) => ({ ...profile }));\n    const merged = await getAllProfiles(input.projectDir, configProfilesArray);\n    const workerConfigs = input.database.getAllWorkerConfigs();\n    syncProfiles(applyWorkerConfigOverrides(merged, workerConfigs));\n  };\n\n  return { refreshProfiles };\n};\n"
  },
  {
    "path": "core/container-toasts.ts",
    "content": "import type { createApi } from \"../api\";\nimport type { createCommunication } from \"../communication\";\nimport type { OrchestratorConfig, WorkerInstance, WorkerProfile } from \"../types\";\nimport type { WorkerJob } from \"../workers/jobs\";\n\ntype ToastVariant = \"info\" | \"success\" | \"warning\" | \"error\";\n\ninterface ToastBody {\n  title: string;\n  message: string;\n  variant: ToastVariant;\n}\n\nconst formatJobToast = (job: WorkerJob, status: \"created\" | \"succeeded\" | \"failed\") => {\n  const label = status === \"created\" ? \"Job Queued\" : status === \"succeeded\" ? \"Job Complete\" : \"Job Failed\";\n  const type: ToastVariant = status === \"failed\" ? \"error\" : status === \"succeeded\" ? \"success\" : \"info\";\n  return { title: `${label}: ${job.workerId}`, message: `Job ${job.id}`, variant: type } satisfies ToastBody;\n};\n\n/** Wire up toast notifications for orchestrator lifecycle events. */\nexport const registerCommunicationToasts = (input: {\n  api: ReturnType<typeof createApi>;\n  communication: ReturnType<typeof createCommunication>;\n  profiles: Record<string, WorkerProfile>;\n  config: OrchestratorConfig;\n}) => {\n  const { api, communication, profiles, config } = input;\n  const toastsEnabled = config.ui?.toasts !== false;\n\n  const showToast = (body: ToastBody) => {\n    if (!toastsEnabled) return;\n    api.tui.showToast({ body }).catch((err) => console.log(\"[Toast] Failed:\", err));\n  };\n\n  const profileCount = Object.keys(profiles).length;\n  const autoSpawn = config.spawn ?? [];\n\n  showToast({\n    title: \"Orchestra Plugin Ready\",\n    message: `${profileCount} worker profiles loaded${autoSpawn.length > 0 ? `, auto-spawning: ${autoSpawn.join(\", \")}` : \"\"}`,\n    variant: \"success\",\n  });\n\n  communication.emit(\n    \"orchestra.started\",\n    { profileCount, autoSpawn, fallbackModel: undefined },\n    { source: \"orchestrator\" },\n  );\n\n  communication.on(\"orchestra.model.resolved\", (event) => {\n    const { resolution } = event.data;\n    showToast({\n      title: `Model Resolved: ${resolution.profileId}`,\n      message: `${resolution.from}  ${resolution.to}`,\n      variant: \"info\",\n    });\n  });\n\n  communication.on(\"orchestra.model.fallback\", (event) => {\n    const { profileId, model, reason } = event.data;\n    showToast({\n      title: `Model Fallback: ${profileId}`,\n      message: `Using ${model} (${reason})`,\n      variant: \"warning\",\n    });\n  });\n\n  communication.on(\"orchestra.worker.spawned\", (event: { data: { worker: WorkerInstance } }) => {\n    const { worker } = event.data;\n    showToast({\n      title: `Spawning: ${worker.profile.name}`,\n      message: `Model: ${worker.profile.model}`,\n      variant: \"info\",\n    });\n  });\n\n  communication.on(\"orchestra.worker.reused\", (event: { data: { worker: WorkerInstance } }) => {\n    const { worker } = event.data;\n    showToast({\n      title: `Reusing: ${worker.profile.name}`,\n      message: `Port ${worker.port}`,\n      variant: \"info\",\n    });\n  });\n\n  communication.on(\"orchestra.worker.ready\", (event: { data: { worker: WorkerInstance } }) => {\n    const { worker } = event.data;\n    showToast({\n      title: `Ready: ${worker.profile.name}`,\n      message: `Port ${worker.port}`,\n      variant: \"success\",\n    });\n  });\n\n  communication.on(\"orchestra.worker.error\", (event: { data: { worker: WorkerInstance; error: unknown } }) => {\n    const { worker, error } = event.data;\n    showToast({\n      title: `Worker Error: ${worker.profile.name}`,\n      message: typeof error === \"string\" ? error : \"Worker encountered an error\",\n      variant: \"error\",\n    });\n  });\n\n  communication.on(\"orchestra.worker.stopped\", (event: { data: { worker: WorkerInstance } }) => {\n    const { worker } = event.data;\n    showToast({\n      title: `Stopped: ${worker.profile.name}`,\n      message: `Port ${worker.port}`,\n      variant: \"warning\",\n    });\n  });\n\n  communication.on(\n    \"orchestra.worker.wakeup\",\n    (event: { data: { workerId: string; reason: string; summary?: string } }) => {\n      const { workerId, reason, summary } = event.data;\n      showToast({\n        title: `Worker Wakeup: ${workerId}`,\n        message: summary ? `${reason}: ${summary}` : reason,\n        variant: \"info\",\n      });\n    },\n  );\n\n  communication.on(\n    \"orchestra.worker.job\",\n    (event: { data: { job: WorkerJob; status: \"created\" | \"succeeded\" | \"failed\" } }) => {\n      showToast(formatJobToast(event.data.job, event.data.status));\n    },\n  );\n\n  communication.on(\"orchestra.subagent.active\", (event) => {\n    const subagent = event.data.subagent;\n    showToast({\n      title: `Subagent Active: ${subagent.workerId}`,\n      message: subagent.profile?.name ?? \"Switching to worker session\",\n      variant: \"info\",\n    });\n  });\n\n  communication.on(\"orchestra.subagent.closed\", (event) => {\n    const subagent = event.data.subagent;\n    const error = event.data.result?.error;\n    showToast({\n      title: `Subagent Closed: ${subagent.workerId}`,\n      message: error ?? \"Returning to parent session\",\n      variant: error ? \"error\" : \"success\",\n    });\n  });\n\n  communication.on(\"orchestra.vision.started\", () => {\n    showToast({\n      title: \"Analyzing Image\",\n      message: \"Vision worker is processing your image...\",\n      variant: \"info\",\n    });\n  });\n\n  communication.on(\n    \"orchestra.vision.completed\",\n    (event: { data: { success: boolean; error?: string; durationMs?: number } }) => {\n      const { success, error, durationMs } = event.data;\n      if (success) {\n        const duration = durationMs ? ` (${(durationMs / 1000).toFixed(1)}s)` : \"\";\n        showToast({\n          title: \"Image Analyzed\",\n          message: `Vision analysis complete${duration}`,\n          variant: \"success\",\n        });\n      } else {\n        showToast({\n          title: \"Vision Failed\",\n          message: error ?? \"Could not analyze image\",\n          variant: \"error\",\n        });\n      }\n    },\n  );\n};\n"
  },
  {
    "path": "core/container-vision.ts",
    "content": "import { appendFile, mkdir } from \"node:fs/promises\";\nimport { join } from \"node:path\";\n\ntype VisionLogEntry = Record<string, unknown>;\n\n/** Resolve vision runtime settings (timeout, prompt, logging) from env and project dir. */\nexport const getVisionRuntimeConfig = (projectDir: string) => {\n  const rawTimeout = process.env.OPENCODE_VISION_TIMEOUT_MS;\n  const timeoutValue = rawTimeout ? Number(rawTimeout) : undefined;\n  const timeoutMs =\n    Number.isFinite(timeoutValue ?? NaN) && (timeoutValue as number) > 0 ? (timeoutValue as number) : 300_000;\n  const prompt = process.env.OPENCODE_VISION_PROMPT?.trim() || undefined;\n\n  const logSink = async (entry: VisionLogEntry) => {\n    try {\n      const logDir = join(projectDir, \".opencode\", \"vision\");\n      await mkdir(logDir, { recursive: true });\n      const payload = { loggedAt: new Date().toISOString(), ...entry };\n      await appendFile(join(logDir, \"jobs.jsonl\"), `${JSON.stringify(payload)}\\n`);\n    } catch {\n      // ignore logging failures\n    }\n  };\n\n  return { timeoutMs, prompt, logSink };\n};\n"
  },
  {
    "path": "core/container.ts",
    "content": "import type { Hooks, PluginInput } from \"@opencode-ai/plugin\";\nimport type { Config } from \"@opencode-ai/sdk\";\nimport { createApi } from \"../api\";\nimport { createSkillsApiServer } from \"../api/skills-server\";\nimport type { CommandRouter } from \"../commands\";\nimport { createCommandRouter } from \"../commands\";\nimport { createCommunication } from \"../communication\";\nimport { createDatabase } from \"../db\";\nimport { createMemoryStore } from \"../memory\";\nimport { ensureNeo4jRunning, setNeo4jIntegrationsConfig } from \"../memory/neo4j\";\nimport { createOrchestrator } from \"../orchestrator\";\nimport { createSkillsService } from \"../skills/service\";\nimport { createTools } from \"../tools\";\nimport type { Factory, OrchestratorConfig, ServiceLifecycle } from \"../types\";\nimport {\n  createVisionRoutingState,\n  routeVisionMessage,\n  syncVisionProcessedMessages,\n  type VisionChatInput,\n  type VisionChatOutput,\n} from \"../ux/vision-routing\";\nimport { createWorkerManager } from \"../workers\";\nimport { createWorkflowEngine } from \"../workflows/factory\";\nimport { createProfileSync } from \"./container-profiles\";\nimport { registerCommunicationToasts } from \"./container-toasts\";\nimport { getVisionRuntimeConfig } from \"./container-vision\";\n\nexport type CoreConfig = {\n  ctx: PluginInput;\n  config: OrchestratorConfig;\n};\n\nexport type CoreHooks = Hooks & {\n  \"tui.command.execute\": CommandRouter[\"execute\"];\n};\n\nexport type CoreService = ServiceLifecycle & {\n  hooks: CoreHooks;\n  services: {\n    api: ReturnType<typeof createApi>;\n    communication: ReturnType<typeof createCommunication>;\n    database: ReturnType<typeof createDatabase>;\n    memory: ReturnType<typeof createMemoryStore>;\n    workers: ReturnType<typeof createWorkerManager>;\n    workflows: ReturnType<typeof createWorkflowEngine>;\n    orchestrator: ReturnType<typeof createOrchestrator>;\n    tools: ReturnType<typeof createTools>;\n    commands: ReturnType<typeof createCommandRouter>;\n    skills: ReturnType<typeof createSkillsService>;\n    skillsApi: ReturnType<typeof createSkillsApiServer>;\n  };\n};\n\n/** Create the orchestrator core services, hooks, and lifecycle handlers. */\nexport const createCore: Factory<CoreConfig, Record<string, never>, CoreService> = ({ config }) => {\n  setNeo4jIntegrationsConfig(config.config.integrations?.neo4j);\n\n  const api = createApi({\n    config: { directory: config.ctx.directory },\n    deps: { client: config.ctx.client },\n  });\n  const communication = createCommunication({ config: {}, deps: { api } });\n  const memory = createMemoryStore({ config: config.config.memory, deps: { api } });\n  const baseProfiles = { ...config.config.profiles };\n  const profiles = { ...baseProfiles };\n  config.config.profiles = profiles;\n  const projectDir = config.ctx.worktree && config.ctx.worktree !== \"/\" ? config.ctx.worktree : config.ctx.directory;\n  const database = createDatabase({ config: { directory: projectDir }, deps: {} });\n  const skills = createSkillsService(projectDir);\n  const workers = createWorkerManager({\n    config: {\n      basePort: config.config.basePort,\n      timeout: config.config.startupTimeout,\n      directory: config.ctx.directory,\n      profiles,\n      modelSelection: config.config.modelSelection,\n      modelAliases: config.config.modelAliases,\n      integrations: config.config.integrations,\n    },\n    deps: { api, communication, memory, db: database },\n  });\n  const workflows = createWorkflowEngine({ config: config.config.workflows, deps: {} });\n  const orchestrator = createOrchestrator({ config: config.config, deps: { api, workers, workflows, communication } });\n  const tools = createTools({ config: config.config, deps: { orchestrator, workers, workflows } });\n  const commands = createCommandRouter({\n    api,\n    orchestrator,\n    workers,\n    memory,\n    config: config.config,\n    projectDir,\n  });\n  const visionState = createVisionRoutingState();\n  const { timeoutMs: visionTimeoutMs, prompt: visionPrompt, logSink } = getVisionRuntimeConfig(projectDir);\n\n  const visionDeps = {\n    workers,\n    ensureWorker: (input: { workerId: string; reason: \"manual\" | \"on-demand\" }) => orchestrator.ensureWorker(input),\n    profiles,\n    communication,\n    timeoutMs: visionTimeoutMs,\n    ...(visionPrompt ? { prompt: visionPrompt } : {}),\n    logSink,\n  };\n  const { refreshProfiles } = createProfileSync({\n    projectDir,\n    baseProfiles,\n    profiles,\n    database,\n  });\n\n  // Pre-load profiles synchronously so they're available for the config hook\n  // The config hook runs before start(), so we need profiles loaded early\n  let profilesLoaded = false;\n  const ensureProfilesLoaded = async () => {\n    if (profilesLoaded) return;\n    profilesLoaded = true;\n    await refreshProfiles();\n  };\n\n  // Eagerly load profiles (fire and forget, but block config hook if needed)\n  const profilesLoadPromise = ensureProfilesLoaded();\n\n  const skillsApi = createSkillsApiServer({\n    config: { enabled: true },\n    deps: {\n      skills,\n      workers,\n      db: database,\n      onWorkerConfigChanged: () => {\n        void refreshProfiles().catch(() => {});\n      },\n      onPreferencesChanged: () => {},\n    },\n  });\n\n  skills.events.on((event) => {\n    if (event.type === \"skill.created\") {\n      communication.emit(\"skill.created\", { skill: event.skill }, { source: \"orchestrator\" });\n    }\n    if (event.type === \"skill.updated\") {\n      communication.emit(\"skill.updated\", { skill: event.skill }, { source: \"orchestrator\" });\n    }\n    if (event.type === \"skill.deleted\") {\n      communication.emit(\"skill.deleted\", { id: event.id, scope: event.scope }, { source: \"orchestrator\" });\n    }\n    void refreshProfiles().catch(() => {});\n  });\n\n  const start = async () => {\n    await api.start();\n    await communication.start();\n    await database.start();\n\n    // Auto-start Neo4j if configured (silent)\n    const neo4jCfg = config.config.integrations?.neo4j;\n    if (neo4jCfg && neo4jCfg.enabled !== false) {\n      await ensureNeo4jRunning(neo4jCfg);\n    }\n\n    await memory.start();\n    await ensureProfilesLoaded(); // Uses cached promise if already loaded by config hook\n    await workers.start();\n    await workflows.start();\n    await orchestrator.start();\n\n    // Start skills API in background (non-blocking, silent)\n    skillsApi.start().catch(() => {});\n    registerCommunicationToasts({\n      api,\n      communication,\n      profiles,\n      config: config.config,\n    });\n  };\n\n  const stop = async () => {\n    await orchestrator.stop();\n    await workflows.stop();\n    await workers.stop();\n    await skillsApi.stop();\n    await memory.stop();\n    await database.stop();\n    await communication.stop();\n    await api.stop();\n  };\n\n  const hooks: CoreHooks = {\n    tool: tools.tool,\n    config: async (input: Config) => {\n      // Ensure profiles are loaded before accessing them\n      await profilesLoadPromise;\n\n      // Inject the orchestrator agent if enabled in config\n      const agentCfg = config.config.agent;\n      if (agentCfg?.enabled !== false) {\n        const agentName = agentCfg?.name ?? \"orchestrator\";\n        input.agent = input.agent ?? {};\n        input.agent[agentName] = {\n          model: agentCfg?.model ?? \"anthropic/claude-opus-4-5\",\n          mode: agentCfg?.mode ?? \"primary\",\n          description: \"OpenCode Orchestrator - Coordinates specialized AI workers for complex tasks\",\n          prompt: agentCfg?.prompt ?? undefined,\n          ...(agentCfg?.color ? { color: agentCfg.color } : {}),\n        };\n      }\n\n      // NOTE: Workers with skillPermissions: \"inherit\" are NOT registered as separate agents.\n      // They remain as workers that the orchestrator can delegate to via ask_worker/delegate_task.\n      // This prevents them from inheriting orchestrator-only tools like spawn_worker.\n      // To interact with memory or other \"agent-level\" workers, use the orchestrator.\n\n      const commandConfig = commands.commandConfig();\n      if (Object.keys(commandConfig).length > 0) {\n        input.command = { ...(input.command ?? {}), ...commandConfig };\n      }\n    },\n    \"tool.execute.before\": tools.guard,\n    \"chat.message\": async (input: VisionChatInput, output: VisionChatOutput) => {\n      await routeVisionMessage(\n        {\n          sessionID: input.sessionID,\n          agent: input.agent,\n          messageID: input.messageID,\n          role: output?.message?.role,\n        },\n        output,\n        visionDeps,\n        visionState,\n      );\n    },\n    // tui.command.execute hook input type is defined by the SDK plugin system\n    \"tui.command.execute\": async (input) => commands.execute(input),\n    \"experimental.chat.messages.transform\": async (_input, output) => {\n      syncVisionProcessedMessages(output, visionState);\n    },\n    \"experimental.chat.system.transform\": tools.systemTransform,\n    \"experimental.session.compacting\": tools.compaction,\n  };\n\n  return {\n    hooks,\n    services: {\n      api,\n      communication,\n      database,\n      memory,\n      workers,\n      workflows,\n      orchestrator,\n      tools,\n      commands,\n      skills,\n      skillsApi,\n    },\n    start,\n    stop,\n    health: async () => ({ ok: true }),\n  };\n};\n"
  },
  {
    "path": "core/index.ts",
    "content": "export { type CoreConfig, type CoreHooks, type CoreService, createCore } from \"./container\";\n"
  },
  {
    "path": "core/jobs.ts",
    "content": "import { WorkerJobRegistry } from \"../workers/jobs\";\n\nexport type { WorkerJob, WorkerJobReport, WorkerJobStatus } from \"../workers/jobs\";\n\nexport const workerJobs = new WorkerJobRegistry();\n"
  },
  {
    "path": "core/spawn-policy.ts",
    "content": "import type { SpawnPolicy, SpawnPolicyConfig } from \"../types\";\n\nexport function resolveSpawnPolicy(config: SpawnPolicyConfig | undefined, id: string): SpawnPolicy {\n  const defaults = config?.default ?? {};\n  const override = config?.profiles?.[id] ?? {};\n  return { ...defaults, ...override };\n}\n\nexport function canAutoSpawn(config: SpawnPolicyConfig | undefined, id: string): boolean {\n  return resolveSpawnPolicy(config, id).autoSpawn !== false;\n}\n\nexport function canSpawnOnDemand(config: SpawnPolicyConfig | undefined, id: string): boolean {\n  return resolveSpawnPolicy(config, id).onDemand !== false;\n}\n\nexport function canSpawnManually(config: SpawnPolicyConfig | undefined, id: string): boolean {\n  return resolveSpawnPolicy(config, id).allowManual !== false;\n}\n\nexport function canWarmPool(config: SpawnPolicyConfig | undefined, id: string): boolean {\n  return resolveSpawnPolicy(config, id).warmPool !== false;\n}\n\nexport function canReuseExisting(config: SpawnPolicyConfig | undefined, id: string): boolean {\n  return resolveSpawnPolicy(config, id).reuseExisting !== false;\n}\n"
  },
  {
    "path": "db/index.ts",
    "content": "import { Database } from \"bun:sqlite\";\nimport { existsSync } from \"node:fs\";\nimport { mkdir } from \"node:fs/promises\";\nimport { join } from \"node:path\";\nimport type { Factory, ServiceLifecycle } from \"../types\";\nimport {\n  CREATE_TABLES_SQL,\n  type Preference,\n  rowToUser,\n  rowToWorkerConfig,\n  rowToWorkerState,\n  SCHEMA_VERSION,\n  type User,\n  type UserRow,\n  type WorkerConfig,\n  type WorkerConfigRow,\n  type WorkerState,\n  type WorkerStateRow,\n} from \"./schema\";\n\nexport type DatabaseConfig = {\n  directory: string;\n  filename?: string;\n};\n\nexport type DatabaseService = ServiceLifecycle & {\n  // User operations\n  getUser(): User | null;\n  createUser(): User;\n  markOnboarded(): User;\n\n  // Preference operations\n  getPreference(key: string): string | null;\n  setPreference(key: string, value: string | null): void;\n  getAllPreferences(): Record<string, string | null>;\n  deletePreference(key: string): void;\n\n  // Worker config operations\n  getWorkerConfig(workerId: string): WorkerConfig | null;\n  setWorkerConfig(\n    workerId: string,\n    config: Partial<Omit<WorkerConfig, \"id\" | \"userId\" | \"workerId\" | \"updatedAt\">>,\n  ): void;\n  getAllWorkerConfigs(): WorkerConfig[];\n  clearWorkerConfig(workerId: string): void;\n\n  // Worker state operations\n  getWorkerState(workerId: string): WorkerState | null;\n  setWorkerState(state: {\n    workerId: string;\n    profileName?: string | null;\n    model?: string | null;\n    serverUrl?: string | null;\n    sessionId?: string | null;\n    uiSessionId?: string | null;\n    status?: string | null;\n    sessionMode?: string | null;\n    parentSessionId?: string | null;\n    startedAt?: Date | null;\n    lastActivity?: Date | null;\n    currentTask?: string | null;\n    lastResult?: WorkerState[\"lastResult\"] | null;\n    lastResultAt?: Date | null;\n    lastResultJobId?: string | null;\n    lastResultDurationMs?: number | null;\n    error?: string | null;\n    warning?: string | null;\n  }): void;\n  getAllWorkerStates(): WorkerState[];\n  clearWorkerState(workerId: string): void;\n\n  // Utility\n  isOnboarded(): boolean;\n  getDbPath(): string;\n};\n\nexport const createDatabase: Factory<DatabaseConfig, Record<string, never>, DatabaseService> = ({ config }) => {\n  const dbPath = join(config.directory, \".opencode\", config.filename ?? \"user.db\");\n  let db: Database | null = null;\n\n  const ensureUser = (): string => {\n    if (!db) throw new Error(\"Database not initialized\");\n\n    const existing = db.prepare(\"SELECT id FROM users LIMIT 1\").get() as { id: string } | undefined;\n    if (existing) return existing.id;\n\n    const id = crypto.randomUUID().replace(/-/g, \"\");\n    db.prepare(\"INSERT INTO users (id) VALUES (?)\").run(id);\n    return id;\n  };\n\n  const getUserId = (): string => {\n    if (!db) throw new Error(\"Database not initialized\");\n    const row = db.prepare(\"SELECT id FROM users LIMIT 1\").get() as { id: string } | undefined;\n    if (!row) throw new Error(\"No user found\");\n    return row.id;\n  };\n\n  const getUser = (): User | null => {\n    if (!db) return null;\n    const row = db.prepare(\"SELECT * FROM users LIMIT 1\").get() as UserRow | undefined;\n    return row ? rowToUser(row) : null;\n  };\n\n  const createUser = (): User => {\n    if (!db) throw new Error(\"Database not initialized\");\n    const id = ensureUser();\n    const row = db.prepare(\"SELECT * FROM users WHERE id = ?\").get(id) as UserRow;\n    return rowToUser(row);\n  };\n\n  const markOnboarded = (): User => {\n    if (!db) throw new Error(\"Database not initialized\");\n    const userId = getUserId();\n    db.prepare(`\n      UPDATE users\n      SET onboarded = 1, onboarded_at = datetime('now'), updated_at = datetime('now')\n      WHERE id = ?\n    `).run(userId);\n    const row = db.prepare(\"SELECT * FROM users WHERE id = ?\").get(userId) as UserRow;\n    return rowToUser(row);\n  };\n\n  const getPreference = (key: string): string | null => {\n    if (!db) return null;\n    const userId = getUserId();\n    const row = db.prepare(\"SELECT value FROM preferences WHERE user_id = ? AND key = ?\").get(userId, key) as\n      | { value: string | null }\n      | undefined;\n    return row?.value ?? null;\n  };\n\n  const setPreference = (key: string, value: string | null): void => {\n    if (!db) throw new Error(\"Database not initialized\");\n    const userId = getUserId();\n    db.prepare(`\n      INSERT INTO preferences (id, user_id, key, value)\n      VALUES (?, ?, ?, ?)\n      ON CONFLICT(user_id, key) DO UPDATE SET value = excluded.value, updated_at = datetime('now')\n    `).run(crypto.randomUUID().replace(/-/g, \"\"), userId, key, value);\n  };\n\n  const getAllPreferences = (): Record<string, string | null> => {\n    if (!db) return {};\n    const userId = getUserId();\n    const rows = db.prepare(\"SELECT key, value FROM preferences WHERE user_id = ?\").all(userId) as Array<{\n      key: string;\n      value: string | null;\n    }>;\n    return Object.fromEntries(rows.map((r) => [r.key, r.value]));\n  };\n\n  const deletePreference = (key: string): void => {\n    if (!db) throw new Error(\"Database not initialized\");\n    const userId = getUserId();\n    db.prepare(\"DELETE FROM preferences WHERE user_id = ? AND key = ?\").run(userId, key);\n  };\n\n  const getWorkerConfig = (workerId: string): WorkerConfig | null => {\n    if (!db) return null;\n    const userId = getUserId();\n    const row = db.prepare(\"SELECT * FROM worker_config WHERE user_id = ? AND worker_id = ?\").get(userId, workerId) as\n      | WorkerConfigRow\n      | undefined;\n    return row ? rowToWorkerConfig(row) : null;\n  };\n\n  const setWorkerConfig = (\n    workerId: string,\n    cfg: Partial<Omit<WorkerConfig, \"id\" | \"userId\" | \"workerId\" | \"updatedAt\">>,\n  ): void => {\n    if (!db) throw new Error(\"Database not initialized\");\n    const userId = getUserId();\n\n    const existing = db\n      .prepare(\"SELECT id FROM worker_config WHERE user_id = ? AND worker_id = ?\")\n      .get(userId, workerId) as { id: string } | undefined;\n\n    if (existing) {\n      const updates: string[] = [];\n      const values: Array<string | number | null> = [];\n\n      if (cfg.model !== undefined) {\n        updates.push(\"model = ?\");\n        values.push(cfg.model);\n      }\n      if (cfg.temperature !== undefined) {\n        updates.push(\"temperature = ?\");\n        values.push(cfg.temperature);\n      }\n      if (cfg.maxTokens !== undefined) {\n        updates.push(\"max_tokens = ?\");\n        values.push(cfg.maxTokens);\n      }\n      if (cfg.enabled !== undefined) {\n        updates.push(\"enabled = ?\");\n        values.push(cfg.enabled ? 1 : 0);\n      }\n\n      if (updates.length > 0) {\n        updates.push(\"updated_at = datetime('now')\");\n        db.prepare(`UPDATE worker_config SET ${updates.join(\", \")} WHERE id = ?`).run(...values, existing.id);\n      }\n    } else {\n      db.prepare(`\n        INSERT INTO worker_config (id, user_id, worker_id, model, temperature, max_tokens, enabled)\n        VALUES (?, ?, ?, ?, ?, ?, ?)\n      `).run(\n        crypto.randomUUID().replace(/-/g, \"\"),\n        userId,\n        workerId,\n        cfg.model ?? null,\n        cfg.temperature ?? null,\n        cfg.maxTokens ?? null,\n        cfg.enabled !== false ? 1 : 0,\n      );\n    }\n  };\n\n  const getAllWorkerConfigs = (): WorkerConfig[] => {\n    if (!db) return [];\n    const userId = getUserId();\n    const rows = db.prepare(\"SELECT * FROM worker_config WHERE user_id = ?\").all(userId) as WorkerConfigRow[];\n    return rows.map(rowToWorkerConfig);\n  };\n\n  const clearWorkerConfig = (workerId: string): void => {\n    if (!db) throw new Error(\"Database not initialized\");\n    const userId = getUserId();\n    db.prepare(\"DELETE FROM worker_config WHERE user_id = ? AND worker_id = ?\").run(userId, workerId);\n  };\n\n  const getWorkerState = (workerId: string): WorkerState | null => {\n    if (!db) return null;\n    const userId = getUserId();\n    const row = db.prepare(\"SELECT * FROM worker_state WHERE user_id = ? AND worker_id = ?\").get(userId, workerId) as\n      | WorkerStateRow\n      | undefined;\n    return row ? rowToWorkerState(row) : null;\n  };\n\n  const setWorkerState = (state: {\n    workerId: string;\n    profileName?: string | null;\n    model?: string | null;\n    serverUrl?: string | null;\n    sessionId?: string | null;\n    uiSessionId?: string | null;\n    status?: string | null;\n    sessionMode?: string | null;\n    parentSessionId?: string | null;\n    startedAt?: Date | null;\n    lastActivity?: Date | null;\n    currentTask?: string | null;\n    lastResult?: WorkerState[\"lastResult\"] | null;\n    lastResultAt?: Date | null;\n    lastResultJobId?: string | null;\n    lastResultDurationMs?: number | null;\n    error?: string | null;\n    warning?: string | null;\n  }): void => {\n    if (!db) throw new Error(\"Database not initialized\");\n    const userId = getUserId();\n    const serializedResult = state.lastResult ? JSON.stringify(state.lastResult) : null;\n    db.prepare(\n      `\n        INSERT INTO worker_state (\n          id,\n          user_id,\n          worker_id,\n          profile_name,\n          model,\n          server_url,\n          session_id,\n          ui_session_id,\n          status,\n          session_mode,\n          parent_session_id,\n          started_at,\n          last_activity,\n          current_task,\n          last_result,\n          last_result_at,\n          last_result_job_id,\n          last_result_duration_ms,\n          error,\n          warning\n        )\n        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n        ON CONFLICT(user_id, worker_id) DO UPDATE SET\n          profile_name = excluded.profile_name,\n          model = excluded.model,\n          server_url = excluded.server_url,\n          session_id = excluded.session_id,\n          ui_session_id = excluded.ui_session_id,\n          status = excluded.status,\n          session_mode = excluded.session_mode,\n          parent_session_id = excluded.parent_session_id,\n          started_at = excluded.started_at,\n          last_activity = excluded.last_activity,\n          current_task = excluded.current_task,\n          last_result = excluded.last_result,\n          last_result_at = excluded.last_result_at,\n          last_result_job_id = excluded.last_result_job_id,\n          last_result_duration_ms = excluded.last_result_duration_ms,\n          error = excluded.error,\n          warning = excluded.warning,\n          updated_at = datetime('now')\n      `,\n    ).run(\n      crypto.randomUUID().replace(/-/g, \"\"),\n      userId,\n      state.workerId,\n      state.profileName ?? null,\n      state.model ?? null,\n      state.serverUrl ?? null,\n      state.sessionId ?? null,\n      state.uiSessionId ?? null,\n      state.status ?? null,\n      state.sessionMode ?? null,\n      state.parentSessionId ?? null,\n      state.startedAt ? state.startedAt.toISOString() : null,\n      state.lastActivity ? state.lastActivity.toISOString() : null,\n      state.currentTask ?? null,\n      serializedResult,\n      state.lastResultAt ? state.lastResultAt.toISOString() : null,\n      state.lastResultJobId ?? null,\n      state.lastResultDurationMs ?? null,\n      state.error ?? null,\n      state.warning ?? null,\n    );\n  };\n\n  const getAllWorkerStates = (): WorkerState[] => {\n    if (!db) return [];\n    const userId = getUserId();\n    const rows = db.prepare(\"SELECT * FROM worker_state WHERE user_id = ?\").all(userId) as WorkerStateRow[];\n    return rows.map(rowToWorkerState);\n  };\n\n  const clearWorkerState = (workerId: string): void => {\n    if (!db) throw new Error(\"Database not initialized\");\n    const userId = getUserId();\n    db.prepare(\"DELETE FROM worker_state WHERE user_id = ? AND worker_id = ?\").run(userId, workerId);\n  };\n\n  const isOnboarded = (): boolean => {\n    const user = getUser();\n    return user?.onboarded ?? false;\n  };\n\n  const start = async () => {\n    const dbDir = join(config.directory, \".opencode\");\n    if (!existsSync(dbDir)) {\n      await mkdir(dbDir, { recursive: true });\n    }\n\n    db = new Database(dbPath, { create: true });\n    db.exec(\"PRAGMA journal_mode = WAL\");\n    db.exec(\"PRAGMA foreign_keys = ON\");\n\n    // Run schema creation\n    db.exec(CREATE_TABLES_SQL);\n\n    // Check/update schema version\n    const versionRow = db.prepare(\"SELECT version FROM schema_version ORDER BY version DESC LIMIT 1\").get() as\n      | { version: number }\n      | undefined;\n    const currentVersion = versionRow?.version ?? 0;\n\n    if (currentVersion < SCHEMA_VERSION) {\n      // Run migrations if needed (for now, just record the version)\n      db.prepare(\"INSERT OR REPLACE INTO schema_version (version) VALUES (?)\").run(SCHEMA_VERSION);\n    }\n\n    // Ensure a user exists\n    ensureUser();\n  };\n\n  const stop = async () => {\n    if (db) {\n      db.close();\n      db = null;\n    }\n  };\n\n  return {\n    start,\n    stop,\n    health: async () => ({ ok: db !== null }),\n    getUser,\n    createUser,\n    markOnboarded,\n    getPreference,\n    setPreference,\n    getAllPreferences,\n    deletePreference,\n    getWorkerConfig,\n    setWorkerConfig,\n    getAllWorkerConfigs,\n    clearWorkerConfig,\n    getWorkerState,\n    setWorkerState,\n    getAllWorkerStates,\n    clearWorkerState,\n    isOnboarded,\n    getDbPath: () => dbPath,\n  };\n};\n\nexport type { User, Preference, WorkerConfig, WorkerState };\n"
  },
  {
    "path": "db/overrides.ts",
    "content": "import type { WorkerProfile } from \"../types\";\nimport type { WorkerConfig } from \"./index\";\n\nexport function applyWorkerConfigOverrides(\n  profiles: Record<string, WorkerProfile>,\n  configs: WorkerConfig[],\n): Record<string, WorkerProfile> {\n  if (!configs.length) return profiles;\n\n  const next: Record<string, WorkerProfile> = {};\n  for (const [id, profile] of Object.entries(profiles)) {\n    next[id] = { ...profile };\n  }\n\n  for (const config of configs) {\n    const profile = next[config.workerId];\n    if (!profile) continue;\n\n    if (config.model !== null && config.model !== undefined) {\n      profile.model = config.model;\n    }\n    if (config.temperature !== null && config.temperature !== undefined) {\n      profile.temperature = config.temperature;\n    }\n    if (config.maxTokens !== null && config.maxTokens !== undefined) {\n      profile.maxTokens = config.maxTokens;\n    }\n    if (typeof config.enabled === \"boolean\") {\n      profile.enabled = config.enabled;\n    }\n  }\n\n  return next;\n}\n"
  },
  {
    "path": "db/schema.ts",
    "content": "/**\n * Database schema for OpenCode Orchestra\n *\n * Tables:\n * - users: Tracks onboarding status and user metadata\n * - preferences: Key-value store for user preferences\n * - worker_config: Per-worker model and settings overrides\n */\n\nexport const SCHEMA_VERSION = 2;\n\nexport const CREATE_TABLES_SQL = `\n-- Users table: tracks onboarding status\nCREATE TABLE IF NOT EXISTS users (\n  id TEXT PRIMARY KEY DEFAULT (lower(hex(randomblob(16)))),\n  onboarded INTEGER DEFAULT 0,\n  onboarded_at TEXT,\n  created_at TEXT DEFAULT (datetime('now')),\n  updated_at TEXT DEFAULT (datetime('now'))\n);\n\n-- Preferences table: key-value store for user settings\nCREATE TABLE IF NOT EXISTS preferences (\n  id TEXT PRIMARY KEY DEFAULT (lower(hex(randomblob(16)))),\n  user_id TEXT NOT NULL REFERENCES users(id) ON DELETE CASCADE,\n  key TEXT NOT NULL,\n  value TEXT,\n  updated_at TEXT DEFAULT (datetime('now')),\n  UNIQUE(user_id, key)\n);\n\n-- Worker config table: per-worker model and settings\nCREATE TABLE IF NOT EXISTS worker_config (\n  id TEXT PRIMARY KEY DEFAULT (lower(hex(randomblob(16)))),\n  user_id TEXT NOT NULL REFERENCES users(id) ON DELETE CASCADE,\n  worker_id TEXT NOT NULL,\n  model TEXT,\n  temperature REAL,\n  max_tokens INTEGER,\n  enabled INTEGER DEFAULT 1,\n  updated_at TEXT DEFAULT (datetime('now')),\n  UNIQUE(user_id, worker_id)\n);\n\n-- Worker state table: runtime status for active workers\nCREATE TABLE IF NOT EXISTS worker_state (\n  id TEXT PRIMARY KEY DEFAULT (lower(hex(randomblob(16)))),\n  user_id TEXT NOT NULL REFERENCES users(id) ON DELETE CASCADE,\n  worker_id TEXT NOT NULL,\n  profile_name TEXT,\n  model TEXT,\n  server_url TEXT,\n  session_id TEXT,\n  ui_session_id TEXT,\n  status TEXT,\n  session_mode TEXT,\n  parent_session_id TEXT,\n  started_at TEXT,\n  last_activity TEXT,\n  current_task TEXT,\n  last_result TEXT,\n  last_result_at TEXT,\n  last_result_job_id TEXT,\n  last_result_duration_ms INTEGER,\n  error TEXT,\n  warning TEXT,\n  updated_at TEXT DEFAULT (datetime('now')),\n  UNIQUE(user_id, worker_id)\n);\n\n-- Schema version tracking\nCREATE TABLE IF NOT EXISTS schema_version (\n  version INTEGER PRIMARY KEY,\n  applied_at TEXT DEFAULT (datetime('now'))\n);\n\n-- Indexes for common queries\nCREATE INDEX IF NOT EXISTS idx_preferences_user_key ON preferences(user_id, key);\nCREATE INDEX IF NOT EXISTS idx_worker_config_user ON worker_config(user_id);\nCREATE INDEX IF NOT EXISTS idx_worker_config_worker ON worker_config(worker_id);\nCREATE INDEX IF NOT EXISTS idx_worker_state_user ON worker_state(user_id);\nCREATE INDEX IF NOT EXISTS idx_worker_state_worker ON worker_state(worker_id);\nCREATE INDEX IF NOT EXISTS idx_worker_state_session ON worker_state(session_id);\n`;\n\nexport type UserRow = {\n  id: string;\n  onboarded: number;\n  onboarded_at: string | null;\n  created_at: string;\n  updated_at: string;\n};\n\nexport type PreferenceRow = {\n  id: string;\n  user_id: string;\n  key: string;\n  value: string | null;\n  updated_at: string;\n};\n\nexport type WorkerConfigRow = {\n  id: string;\n  user_id: string;\n  worker_id: string;\n  model: string | null;\n  temperature: number | null;\n  max_tokens: number | null;\n  enabled: number;\n  updated_at: string;\n};\n\nexport type WorkerStateRow = {\n  id: string;\n  user_id: string;\n  worker_id: string;\n  profile_name: string | null;\n  model: string | null;\n  server_url: string | null;\n  session_id: string | null;\n  ui_session_id: string | null;\n  status: string | null;\n  session_mode: string | null;\n  parent_session_id: string | null;\n  started_at: string | null;\n  last_activity: string | null;\n  current_task: string | null;\n  last_result: string | null;\n  last_result_at: string | null;\n  last_result_job_id: string | null;\n  last_result_duration_ms: number | null;\n  error: string | null;\n  warning: string | null;\n  updated_at: string;\n};\n\nexport type User = {\n  id: string;\n  onboarded: boolean;\n  onboardedAt: Date | null;\n  createdAt: Date;\n  updatedAt: Date;\n};\n\nexport type Preference = {\n  id: string;\n  userId: string;\n  key: string;\n  value: string | null;\n  updatedAt: Date;\n};\n\nexport type WorkerConfig = {\n  id: string;\n  userId: string;\n  workerId: string;\n  model: string | null;\n  temperature: number | null;\n  maxTokens: number | null;\n  enabled: boolean;\n  updatedAt: Date;\n};\n\nexport type WorkerState = {\n  id: string;\n  userId: string;\n  workerId: string;\n  profileName: string | null;\n  model: string | null;\n  serverUrl: string | null;\n  sessionId: string | null;\n  uiSessionId: string | null;\n  status: string | null;\n  sessionMode: string | null;\n  parentSessionId: string | null;\n  startedAt: Date | null;\n  lastActivity: Date | null;\n  currentTask: string | null;\n  lastResult: {\n    at?: string;\n    jobId?: string;\n    response?: string;\n    report?: {\n      summary?: string;\n      details?: string;\n      issues?: string[];\n      notes?: string;\n    };\n    durationMs?: number;\n  } | null;\n  lastResultAt: Date | null;\n  lastResultJobId: string | null;\n  lastResultDurationMs: number | null;\n  error: string | null;\n  warning: string | null;\n  updatedAt: Date;\n};\n\nexport function rowToUser(row: UserRow): User {\n  return {\n    id: row.id,\n    onboarded: row.onboarded === 1,\n    onboardedAt: row.onboarded_at ? new Date(row.onboarded_at) : null,\n    createdAt: new Date(row.created_at),\n    updatedAt: new Date(row.updated_at),\n  };\n}\n\nexport function rowToPreference(row: PreferenceRow): Preference {\n  return {\n    id: row.id,\n    userId: row.user_id,\n    key: row.key,\n    value: row.value,\n    updatedAt: new Date(row.updated_at),\n  };\n}\n\nexport function rowToWorkerConfig(row: WorkerConfigRow): WorkerConfig {\n  return {\n    id: row.id,\n    userId: row.user_id,\n    workerId: row.worker_id,\n    model: row.model,\n    temperature: row.temperature,\n    maxTokens: row.max_tokens,\n    enabled: row.enabled === 1,\n    updatedAt: new Date(row.updated_at),\n  };\n}\n\nexport function rowToWorkerState(row: WorkerStateRow): WorkerState {\n  let parsedResult: WorkerState[\"lastResult\"] = null;\n  if (row.last_result) {\n    try {\n      parsedResult = JSON.parse(row.last_result) as WorkerState[\"lastResult\"];\n    } catch {\n      parsedResult = null;\n    }\n  }\n  return {\n    id: row.id,\n    userId: row.user_id,\n    workerId: row.worker_id,\n    profileName: row.profile_name,\n    model: row.model,\n    serverUrl: row.server_url,\n    sessionId: row.session_id,\n    uiSessionId: row.ui_session_id,\n    status: row.status,\n    sessionMode: row.session_mode,\n    parentSessionId: row.parent_session_id,\n    startedAt: row.started_at ? new Date(row.started_at) : null,\n    lastActivity: row.last_activity ? new Date(row.last_activity) : null,\n    currentTask: row.current_task,\n    lastResult: parsedResult,\n    lastResultAt: row.last_result_at ? new Date(row.last_result_at) : null,\n    lastResultJobId: row.last_result_job_id,\n    lastResultDurationMs: row.last_result_duration_ms,\n    error: row.error,\n    warning: row.warning,\n    updatedAt: new Date(row.updated_at),\n  };\n}\n"
  },
  {
    "path": "helpers/advanced-util.ts",
    "content": "import { debuglog, format, inspect } from \"node:util\";\nimport type { WorkerInstance } from \"../types\";\n\n// Enhanced debugging for worker states\nexport const workerDebug = debuglog(\"opencode:worker\");\n\n// Type checking utilities\nexport const isWorkerInstance = (obj: unknown): obj is WorkerInstance => {\n  return (\n    typeof obj === \"object\" &&\n    obj !== null &&\n    typeof (obj as WorkerInstance).profile === \"object\" &&\n    typeof (obj as WorkerInstance).status === \"string\"\n  );\n};\n\n// Formatted worker status reporting\nexport const formatWorkerStatus = (worker: WorkerInstance): string => {\n  return format(\n    \"Worker %s: %s (pid: %s, port: %s)\",\n    worker.profile.id,\n    worker.status,\n    worker.pid || \"unknown\",\n    worker.port || \"unknown\",\n  );\n};\n\n// Enhanced inspection for worker objects\nexport const inspectWorker = (worker: WorkerInstance, depth: number = 2): string => {\n  return inspect(worker, {\n    depth,\n    colors: process.stdout.isTTY,\n    compact: false,\n    showHidden: false,\n  });\n};\n\n// Safe JSON parsing with error handling\nexport const safeJsonParse = <T = unknown>(str: string, fallback: T): T => {\n  try {\n    return JSON.parse(str);\n  } catch {\n    return fallback;\n  }\n};\n\n// Timeout utility for async operations\nexport const withTimeout = <T>(\n  promise: Promise<T>,\n  timeoutMs: number,\n  timeoutError: Error = new Error(\"Operation timed out\"),\n): Promise<T> => {\n  return Promise.race([\n    promise,\n    new Promise<T>((_, reject) => {\n      setTimeout(() => reject(timeoutError), timeoutMs);\n    }),\n  ]);\n};\n\n// Retry utility with exponential backoff\nexport const retry = async <T>(fn: () => Promise<T>, maxAttempts: number = 3, baseDelay: number = 1000): Promise<T> => {\n  let lastError: Error;\n\n  for (let attempt = 1; attempt <= maxAttempts; attempt++) {\n    try {\n      return await fn();\n    } catch (error) {\n      lastError = error as Error;\n\n      if (attempt === maxAttempts) {\n        throw lastError;\n      }\n\n      const delay = baseDelay * 2 ** (attempt - 1);\n      workerDebug(`Attempt ${attempt} failed, retrying in ${delay}ms: ${lastError.message}`);\n      await new Promise((resolve) => setTimeout(resolve, delay));\n    }\n  }\n\n  throw lastError!;\n};\n\n// Memory usage formatting\nexport const formatMemoryUsage = (bytes: number): string => {\n  const units = [\"B\", \"KB\", \"MB\", \"GB\"];\n  let size = bytes;\n  let unitIndex = 0;\n\n  while (size >= 1024 && unitIndex < units.length - 1) {\n    size /= 1024;\n    unitIndex++;\n  }\n\n  return `${size.toFixed(2)} ${units[unitIndex]}`;\n};\n\n// Performance timer utility\nexport const createTimer = () => {\n  const start = process.hrtime.bigint();\n\n  return {\n    elapsed: (): number => {\n      const end = process.hrtime.bigint();\n      return Number(end - start) / 1000000; // Convert to milliseconds\n    },\n\n    elapsedMicros: (): number => {\n      const end = process.hrtime.bigint();\n      return Number(end - start) / 1000; // Convert to microseconds\n    },\n  };\n};\n\n// Safe process exit handling\nexport const gracefulShutdown = (cleanup: () => Promise<void> | void) => {\n  const shutdown = async (signal: string) => {\n    workerDebug(`Received ${signal}, starting graceful shutdown`);\n    try {\n      await cleanup();\n      workerDebug(\"Cleanup completed, exiting\");\n      process.exit(0);\n    } catch (error) {\n      workerDebug(`Cleanup failed: ${error}`);\n      process.exit(1);\n    }\n  };\n\n  process.on(\"SIGTERM\", () => shutdown(\"SIGTERM\"));\n  process.on(\"SIGINT\", () => shutdown(\"SIGINT\"));\n  process.on(\"SIGUSR2\", () => shutdown(\"SIGUSR2\")); // For nodemon\n};\n"
  },
  {
    "path": "helpers/format.ts",
    "content": "import { homedir } from \"node:os\";\nimport { join } from \"node:path\";\n\nfunction isPlainObject(value: unknown): value is Record<string, unknown> {\n  return typeof value === \"object\" && value !== null && !Array.isArray(value);\n}\n\nfunction asBooleanRecord(value: unknown): Record<string, boolean> | undefined {\n  if (!isPlainObject(value)) return undefined;\n  const out: Record<string, boolean> = {};\n  for (const [k, v] of Object.entries(value)) {\n    if (typeof v !== \"boolean\") return undefined;\n    out[k] = v;\n  }\n  return out;\n}\n\nfunction asStringArray(value: unknown): string[] | undefined {\n  if (!Array.isArray(value)) return undefined;\n  if (value.every((v) => typeof v === \"string\")) return value;\n  return undefined;\n}\n\nfunction deepMerge(base: Record<string, unknown>, override: Record<string, unknown>): Record<string, unknown> {\n  const out: Record<string, unknown> = { ...base };\n  for (const [k, v] of Object.entries(override)) {\n    if (Array.isArray(v)) {\n      out[k] = v;\n    } else if (isPlainObject(v) && isPlainObject(out[k])) {\n      out[k] = deepMerge(out[k] as Record<string, unknown>, v);\n    } else {\n      out[k] = v;\n    }\n  }\n  return out;\n}\n\nfunction getUserConfigDir(): string {\n  // Linux/macOS: respect XDG_CONFIG_HOME; Windows best-effort.\n  if (process.platform === \"win32\") {\n    return process.env.APPDATA || join(homedir(), \"AppData\", \"Roaming\");\n  }\n  return process.env.XDG_CONFIG_HOME || join(homedir(), \".config\");\n}\n\nexport { isPlainObject, asBooleanRecord, asStringArray, deepMerge, getUserConfigDir };\n"
  },
  {
    "path": "helpers/fs.ts",
    "content": "import { mkdir, rename, unlink, writeFile } from \"node:fs/promises\";\nimport { dirname, join } from \"node:path\";\n\ntype WriteJsonAtomicOptions = {\n  tmpPrefix?: string;\n  fs?: {\n    mkdir?: typeof mkdir;\n    rename?: typeof rename;\n    unlink?: typeof unlink;\n    writeFile?: typeof writeFile;\n  };\n};\n\n/**\n * Write JSON data atomically using a temp file and rename.\n *\n * Uses a temp file in the same directory as the target to ensure rename is atomic\n * (same filesystem). Falls back to direct write only if same-directory temp fails,\n * with a warning that atomicity is not guaranteed.\n */\nexport async function writeJsonAtomic(path: string, data: unknown, options?: WriteJsonAtomicOptions): Promise<void> {\n  const fs = {\n    mkdir: options?.fs?.mkdir ?? mkdir,\n    rename: options?.fs?.rename ?? rename,\n    unlink: options?.fs?.unlink ?? unlink,\n    writeFile: options?.fs?.writeFile ?? writeFile,\n  };\n\n  const targetDir = dirname(path);\n  await fs.mkdir(targetDir, { recursive: true }).catch(() => {});\n\n  // Use temp file in same directory to ensure atomic rename (same filesystem)\n  const tmpName = `.${options?.tmpPrefix ?? \"opencode-orch\"}-${process.pid}-${Date.now()}-${Math.random().toString(16).slice(2)}.tmp`;\n  const tmp = join(targetDir, tmpName);\n\n  try {\n    await fs.writeFile(tmp, JSON.stringify(data, null, 2), \"utf8\");\n    await fs.rename(tmp, path);\n  } catch (_renameError) {\n    // Clean up temp file if it exists\n    await fs.unlink(tmp).catch(() => {});\n\n    // Last resort: direct write (not atomic, but better than failing)\n    // This should rarely happen since temp is in same directory\n    console.warn(\n      `[writeJsonAtomic] Atomic rename failed for ${path}, falling back to direct write. ` +\n        `Data integrity is not guaranteed if process crashes during write.`,\n    );\n    await fs.writeFile(path, JSON.stringify(data, null, 2), \"utf8\");\n  }\n}\n"
  },
  {
    "path": "helpers/process.ts",
    "content": "type IsProcessAliveOptions = {\n  treatEpermAsAlive?: boolean;\n};\n\nexport function isProcessAlive(pid: number, options?: IsProcessAliveOptions): boolean {\n  try {\n    process.kill(pid, 0);\n    return true;\n  } catch (err: unknown) {\n    if (\n      options?.treatEpermAsAlive &&\n      err &&\n      typeof err === \"object\" &&\n      \"code\" in err &&\n      (err as { code?: string }).code === \"EPERM\"\n    ) {\n      return true;\n    }\n    return false;\n  }\n}\n"
  },
  {
    "path": "index.ts",
    "content": "import { existsSync, readFileSync } from \"node:fs\";\nimport { join } from \"node:path\";\nimport type { Hooks, Plugin } from \"@opencode-ai/plugin\";\nimport { loadOrchestratorConfig } from \"./config/orchestrator\";\nimport { createCore } from \"./core\";\nimport { cleanupStaleWorkers } from \"./workers/pid-tracker\";\n\n/** Load .env file from a directory into process.env (silent, no overwrites). */\nfunction loadEnvFile(directory: string): void {\n  const envPath = join(directory, \".env\");\n  if (!existsSync(envPath)) return;\n  try {\n    const content = readFileSync(envPath, \"utf8\");\n    for (const line of content.split(\"\\n\")) {\n      const trimmed = line.trim();\n      if (!trimmed || trimmed.startsWith(\"#\")) continue;\n      const eqIndex = trimmed.indexOf(\"=\");\n      if (eqIndex === -1) continue;\n      const key = trimmed.slice(0, eqIndex).trim();\n      let value = trimmed.slice(eqIndex + 1).trim();\n      // Remove quotes if present\n      if ((value.startsWith('\"') && value.endsWith('\"')) || (value.startsWith(\"'\") && value.endsWith(\"'\"))) {\n        value = value.slice(1, -1);\n      }\n      // Don't overwrite existing env vars\n      if (key && process.env[key] === undefined) {\n        process.env[key] = value;\n      }\n    }\n  } catch {\n    // Silently ignore .env load failures\n  }\n}\n\nconst GLOBAL_KEY = \"__opencode_orchestra_core__\";\n\ntype GlobalCoreState = {\n  core?: ReturnType<typeof createCore>;\n  hooks?: Hooks;\n  startPromise?: Promise<void>;\n  exitHandlersSet?: boolean;\n};\n\nconst globalStore = globalThis as unknown as Record<string, GlobalCoreState | undefined>;\nconst existingState = globalStore[GLOBAL_KEY];\nconst globalState = existingState ?? {};\nif (existingState === undefined || existingState === null) {\n  globalStore[GLOBAL_KEY] = globalState;\n}\n\nexport const OrchestratorPlugin: Plugin = async (ctx) => {\n  // Load .env from project directory (before any other initialization)\n  loadEnvFile(ctx.directory);\n\n  if (process.env.OPENCODE_ORCHESTRATOR_WORKER === \"1\") {\n    return {};\n  }\n\n  if (globalState.hooks) {\n    return globalState.hooks;\n  }\n\n  if (globalState.startPromise) {\n    await globalState.startPromise;\n    return globalState.hooks ?? {};\n  }\n\n  globalState.startPromise = (async () => {\n    // Clean up stale worker entries from previous sessions (silent)\n    await cleanupStaleWorkers();\n\n    const { config } = await loadOrchestratorConfig({\n      directory: ctx.directory,\n      worktree: ctx.worktree || undefined,\n    });\n    const core = createCore({ config: { ctx, config }, deps: {} });\n    await core.start();\n    globalState.core = core;\n    globalState.hooks = core.hooks;\n\n    if (!globalState.exitHandlersSet) {\n      globalState.exitHandlersSet = true;\n      const onExit = async () => {\n        await core.stop().catch(() => {});\n      };\n      process.once(\"beforeExit\", () => {\n        void onExit();\n      });\n      process.once(\"SIGINT\", () => {\n        void onExit();\n        process.exit(130);\n      });\n      process.once(\"SIGTERM\", () => {\n        void onExit();\n        process.exit(143);\n      });\n    }\n  })();\n\n  await globalState.startPromise;\n  return globalState.hooks ?? {};\n};\n\nexport default OrchestratorPlugin;\nexport { createCommandRouter } from \"./commands\";\n"
  },
  {
    "path": "integrations/linear-config.ts",
    "content": "import type { LinearIntegrationConfig } from \"../types\";\nimport type { LinearConfig } from \"./linear-types\";\n\nconst DEFAULT_API_URL = \"https://api.linear.app/graphql\";\n\n/** Load Linear config from environment variables, if available. */\nexport const loadLinearConfigFromEnv = (): LinearConfig | undefined => {\n  const apiKey = process.env.LINEAR_API_KEY;\n  const teamId = process.env.LINEAR_TEAM_ID;\n  if (!apiKey || !teamId) return undefined;\n  return {\n    apiKey,\n    teamId,\n    apiUrl: process.env.LINEAR_API_URL || DEFAULT_API_URL,\n    projectPrefix: process.env.LINEAR_PROJECT_PREFIX || undefined,\n  };\n};\n\n/** Resolve Linear config from integration settings and environment variables. */\nexport const resolveLinearConfig = (input?: LinearIntegrationConfig): LinearConfig => {\n  if (input?.enabled === false) {\n    throw new Error(\"Linear integration is disabled.\");\n  }\n\n  const apiKey = input?.apiKey || process.env.LINEAR_API_KEY;\n  const teamId = input?.teamId || process.env.LINEAR_TEAM_ID;\n  if (!apiKey || !teamId) {\n    throw new Error(\"Missing Linear credentials. Set LINEAR_API_KEY and LINEAR_TEAM_ID.\");\n  }\n\n  return {\n    apiKey,\n    teamId,\n    apiUrl: input?.apiUrl || process.env.LINEAR_API_URL || DEFAULT_API_URL,\n    projectPrefix: input?.projectPrefix || process.env.LINEAR_PROJECT_PREFIX || undefined,\n  };\n};\n"
  },
  {
    "path": "integrations/linear-issues.ts",
    "content": "import { linearRequest } from \"./linear-request\";\nimport { getTeamStates, normalizeStatus } from \"./linear-teams\";\nimport type { LinearConfig, LinearIssue } from \"./linear-types\";\n\n/** Create a new issue in Linear. */\nexport const createIssue = async (input: {\n  cfg: LinearConfig;\n  title: string;\n  description?: string;\n  projectId?: string;\n  priority?: number;\n  estimate?: number;\n}): Promise<{ issueId: string; identifier?: string; url?: string }> => {\n  const data = await linearRequest<{\n    issueCreate: { success: boolean; issue?: LinearIssue };\n  }>(\n    input.cfg,\n    `mutation CreateIssue($input: IssueCreateInput!) {\n      issueCreate(input: $input) {\n        success\n        issue { id identifier url }\n      }\n    }`,\n    {\n      input: {\n        title: input.title,\n        description: input.description,\n        teamId: input.cfg.teamId,\n        projectId: input.projectId,\n        priority: input.priority,\n        estimate: input.estimate,\n      },\n    },\n  );\n\n  const issue = data.issueCreate.issue;\n  if (!issue?.id) throw new Error(\"Linear API error: Issue not created.\");\n  return { issueId: issue.id, identifier: issue.identifier, url: issue.url ?? undefined };\n};\n\n/** Update fields on an existing Linear issue. */\nexport const updateIssue = async (input: {\n  cfg: LinearConfig;\n  issueId: string;\n  title?: string;\n  description?: string;\n  stateId?: string;\n  priority?: number;\n  estimate?: number;\n  labelIds?: string[];\n  projectId?: string;\n  assigneeId?: string;\n}): Promise<{ issueId: string; title?: string; url?: string }> => {\n  const data = await linearRequest<{\n    issueUpdate: { success: boolean; issue?: LinearIssue };\n  }>(\n    input.cfg,\n    `mutation UpdateIssue($input: IssueUpdateInput!) {\n      issueUpdate(input: $input) {\n        success\n        issue { id title url }\n      }\n    }`,\n    {\n      input: {\n        id: input.issueId,\n        title: input.title,\n        description: input.description,\n        stateId: input.stateId,\n        priority: input.priority,\n        estimate: input.estimate,\n        labelIds: input.labelIds,\n        projectId: input.projectId,\n        assigneeId: input.assigneeId,\n      },\n    },\n  );\n\n  const issue = data.issueUpdate.issue;\n  if (!issue?.id) throw new Error(\"Linear API error: Issue not updated.\");\n  return { issueId: issue.id, title: issue.title, url: issue.url ?? undefined };\n};\n\n/** Add a comment to a Linear issue. */\nexport const addComment = async (input: {\n  cfg: LinearConfig;\n  issueId: string;\n  body: string;\n}): Promise<{ commentId: string; url?: string }> => {\n  const data = await linearRequest<{\n    commentCreate: { success: boolean; comment?: { id: string; url?: string } };\n  }>(\n    input.cfg,\n    `mutation AddComment($input: CommentCreateInput!) {\n      commentCreate(input: $input) {\n        success\n        comment { id url }\n      }\n    }`,\n    {\n      input: {\n        issueId: input.issueId,\n        body: input.body,\n      },\n    },\n  );\n\n  const comment = data.commentCreate.comment;\n  if (!comment?.id) throw new Error(\"Linear API error: Comment not created.\");\n  return { commentId: comment.id, url: comment.url ?? undefined };\n};\n\n/** Fetch a Linear issue by ID. */\nexport const getIssue = async (input: { cfg: LinearConfig; issueId: string }): Promise<LinearIssue> => {\n  const data = await linearRequest<{ issue: LinearIssue }>(\n    input.cfg,\n    `query GetIssue($id: String!) {\n      issue(id: $id) {\n        id\n        identifier\n        title\n        description\n        url\n        priority\n        estimate\n        state { id name type }\n        labels { nodes { id name } }\n        assignee { id name }\n        project { id name }\n      }\n    }`,\n    { id: input.issueId },\n  );\n\n  if (!data.issue?.id) throw new Error(\"Linear API error: Issue not found.\");\n  return data.issue;\n};\n\n/** Fetch label IDs currently applied to a Linear issue. */\nexport const getIssueLabelIds = async (input: { cfg: LinearConfig; issueId: string }): Promise<string[]> => {\n  const data = await linearRequest<{\n    issue: { labels: { nodes: Array<{ id: string }> } };\n  }>(\n    input.cfg,\n    `query IssueLabels($id: ID!) {\n      issue(id: $id) {\n        labels { nodes { id } }\n      }\n    }`,\n    { id: input.issueId },\n  );\n\n  return data.issue?.labels?.nodes?.map((label) => label.id) ?? [];\n};\n\n/** Add a label to a Linear issue, preserving existing labels. */\nexport const addLabel = async (input: {\n  cfg: LinearConfig;\n  issueId: string;\n  labelId: string;\n}): Promise<{ issueId: string; labelIds: string[] }> => {\n  const existing = await getIssueLabelIds({ cfg: input.cfg, issueId: input.issueId });\n  const next = Array.from(new Set([...existing, input.labelId]));\n  await updateIssue({ cfg: input.cfg, issueId: input.issueId, labelIds: next });\n  return { issueId: input.issueId, labelIds: next };\n};\n\n/** Set an estimate on a Linear issue. */\nexport const setEstimate = async (input: {\n  cfg: LinearConfig;\n  issueId: string;\n  estimate: number;\n}): Promise<{ issueId: string; estimate: number }> => {\n  await updateIssue({ cfg: input.cfg, issueId: input.issueId, estimate: input.estimate });\n  return { issueId: input.issueId, estimate: input.estimate };\n};\n\n/** Map a status label to a Linear workflow state and update the issue. */\nexport const syncTaskStatus = async (input: {\n  cfg: LinearConfig;\n  issueId: string;\n  status: string;\n}): Promise<{ issueId: string; stateId: string }> => {\n  const states = await getTeamStates({ cfg: input.cfg });\n  const desired = normalizeStatus(input.status);\n\n  const typeMap: Record<string, string> = {\n    backlog: \"backlog\",\n    todo: \"unstarted\",\n    unstarted: \"unstarted\",\n    in_progress: \"started\",\n    started: \"started\",\n    review: \"started\",\n    done: \"completed\",\n    completed: \"completed\",\n    canceled: \"canceled\",\n  };\n\n  const desiredType = typeMap[desired];\n  const byType = desiredType ? states.find((state) => state.type?.toLowerCase() === desiredType) : undefined;\n  const byName = states.find((state) => normalizeStatus(state.name || \"\") === desired);\n  const chosen = byType || byName;\n  if (!chosen?.id) {\n    throw new Error(`Linear API error: No matching state for status '${input.status}'.`);\n  }\n\n  await updateIssue({ cfg: input.cfg, issueId: input.issueId, stateId: chosen.id });\n  return { issueId: input.issueId, stateId: chosen.id };\n};\n"
  },
  {
    "path": "integrations/linear-projects.ts",
    "content": "import { linearRequest } from \"./linear-request\";\nimport type { LinearConfig, LinearProject, LinearProjectStatus } from \"./linear-types\";\n\nconst applyProjectPrefix = (cfg: LinearConfig, name: string): string => {\n  const prefix = cfg.projectPrefix;\n  if (!prefix) return name;\n  const normalized = `${prefix}-`;\n  if (name.startsWith(normalized)) return name;\n  return `${normalized}${name}`;\n};\n\n/** Fetch the current Linear viewer identity. */\nexport const getViewer = async (cfg: LinearConfig): Promise<{ id: string; name?: string; email?: string }> => {\n  const data = await linearRequest<{ viewer: { id: string; name?: string; email?: string } }>(\n    cfg,\n    \"query Viewer { viewer { id name email } }\",\n  );\n  return data.viewer;\n};\n\n/** Create a new Linear project. */\nexport const createProject = async (input: {\n  cfg: LinearConfig;\n  name: string;\n  description?: string;\n  teamId?: string;\n}): Promise<{ projectId: string; name?: string; url?: string }> => {\n  const name = applyProjectPrefix(input.cfg, input.name);\n  const data = await linearRequest<{\n    projectCreate: { success: boolean; project?: LinearProject };\n  }>(\n    input.cfg,\n    `mutation CreateProject($input: ProjectCreateInput!) {\n      projectCreate(input: $input) {\n        success\n        project { id name url }\n      }\n    }`,\n    {\n      input: {\n        name,\n        description: input.description,\n        teamId: input.teamId ?? input.cfg.teamId,\n      },\n    },\n  );\n\n  const project = data.projectCreate.project;\n  if (!project?.id) throw new Error(\"Linear API error: Project not created.\");\n  return { projectId: project.id, name: project.name, url: project.url ?? undefined };\n};\n\n/** Fetch status fields for a Linear project. */\nexport const getProjectStatus = async (input: {\n  cfg: LinearConfig;\n  projectId: string;\n}): Promise<LinearProjectStatus> => {\n  const data = await linearRequest<{ project: LinearProject }>(\n    input.cfg,\n    `query ProjectStatus($id: ID!) {\n      project(id: $id) {\n        id\n        name\n        state\n        url\n        progress\n        issueCount\n        completedIssueCount\n      }\n    }`,\n    { id: input.projectId },\n  );\n\n  if (!data.project?.id) throw new Error(\"Linear API error: Project not found.\");\n  return { project: data.project };\n};\n"
  },
  {
    "path": "integrations/linear-request.ts",
    "content": "import type { LinearConfig } from \"./linear-types\";\n\ntype LinearGraphQLError = {\n  message: string;\n};\n\ntype LinearGraphQLResponse<T> = {\n  data?: T;\n  errors?: LinearGraphQLError[];\n};\n\nexport const linearRequest = async <T>(\n  cfg: LinearConfig,\n  query: string,\n  variables?: Record<string, unknown>,\n): Promise<T> => {\n  const response = await fetch(cfg.apiUrl, {\n    method: \"POST\",\n    headers: {\n      \"Content-Type\": \"application/json\",\n      Authorization: cfg.apiKey,\n    },\n    body: JSON.stringify({ query, variables }),\n  });\n\n  const text = await response.text();\n  if (!response.ok) {\n    throw new Error(`Linear API error: HTTP ${response.status} ${response.statusText}`);\n  }\n\n  let payload: LinearGraphQLResponse<T>;\n  try {\n    payload = JSON.parse(text) as LinearGraphQLResponse<T>;\n  } catch {\n    throw new Error(\"Linear API error: Invalid JSON response.\");\n  }\n\n  if (payload.errors && payload.errors.length > 0) {\n    throw new Error(`Linear API error: ${payload.errors.map((e) => e.message).join(\"; \")}`);\n  }\n  if (!payload.data) {\n    throw new Error(\"Linear API error: Missing response data.\");\n  }\n  return payload.data;\n};\n"
  },
  {
    "path": "integrations/linear-teams.ts",
    "content": "import { linearRequest } from \"./linear-request\";\nimport type { LinearConfig, LinearTeamState } from \"./linear-types\";\n\n/** Fetch workflow states for a Linear team. */\nexport const getTeamStates = async (input: { cfg: LinearConfig; teamId?: string }): Promise<LinearTeamState[]> => {\n  const data = await linearRequest<{\n    team: { states: { nodes: LinearTeamState[] } };\n  }>(\n    input.cfg,\n    `query TeamStates($id: ID!) {\n      team(id: $id) {\n        states {\n          nodes { id name type }\n        }\n      }\n    }`,\n    { id: input.teamId ?? input.cfg.teamId },\n  );\n\n  return data.team?.states?.nodes ?? [];\n};\n\n/** Normalize a status string to a slug-friendly format. */\nexport const normalizeStatus = (status: string): string => status.trim().toLowerCase().replace(/\\s+/g, \"_\");\n"
  },
  {
    "path": "integrations/linear-types.ts",
    "content": "export type LinearConfig = {\n  apiKey: string;\n  teamId: string;\n  apiUrl: string;\n  projectPrefix?: string;\n};\n\nexport type LinearIssue = {\n  id: string;\n  title?: string;\n  url?: string;\n  identifier?: string;\n};\n\nexport type LinearProject = {\n  id: string;\n  name?: string;\n  state?: string;\n  url?: string;\n  progress?: number | null;\n  issueCount?: number | null;\n  completedIssueCount?: number | null;\n};\n\nexport type LinearProjectStatus = {\n  project: LinearProject;\n};\n\nexport type LinearTeamState = {\n  id: string;\n  name?: string;\n  type?: string;\n};\n"
  },
  {
    "path": "integrations/linear.ts",
    "content": "export { loadLinearConfigFromEnv, resolveLinearConfig } from \"./linear-config\";\nexport {\n  addComment,\n  addLabel,\n  createIssue,\n  getIssue,\n  getIssueLabelIds,\n  setEstimate,\n  syncTaskStatus,\n  updateIssue,\n} from \"./linear-issues\";\nexport { createProject, getProjectStatus, getViewer } from \"./linear-projects\";\nexport { getTeamStates } from \"./linear-teams\";\nexport type {\n  LinearConfig,\n  LinearIssue,\n  LinearProject,\n  LinearProjectStatus,\n  LinearTeamState,\n} from \"./linear-types\";\n"
  },
  {
    "path": "integrations/registry.ts",
    "content": "import type { ToolDefinition } from \"@opencode-ai/plugin\";\nimport { isPlainObject } from \"../helpers/format\";\nimport { createLinearTools } from \"../tools/linear-tools\";\nimport type { IntegrationsConfig, LinearIntegrationConfig } from \"../types\";\nimport { resolveLinearConfig } from \"./linear-config\";\nimport type { LinearConfig } from \"./linear-types\";\n\nexport type IntegrationToolGroup = {\n  orchestrator?: Record<string, ToolDefinition>;\n  workers?: Record<string, ToolDefinition>;\n};\n\nexport type IntegrationDefinition = {\n  key: string;\n  resolveConfig?: (config: unknown) => unknown | undefined;\n  toEnv?: (config: unknown) => Record<string, string>;\n  tools?: (input: { config: unknown }) => IntegrationToolGroup;\n};\n\nconst registry = new Map<string, IntegrationDefinition>();\n\nexport const registerIntegration = (definition: IntegrationDefinition): void => {\n  registry.set(definition.key, definition);\n};\n\nconst resolveConfigSafe = (definition: IntegrationDefinition, config: unknown): unknown | undefined => {\n  if (!definition.resolveConfig) return config;\n  try {\n    return definition.resolveConfig(config);\n  } catch {\n    return undefined;\n  }\n};\n\nexport const getIntegrationTools = (\n  integrations?: IntegrationsConfig,\n): { orchestrator: Record<string, ToolDefinition>; workers: Record<string, ToolDefinition> } => {\n  const raw = (integrations ?? {}) as Record<string, unknown>;\n  const orchestrator: Record<string, ToolDefinition> = {};\n  const workers: Record<string, ToolDefinition> = {};\n\n  for (const definition of registry.values()) {\n    if (!definition.tools) continue;\n    const resolved = resolveConfigSafe(definition, raw[definition.key]);\n    if (resolved === undefined) continue;\n\n    const tools = definition.tools({ config: raw[definition.key] });\n    if (tools.orchestrator) Object.assign(orchestrator, tools.orchestrator);\n    if (tools.workers) Object.assign(workers, tools.workers);\n  }\n\n  return { orchestrator, workers };\n};\n\nexport const getIntegrationEnv = (integrations: Record<string, unknown>): Record<string, string> => {\n  const env: Record<string, string> = {};\n  for (const definition of registry.values()) {\n    if (!definition.toEnv) continue;\n    const resolved = resolveConfigSafe(definition, integrations[definition.key]);\n    if (resolved === undefined) continue;\n    Object.assign(env, definition.toEnv(resolved));\n  }\n  return env;\n};\n\nconst toLinearEnv = (cfg: LinearConfig): Record<string, string> => {\n  const env: Record<string, string> = {};\n  if (cfg.apiKey) env.LINEAR_API_KEY = cfg.apiKey;\n  if (cfg.teamId) env.LINEAR_TEAM_ID = cfg.teamId;\n  if (cfg.apiUrl) env.LINEAR_API_URL = cfg.apiUrl;\n  if (cfg.projectPrefix) env.LINEAR_PROJECT_PREFIX = cfg.projectPrefix;\n  return env;\n};\n\nregisterIntegration({\n  key: \"linear\",\n  resolveConfig: (config) => resolveLinearConfig(config as LinearIntegrationConfig | undefined),\n  toEnv: (config) => toLinearEnv(config as LinearConfig),\n  tools: (input) => createLinearTools({ config: input.config as LinearIntegrationConfig }),\n});\n\nregisterIntegration({\n  key: \"neo4j\",\n  resolveConfig: (config) => {\n    if (!isPlainObject(config)) return undefined;\n    if (config.enabled === false) return undefined;\n    return config;\n  },\n  toEnv: (config) => {\n    if (!isPlainObject(config)) return {};\n    const env: Record<string, string> = {};\n    if (typeof config.uri === \"string\") env.OPENCODE_NEO4J_URI = config.uri;\n    if (typeof config.username === \"string\") env.OPENCODE_NEO4J_USERNAME = config.username;\n    if (typeof config.password === \"string\") env.OPENCODE_NEO4J_PASSWORD = config.password;\n    if (typeof config.database === \"string\") env.OPENCODE_NEO4J_DATABASE = config.database;\n    return env;\n  },\n});\n"
  },
  {
    "path": "integrations/selection.ts",
    "content": "import type { IntegrationsConfig, WorkerProfile } from \"../types\";\n\nexport const resolveIntegrationsForProfile = (\n  profile: WorkerProfile,\n  globalIntegrations?: IntegrationsConfig,\n): Record<string, unknown> => {\n  const selection = profile.integrations;\n  if (!selection) return {};\n\n  const integrations = (globalIntegrations ?? {}) as Record<string, unknown>;\n  const resolved: Record<string, unknown> = {};\n\n  if (selection.inheritAll) {\n    for (const [key, value] of Object.entries(integrations)) {\n      if (value !== undefined) resolved[key] = value;\n    }\n  }\n\n  if (selection.include && selection.include.length > 0) {\n    for (const key of selection.include) {\n      if (key in integrations) resolved[key] = integrations[key];\n    }\n  }\n\n  if (selection.exclude && selection.exclude.length > 0) {\n    for (const key of selection.exclude) {\n      delete resolved[key];\n    }\n  }\n\n  return resolved;\n};\n"
  },
  {
    "path": "memory/auto.ts",
    "content": "import type { MemoryNode } from \"./graph/shared\";\nimport { loadNeo4jConfig, type Neo4jConfig } from \"./neo4j\";\nimport type { MemoryScope } from \"./store\";\nimport { getMemoryByKey, linkMemory, trimGlobalMessageProjects, trimMemoryByKeyPrefix, upsertMemory } from \"./store\";\nimport { appendRollingSummary, normalizeForMemory } from \"./text\";\n\nexport type MessageMemoryInput = {\n  cfg?: Neo4jConfig;\n  text: string;\n  sessionId?: string;\n  messageId?: string;\n  role?: string;\n  userId?: string;\n  scope: MemoryScope;\n  projectId?: string;\n  maxChars?: number;\n  deps?: {\n    loadNeo4jConfig?: typeof loadNeo4jConfig;\n    upsertMemory?: typeof upsertMemory;\n    linkMemory?: typeof linkMemory;\n    getMemoryByKey?: typeof getMemoryByKey;\n    trimMemoryByKeyPrefix?: typeof trimMemoryByKeyPrefix;\n    trimGlobalMessageProjects?: typeof trimGlobalMessageProjects;\n  };\n  summaries?: {\n    enabled?: boolean;\n    sessionMaxChars?: number;\n    projectMaxChars?: number;\n  };\n  trim?: {\n    maxMessagesPerSession?: number;\n    maxMessagesPerProject?: number;\n    maxMessagesGlobal?: number;\n    maxProjectsGlobal?: number;\n  };\n};\n\nfunction clamp(n: number, min: number, max: number): number {\n  return Math.max(min, Math.min(max, n));\n}\n\nexport async function recordMessageMemory(input: MessageMemoryInput): Promise<void> {\n  const deps = input.deps ?? {};\n  const loadNeo4jConfigFn = deps.loadNeo4jConfig ?? loadNeo4jConfig;\n  const upsertMemoryFn = deps.upsertMemory ?? upsertMemory;\n  const linkMemoryFn = deps.linkMemory ?? linkMemory;\n  const getMemoryByKeyFn = deps.getMemoryByKey ?? getMemoryByKey;\n  const trimMemoryByKeyPrefixFn = deps.trimMemoryByKeyPrefix ?? trimMemoryByKeyPrefix;\n  const trimGlobalMessageProjectsFn = deps.trimGlobalMessageProjects ?? trimGlobalMessageProjects;\n\n  const cfg = input.cfg ?? loadNeo4jConfigFn();\n\n  const text = input.text.trim();\n  if (!text) return;\n\n  const maxChars = clamp(input.maxChars ?? 2000, 100, 8000);\n  const keyBase = input.messageId ?? `${Date.now()}`;\n  const session = input.sessionId ?? \"unknown\";\n  const role = input.role ?? \"unknown\";\n  const userId = input.userId ?? \"unknown\";\n  const projectId = input.projectId;\n  const key =\n    input.scope === \"global\"\n      ? `message:${projectId ?? \"unknown\"}:${session}:${keyBase}`\n      : `message:${session}:${keyBase}`;\n\n  const tags = [\"message\", role, `session:${session}`, `user:${userId}`];\n  if (projectId) tags.push(`project:${projectId}`);\n\n  try {\n    await upsertMemoryFn({\n      cfg,\n      scope: input.scope,\n      projectId: input.scope === \"project\" ? input.projectId : undefined,\n      key,\n      value: normalizeForMemory(text, maxChars),\n      tags,\n    });\n  } catch {}\n\n  const projectKey = projectId ? `project:${projectId}` : undefined;\n  const userKey = `user:${userId}`;\n\n  try {\n    await upsertMemoryFn({\n      cfg,\n      scope: input.scope,\n      projectId: input.scope === \"project\" ? projectId : undefined,\n      key: userKey,\n      value: `User ${userId}`,\n      tags: [\"user\"],\n    });\n  } catch {}\n\n  // Also keep a lightweight global index of known users/projects for cross-project retrieval.\n  try {\n    await upsertMemoryFn({\n      cfg,\n      scope: \"global\",\n      key: userKey,\n      value: `User ${userId}`,\n      tags: [\"user\"],\n    });\n  } catch {}\n\n  if (projectKey) {\n    try {\n      await upsertMemoryFn({\n        cfg,\n        scope: input.scope === \"project\" ? \"project\" : \"global\",\n        ...(input.scope === \"project\" ? { projectId } : {}),\n        key: projectKey,\n        value: `Project ${projectId}`,\n        tags: [\"project\"],\n      });\n    } catch {}\n\n    try {\n      await upsertMemoryFn({\n        cfg,\n        scope: \"global\",\n        key: projectKey,\n        value: `Project ${projectId}`,\n        tags: [\"project\"],\n      });\n    } catch {}\n  }\n\n  try {\n    await linkMemoryFn({\n      cfg,\n      scope: input.scope,\n      projectId: input.scope === \"project\" ? projectId : undefined,\n      fromKey: key,\n      toKey: userKey,\n      type: \"belongs_to_user\",\n    });\n  } catch {}\n\n  if (projectKey) {\n    try {\n      await linkMemoryFn({\n        cfg,\n        scope: input.scope,\n        projectId: input.scope === \"project\" ? projectId : undefined,\n        fromKey: key,\n        toKey: projectKey,\n        type: \"belongs_to_project\",\n      });\n    } catch {}\n  }\n\n  const summariesEnabled = input.summaries?.enabled !== false;\n  if (summariesEnabled && projectId) {\n    const entrySnippet = normalizeForMemory(text, 420);\n    const entry = `- ${new Date().toISOString()} [${role}/${userId}] ${entrySnippet}`;\n\n    const projectMaxChars = clamp(input.summaries?.projectMaxChars ?? 2000, 200, 20000);\n    const globalProjectSummaryKey = `summary:project:${projectId}`;\n\n    if (input.scope === \"project\") {\n      let prev: MemoryNode | undefined;\n      try {\n        prev = await getMemoryByKeyFn({ cfg, scope: \"project\", projectId, key: \"summary:project\" });\n      } catch {\n        prev = undefined;\n      }\n      const next = appendRollingSummary(prev?.value, entry, projectMaxChars);\n      try {\n        await upsertMemoryFn({\n          cfg,\n          scope: \"project\",\n          projectId,\n          key: \"summary:project\",\n          value: next,\n          tags: [\"summary\", \"project\"],\n        });\n      } catch {}\n\n      const sessionMaxChars = clamp(input.summaries?.sessionMaxChars ?? 2000, 200, 20000);\n      const sessionKey = `summary:session:${session}`;\n      let prevSession: MemoryNode | undefined;\n      try {\n        prevSession = await getMemoryByKeyFn({ cfg, scope: \"project\", projectId, key: sessionKey });\n      } catch {\n        prevSession = undefined;\n      }\n      const nextSession = appendRollingSummary(prevSession?.value, entry, sessionMaxChars);\n      try {\n        await upsertMemoryFn({\n          cfg,\n          scope: \"project\",\n          projectId,\n          key: sessionKey,\n          value: nextSession,\n          tags: [\"summary\", \"session\", `session:${session}`],\n        });\n      } catch {}\n    }\n\n    // Always update a global per-project summary for cross-project retrieval.\n    let prevGlobal: MemoryNode | undefined;\n    try {\n      prevGlobal = await getMemoryByKeyFn({ cfg, scope: \"global\", key: globalProjectSummaryKey });\n    } catch {\n      prevGlobal = undefined;\n    }\n    const nextGlobal = appendRollingSummary(prevGlobal?.value, entry, projectMaxChars);\n    try {\n      await upsertMemoryFn({\n        cfg,\n        scope: \"global\",\n        key: globalProjectSummaryKey,\n        value: nextGlobal,\n        tags: [\"summary\", \"project\", `project:${projectId}`],\n      });\n    } catch {}\n  }\n\n  // Trimming: keep memory bounded.\n  const maxPerSession = input.trim?.maxMessagesPerSession;\n  const maxPerProject = input.trim?.maxMessagesPerProject;\n  const maxGlobal = input.trim?.maxMessagesGlobal;\n  const maxProjectsGlobal = input.trim?.maxProjectsGlobal;\n\n  const sessionLimit = typeof maxPerSession === \"number\" ? clamp(maxPerSession, 0, 10000) : undefined;\n  const projectLimit = typeof maxPerProject === \"number\" ? clamp(maxPerProject, 0, 100000) : undefined;\n  const globalLimit = typeof maxGlobal === \"number\" ? clamp(maxGlobal, 0, 200000) : undefined;\n  const projectsLimit = typeof maxProjectsGlobal === \"number\" ? clamp(maxProjectsGlobal, 0, 10000) : undefined;\n\n  if (sessionLimit !== undefined) {\n    const prefix = input.scope === \"global\" ? `message:${projectId ?? \"unknown\"}:${session}:` : `message:${session}:`;\n    try {\n      await trimMemoryByKeyPrefixFn({\n        cfg,\n        scope: input.scope,\n        projectId: input.scope === \"project\" ? projectId : undefined,\n        keyPrefix: prefix,\n        keepLatest: sessionLimit,\n      });\n    } catch {}\n  }\n\n  if (projectLimit !== undefined && projectId) {\n    const prefix = input.scope === \"global\" ? `message:${projectId}:` : \"message:\";\n    try {\n      await trimMemoryByKeyPrefixFn({\n        cfg,\n        scope: input.scope,\n        projectId: input.scope === \"project\" ? projectId : undefined,\n        keyPrefix: prefix,\n        keepLatest: projectLimit,\n      });\n    } catch {}\n  }\n\n  if (input.scope === \"global\" && globalLimit !== undefined) {\n    try {\n      await trimMemoryByKeyPrefixFn({ cfg, scope: \"global\", keyPrefix: \"message:\", keepLatest: globalLimit });\n    } catch {}\n  }\n\n  if (input.scope === \"global\" && projectsLimit !== undefined) {\n    try {\n      await trimGlobalMessageProjectsFn({ cfg, keepProjects: projectsLimit });\n    } catch {}\n  }\n}\n"
  },
  {
    "path": "memory/graph.ts",
    "content": "import type { Record } from \"neo4j-driver\";\nimport type { MemoryNode, MemoryRecordShape, MemoryScope } from \"./graph/shared\";\nimport { requireProjectId, toNode } from \"./graph/shared\";\nimport type { Neo4jConfig } from \"./neo4j\";\nimport { withNeo4jSession } from \"./neo4j\";\n\nexport async function upsertMemory(input: {\n  cfg: Neo4jConfig;\n  scope: MemoryScope;\n  projectId?: string;\n  key: string;\n  value: string;\n  tags?: string[];\n  deps?: { withSession?: typeof withNeo4jSession };\n}): Promise<MemoryNode> {\n  const scope = input.scope;\n  const projectId = requireProjectId(scope, input.projectId);\n  const withSession = input.deps?.withSession ?? withNeo4jSession;\n\n  return await withSession(input.cfg, async (session) => {\n    const mergePattern =\n      scope === \"project\" ? `{ scope: $scope, projectId: $projectId, key: $key }` : `{ scope: $scope, key: $key }`;\n    const res = await session.run(\n      `\nMERGE (n:Memory ${mergePattern})\nON CREATE SET n.createdAt = timestamp()\nSET n.value = $value,\n    n.tags = $tags,\n    n.updatedAt = timestamp()\nRETURN n\n      `.trim(),\n      {\n        scope,\n        ...(scope === \"project\" ? { projectId } : {}),\n        key: input.key,\n        value: input.value,\n        tags: input.tags ?? [],\n      },\n    );\n    const rec = res.records?.[0] as Record<MemoryRecordShape> | undefined;\n    if (!rec) throw new Error(\"No record returned from Neo4j\");\n    return toNode(rec);\n  });\n}\n\nexport async function linkMemory(input: {\n  cfg: Neo4jConfig;\n  scope: MemoryScope;\n  projectId?: string;\n  fromKey: string;\n  toKey: string;\n  type?: string;\n  deps?: { withSession?: typeof withNeo4jSession };\n}): Promise<{ ok: true }> {\n  const scope = input.scope;\n  const projectId = requireProjectId(scope, input.projectId);\n  const type = input.type ?? \"relates_to\";\n  const withSession = input.deps?.withSession ?? withNeo4jSession;\n\n  await withSession(input.cfg, async (session) => {\n    await session.run(\n      `\nMATCH (a:Memory ${scope === \"project\" ? `{ scope: $scope, projectId: $projectId, key: $fromKey }` : `{ scope: $scope, key: $fromKey }`})\nMATCH (b:Memory ${scope === \"project\" ? `{ scope: $scope, projectId: $projectId, key: $toKey }` : `{ scope: $scope, key: $toKey }`})\nMERGE (a)-[r:RELATES_TO { type: $type }]->(b)\nSET r.updatedAt = timestamp()\nRETURN r\n      `.trim(),\n      {\n        scope,\n        ...(scope === \"project\" ? { projectId } : {}),\n        fromKey: input.fromKey,\n        toKey: input.toKey,\n        type,\n      },\n    );\n  });\n\n  return { ok: true };\n}\n\nexport async function getMemoryByKey(input: {\n  cfg: Neo4jConfig;\n  scope: MemoryScope;\n  projectId?: string;\n  key: string;\n  deps?: { withSession?: typeof withNeo4jSession };\n}): Promise<MemoryNode | undefined> {\n  const scope = input.scope;\n  const projectId = requireProjectId(scope, input.projectId);\n  const withSession = input.deps?.withSession ?? withNeo4jSession;\n\n  return await withSession(input.cfg, async (session) => {\n    const matchPattern =\n      scope === \"project\" ? `{ scope: $scope, projectId: $projectId, key: $key }` : `{ scope: $scope, key: $key }`;\n    const res = await session.run(\n      `\nMATCH (n:Memory ${matchPattern})\nRETURN n\nLIMIT 1\n      `.trim(),\n      {\n        scope,\n        ...(scope === \"project\" ? { projectId } : {}),\n        key: input.key,\n      },\n    );\n    const rec = res.records?.[0] as Record<MemoryRecordShape> | undefined;\n    if (!rec) return undefined;\n    return toNode(rec);\n  });\n}\n\nexport async function searchMemory(input: {\n  cfg: Neo4jConfig;\n  scope: MemoryScope;\n  projectId?: string;\n  query: string;\n  limit?: number;\n  deps?: { withSession?: typeof withNeo4jSession };\n}): Promise<MemoryNode[]> {\n  const scope = input.scope;\n  const projectId = requireProjectId(scope, input.projectId);\n  const limit = Math.floor(Math.max(1, Math.min(50, input.limit ?? 10)));\n  const withSession = input.deps?.withSession ?? withNeo4jSession;\n\n  return await withSession(input.cfg, async (session) => {\n    const matchPattern = scope === \"project\" ? `{ scope: $scope, projectId: $projectId }` : `{ scope: $scope }`;\n    const res = await session.run(\n      `\nMATCH (n:Memory ${matchPattern})\nWHERE toLower(n.key) CONTAINS toLower($q)\n   OR toLower(n.value) CONTAINS toLower($q)\n   OR any(t IN coalesce(n.tags, []) WHERE toLower(t) CONTAINS toLower($q))\nRETURN n\nORDER BY n.updatedAt DESC\nLIMIT toInteger($limit)\n      `.trim(),\n      {\n        scope,\n        ...(scope === \"project\" ? { projectId } : {}),\n        q: input.query,\n        limit,\n      },\n    );\n    return res.records.map((r) => toNode(r as Record<MemoryRecordShape>));\n  });\n}\n\nexport async function recentMemory(input: {\n  cfg: Neo4jConfig;\n  scope: MemoryScope;\n  projectId?: string;\n  limit?: number;\n  deps?: { withSession?: typeof withNeo4jSession };\n}): Promise<MemoryNode[]> {\n  const scope = input.scope;\n  const projectId = requireProjectId(scope, input.projectId);\n  const limit = Math.floor(Math.max(1, Math.min(50, input.limit ?? 10)));\n  const withSession = input.deps?.withSession ?? withNeo4jSession;\n\n  return await withSession(input.cfg, async (session) => {\n    const matchPattern = scope === \"project\" ? `{ scope: $scope, projectId: $projectId }` : `{ scope: $scope }`;\n    const res = await session.run(\n      `\nMATCH (n:Memory ${matchPattern})\nRETURN n\nORDER BY n.updatedAt DESC\nLIMIT toInteger($limit)\n      `.trim(),\n      {\n        scope,\n        ...(scope === \"project\" ? { projectId } : {}),\n        limit,\n      },\n    );\n    return res.records.map((r) => toNode(r as Record<MemoryRecordShape>));\n  });\n}\n\nexport type { MemoryNode, MemoryScope };\nexport { trimGlobalMessageProjects, trimMemoryByKeyPrefix } from \"./graph/trim\";\n"
  },
  {
    "path": "memory/graph/shared.ts",
    "content": "import type { Node, Record } from \"neo4j-driver\";\n\nexport type MemoryScope = \"global\" | \"project\";\n\n/**\n * Properties stored on a Memory node in Neo4j.\n */\nexport type MemoryNodeProperties = {\n  scope: string;\n  projectId?: string;\n  key: string;\n  value: string;\n  tags?: string[];\n  createdAt?: number;\n  updatedAt?: number;\n};\n\n/**\n * The shape of a Neo4j record containing a Memory node under key \"n\".\n */\nexport type MemoryRecordShape = {\n  n: Node<number, MemoryNodeProperties>;\n};\n\nexport type MemoryNode = {\n  scope: MemoryScope;\n  projectId?: string;\n  key: string;\n  value: string;\n  tags: string[];\n  createdAt?: number;\n  updatedAt?: number;\n};\n\nexport function requireProjectId(scope: MemoryScope, projectId: string | undefined): string | undefined {\n  if (scope !== \"project\") return undefined;\n  if (!projectId) throw new Error(\"projectId is required for project scope\");\n  return projectId;\n}\n\nfunction normalizeTags(tags: unknown): string[] {\n  if (!Array.isArray(tags)) return [];\n  return tags\n    .filter((t) => typeof t === \"string\")\n    .map((t) => t.trim())\n    .filter(Boolean);\n}\n\n/**\n * Convert a Neo4j Record containing a Memory node to a MemoryNode object.\n */\nexport function toNode(record: Record<MemoryRecordShape>): MemoryNode {\n  const n = record.get(\"n\");\n  const p = n?.properties ?? {};\n  return {\n    scope: (p.scope as MemoryScope) ?? \"project\",\n    projectId: typeof p.projectId === \"string\" ? p.projectId : undefined,\n    key: String(p.key ?? \"\"),\n    value: String(p.value ?? \"\"),\n    tags: normalizeTags(p.tags),\n    createdAt: typeof p.createdAt === \"number\" ? p.createdAt : undefined,\n    updatedAt: typeof p.updatedAt === \"number\" ? p.updatedAt : undefined,\n  };\n}\n"
  },
  {
    "path": "memory/graph/trim.ts",
    "content": "import type { Record } from \"neo4j-driver\";\nimport type { Neo4jConfig } from \"../neo4j\";\nimport { withNeo4jSession } from \"../neo4j\";\nimport type { MemoryScope } from \"./shared\";\nimport { requireProjectId } from \"./shared\";\n\n/**\n * Record shape for queries returning a deleted count.\n */\ntype DeletedCountRecord = { deleted: number };\n\n/**\n * Record shape for queries returning project drop statistics.\n */\ntype TrimProjectsRecord = { projectsDropped: number; messagesDeleted: number };\n\nexport async function trimMemoryByKeyPrefix(input: {\n  cfg: Neo4jConfig;\n  scope: MemoryScope;\n  projectId?: string;\n  keyPrefix: string;\n  keepLatest: number;\n  deps?: { withSession?: typeof withNeo4jSession };\n}): Promise<{ deleted: number }> {\n  const scope = input.scope;\n  const projectId = requireProjectId(scope, input.projectId);\n  const keepLatest = Math.max(0, Math.floor(input.keepLatest));\n  const withSession = input.deps?.withSession ?? withNeo4jSession;\n\n  if (keepLatest === 0) {\n    const deleted = await withSession(input.cfg, async (session) => {\n      const matchPattern = scope === \"project\" ? `{ scope: $scope, projectId: $projectId }` : `{ scope: $scope }`;\n      const res = await session.run(\n        `\nMATCH (n:Memory ${matchPattern})\nWHERE n.key STARTS WITH $prefix\nWITH collect(n) AS nodes\nFOREACH (x IN nodes | DETACH DELETE x)\nRETURN size(nodes) AS deleted\n        `.trim(),\n        {\n          scope,\n          ...(scope === \"project\" ? { projectId } : {}),\n          prefix: input.keyPrefix,\n        },\n      );\n      const rec = res.records?.[0] as Record<DeletedCountRecord> | undefined;\n      return rec ? rec.get(\"deleted\") : 0;\n    });\n    return { deleted };\n  }\n\n  const deleted = await withSession(input.cfg, async (session) => {\n    const matchPattern = scope === \"project\" ? `{ scope: $scope, projectId: $projectId }` : `{ scope: $scope }`;\n    const res = await session.run(\n      `\nMATCH (n:Memory ${matchPattern})\nWHERE n.key STARTS WITH $prefix\nWITH n ORDER BY n.updatedAt DESC\nWITH collect(n) AS nodes\nWITH nodes[toInteger($keepLatest)..] AS toDelete\nFOREACH (x IN toDelete | DETACH DELETE x)\nRETURN size(toDelete) AS deleted\n      `.trim(),\n      {\n        scope,\n        ...(scope === \"project\" ? { projectId } : {}),\n        prefix: input.keyPrefix,\n        keepLatest,\n      },\n    );\n    const rec = res.records?.[0] as Record<DeletedCountRecord> | undefined;\n    return rec ? rec.get(\"deleted\") : 0;\n  });\n\n  return { deleted };\n}\n\nexport async function trimGlobalMessageProjects(input: {\n  cfg: Neo4jConfig;\n  keepProjects: number;\n  deps?: { withSession?: typeof withNeo4jSession };\n}): Promise<{ projectsDropped: number; messagesDeleted: number }> {\n  const keepProjects = Math.max(0, Math.floor(input.keepProjects));\n  if (keepProjects <= 0) {\n    const { deleted } = await trimMemoryByKeyPrefix({\n      cfg: input.cfg,\n      scope: \"global\",\n      keyPrefix: \"message:\",\n      keepLatest: 0,\n      deps: input.deps,\n    });\n    return { projectsDropped: 0, messagesDeleted: deleted };\n  }\n\n  const withSession = input.deps?.withSession ?? withNeo4jSession;\n\n  return await withSession(input.cfg, async (session) => {\n    const res = await session.run(\n      `\nMATCH (n:Memory { scope: $scope })\nWHERE n.key STARTS WITH $prefix\nWITH split(n.key, ':')[1] AS projectId, max(n.updatedAt) AS lastUpdated\nORDER BY lastUpdated DESC\nWITH collect(projectId) AS projects\nWITH projects[toInteger($keepProjects)..] AS toDrop\nMATCH (m:Memory { scope: $scope })\nWHERE m.key STARTS WITH $prefix AND split(m.key, ':')[1] IN toDrop\nWITH toDrop, collect(m) AS toDelete\nFOREACH (x IN toDelete | DETACH DELETE x)\nRETURN size(toDrop) AS projectsDropped, size(toDelete) AS messagesDeleted\n      `.trim(),\n      { keepProjects, scope: \"global\", prefix: \"message:\" },\n    );\n    const rec = res.records?.[0] as Record<TrimProjectsRecord> | undefined;\n    return {\n      projectsDropped: rec ? rec.get(\"projectsDropped\") : 0,\n      messagesDeleted: rec ? rec.get(\"messagesDeleted\") : 0,\n    };\n  });\n}\n"
  },
  {
    "path": "memory/index.ts",
    "content": "import type { TextPartInput } from \"@opencode-ai/sdk\";\nimport type { ApiService } from \"../api\";\nimport type { Factory, MemoryConfig, ServiceLifecycle } from \"../types\";\nimport { recordMessageMemory } from \"./auto\";\nimport { buildMemoryInjection } from \"./inject\";\nimport { loadNeo4jConfig, type Neo4jConfig } from \"./neo4j\";\nimport type { MemoryScope } from \"./store\";\n\ntype SessionPromptArgs = {\n  path: { id: string };\n  body: {\n    noReply?: boolean;\n    parts: TextPartInput[];\n  };\n  query?: { directory?: string };\n};\n\ntype SessionClient = {\n  session: {\n    prompt: (args: SessionPromptArgs) => Promise<unknown>;\n  };\n};\n\nexport type MemoryDeps = {\n  api?: ApiService;\n  memory?: {\n    recordMessageMemory?: typeof recordMessageMemory;\n    buildMemoryInjection?: typeof buildMemoryInjection;\n    loadNeo4jConfig?: typeof loadNeo4jConfig;\n  };\n};\n\nexport type MemoryService = ServiceLifecycle & {\n  enabled: boolean;\n  getScope: () => MemoryScope;\n  getProjectId: () => string | undefined;\n  inject: (input: { client: SessionClient; sessionId: string; directory?: string }) => Promise<boolean>;\n  record: (input: {\n    text: string;\n    sessionId?: string;\n    messageId?: string;\n    role?: string;\n    userId?: string;\n  }) => Promise<void>;\n};\n\nexport const createMemoryStore: Factory<MemoryConfig | undefined, MemoryDeps, MemoryService> = ({ config, deps }) => {\n  const cfg: MemoryConfig = config ?? {};\n  const enabled = cfg.enabled !== false;\n  const autoRecord = cfg.autoRecord !== false;\n  const autoInject = cfg.autoInject !== false;\n  const requestedScope: MemoryScope = cfg.scope ?? \"project\";\n  const memoryDeps = deps.memory ?? {};\n  const recordMessage = memoryDeps.recordMessageMemory ?? recordMessageMemory;\n  const buildInjection = memoryDeps.buildMemoryInjection ?? buildMemoryInjection;\n  const loadConfig = memoryDeps.loadNeo4jConfig ?? loadNeo4jConfig;\n  const neo4j: Neo4jConfig | undefined = loadConfig();\n\n  let projectId: string | undefined;\n  let projectResolved = false;\n\n  const resolveProjectId = async () => {\n    if (projectResolved) return projectId;\n    projectResolved = true;\n    if (!deps.api || requestedScope !== \"project\") return projectId;\n    try {\n      const res = await deps.api.project.current({});\n      // SDK response type has complex conditional generics - use type assertion for data extraction\n      const data = (res as { data?: { id?: string } })?.data ?? (res as { id?: string });\n      if (data?.id) projectId = data.id;\n    } catch {}\n    return projectId;\n  };\n\n  const resolveScope = async (): Promise<MemoryScope> => {\n    if (requestedScope !== \"project\") return requestedScope;\n    const pid = await resolveProjectId();\n    return pid ? \"project\" : \"global\";\n  };\n\n  const resolveProjectForScope = async (): Promise<{ scope: MemoryScope; projectId?: string }> => {\n    const scope = await resolveScope();\n    if (scope !== \"project\") return { scope };\n    return { scope, projectId: await resolveProjectId() };\n  };\n\n  return {\n    enabled,\n    getScope: () => requestedScope,\n    getProjectId: () => projectId,\n    inject: async ({ client, sessionId, directory }) => {\n      if (!enabled || !autoInject) return false;\n      const { scope, projectId: pid } = await resolveProjectForScope();\n      const injection = await buildInjection({\n        enabled: true,\n        cfg: neo4j,\n        scope,\n        projectId: pid,\n        sessionId,\n        inject: cfg.inject,\n      });\n      if (!injection) return false;\n      try {\n        await client.session.prompt({\n          path: { id: sessionId },\n          body: {\n            noReply: true,\n            parts: [{ type: \"text\", text: injection }],\n          },\n          ...(directory ? { query: { directory } } : {}),\n        });\n        return true;\n      } catch {\n        return false;\n      }\n    },\n    record: async (input) => {\n      if (!enabled || !autoRecord) return;\n      const { scope, projectId: pid } = await resolveProjectForScope();\n      try {\n        await recordMessage({\n          cfg: neo4j,\n          text: input.text,\n          sessionId: input.sessionId,\n          messageId: input.messageId,\n          role: input.role,\n          userId: input.userId,\n          scope,\n          projectId: pid,\n          maxChars: cfg.maxChars,\n          summaries: cfg.summaries,\n          trim: cfg.trim,\n        });\n      } catch {}\n    },\n    start: async () => {\n      if (!enabled) return;\n      // Don't block startup - resolve project ID in background\n      void resolveProjectId();\n    },\n    stop: async () => {},\n    health: async () => ({\n      ok: true,\n      info: {\n        enabled,\n        scope: requestedScope,\n        projectId,\n      },\n    }),\n  };\n};\n"
  },
  {
    "path": "memory/inject.ts",
    "content": "import { loadNeo4jConfig, type Neo4jConfig } from \"./neo4j\";\nimport { getMemoryByKey, type MemoryNode, type MemoryScope, recentMemory } from \"./store\";\nimport { shortenWithMarker } from \"./text\";\n\nfunction clamp(n: number, min: number, max: number): number {\n  return Math.max(min, Math.min(max, n));\n}\n\nfunction shorten(text: string, maxChars: number): string {\n  return shortenWithMarker(text, maxChars, { headRatio: 0.4 });\n}\n\nfunction isMessageLike(node: MemoryNode): boolean {\n  if (node.key.startsWith(\"message:\")) return true;\n  if (node.tags.includes(\"message\")) return true;\n  return false;\n}\n\nfunction isAutoScaffold(node: MemoryNode): boolean {\n  if (node.key.startsWith(\"summary:\")) return true;\n  if (node.key.startsWith(\"project:\")) return true;\n  if (node.key.startsWith(\"user:\")) return true;\n  return false;\n}\n\nfunction renderEntry(node: MemoryNode): string {\n  const value = node.value.replace(/\\s+/g, \" \").trim();\n  return `- \\`${node.key}\\` ${value}`;\n}\n\nexport async function buildMemoryInjection(input: {\n  enabled: boolean;\n  cfg?: Neo4jConfig;\n  scope: MemoryScope;\n  projectId?: string;\n  sessionId?: string;\n  inject?: {\n    maxChars?: number;\n    maxEntries?: number;\n    includeMessages?: boolean;\n    includeSessionSummary?: boolean;\n    includeProjectSummary?: boolean;\n    includeGlobal?: boolean;\n    maxGlobalEntries?: number;\n  };\n  deps?: {\n    loadNeo4jConfig?: typeof loadNeo4jConfig;\n    getMemoryByKey?: typeof getMemoryByKey;\n    recentMemory?: typeof recentMemory;\n  };\n}): Promise<string | undefined> {\n  if (!input.enabled) return undefined;\n  const loadConfig = input.deps?.loadNeo4jConfig ?? loadNeo4jConfig;\n  const getByKey = input.deps?.getMemoryByKey ?? getMemoryByKey;\n  const recent = input.deps?.recentMemory ?? recentMemory;\n  const cfg = input.cfg ?? loadConfig();\n\n  const maxChars = clamp(input.inject?.maxChars ?? 2000, 200, 20000);\n  const maxEntries = clamp(input.inject?.maxEntries ?? 8, 0, 50);\n  const includeMessages = input.inject?.includeMessages === true;\n  const includeSessionSummary = input.inject?.includeSessionSummary !== false;\n  const includeProjectSummary = input.inject?.includeProjectSummary !== false;\n  const includeGlobal = input.inject?.includeGlobal !== false;\n  const maxGlobalEntries = clamp(input.inject?.maxGlobalEntries ?? 3, 0, 20);\n\n  const scope = input.scope;\n  const projectId = input.projectId;\n  const sessionId = input.sessionId;\n\n  const lines: string[] = [\"## Memory (auto)\", \"\"];\n\n  const projectSummaryKey =\n    scope === \"project\" ? \"summary:project\" : projectId ? `summary:project:${projectId}` : undefined;\n  const sessionSummaryKey = sessionId ? `summary:session:${sessionId}` : undefined;\n\n  if (includeProjectSummary && projectSummaryKey) {\n    let node: MemoryNode | undefined;\n    try {\n      node = await getByKey({\n        cfg,\n        scope,\n        projectId: scope === \"project\" ? projectId : undefined,\n        key: projectSummaryKey,\n      });\n    } catch {\n      node = undefined;\n    }\n    if (node?.value?.trim()) {\n      lines.push(\"### Project\");\n      lines.push(shorten(node.value.trim(), clamp(Math.floor(maxChars * 0.5), 200, 6000)));\n      lines.push(\"\");\n    }\n  }\n\n  if (includeSessionSummary && scope === \"project\" && projectId && sessionSummaryKey) {\n    let node: MemoryNode | undefined;\n    try {\n      node = await getByKey({ cfg, scope: \"project\", projectId, key: sessionSummaryKey });\n    } catch {\n      node = undefined;\n    }\n    if (node?.value?.trim()) {\n      lines.push(\"### Session\");\n      lines.push(shorten(node.value.trim(), clamp(Math.floor(maxChars * 0.35), 200, 4000)));\n      lines.push(\"\");\n    }\n  }\n\n  const gather = async (\n    scopeToRead: MemoryScope,\n    projectIdToRead: string | undefined,\n    limit: number,\n  ): Promise<MemoryNode[]> => {\n    let nodes: MemoryNode[] = [];\n    try {\n      nodes = await recent({ cfg, scope: scopeToRead, projectId: projectIdToRead, limit });\n    } catch {\n      nodes = [];\n    }\n    const filtered = nodes.filter((n) => {\n      if (!includeMessages && isMessageLike(n)) return false;\n      if (isAutoScaffold(n)) return false;\n      return true;\n    });\n    return filtered;\n  };\n\n  const mainNodes = await gather(scope, scope === \"project\" ? projectId : undefined, 50);\n  const extras: string[] = [];\n  for (const node of mainNodes.slice(0, maxEntries)) {\n    extras.push(renderEntry(node));\n  }\n\n  if (includeGlobal && scope === \"project\" && maxGlobalEntries > 0) {\n    const globalNodes = await gather(\"global\", undefined, 50);\n    for (const node of globalNodes.slice(0, maxGlobalEntries)) {\n      extras.push(renderEntry(node));\n    }\n  }\n\n  if (extras.length > 0) {\n    lines.push(\"### Notes\");\n    lines.push(...extras);\n    lines.push(\"\");\n  }\n\n  if (lines.length <= 2) return undefined;\n  return shorten(lines.join(\"\\n\").trim(), maxChars);\n}\n"
  },
  {
    "path": "memory/neo4j-config.ts",
    "content": "import { existsSync, readFileSync } from \"node:fs\";\nimport { join } from \"node:path\";\nimport type { Neo4jIntegrationConfig } from \"../types\";\nimport type { OrchestratorConfigFile } from \"../types/config\";\n\nexport const NEO4J_CONTAINER_NAME = \"opencode-neo4j\";\nexport const NEO4J_DEFAULT_IMAGE = \"neo4j:community\";\nexport const NEO4J_STARTUP_TIMEOUT_MS = 30_000;\nexport const NEO4J_HEALTH_CHECK_INTERVAL_MS = 1_000;\n\nexport type Neo4jConfig = {\n  uri: string;\n  username: string;\n  password: string;\n  database?: string;\n};\n\nlet integrationsNeo4jConfig: Neo4jIntegrationConfig | undefined;\n\n/** Cache the orchestrator-provided Neo4j integration config. */\nexport function setNeo4jIntegrationsConfig(cfg: Neo4jIntegrationConfig | undefined): void {\n  integrationsNeo4jConfig = cfg;\n}\n\n/** Return the cached Neo4j integration config, if any. */\nexport function getNeo4jIntegrationsConfig(): Neo4jIntegrationConfig | undefined {\n  return integrationsNeo4jConfig;\n}\n\nconst loadNeo4jConfigFromFile = (): Neo4jConfig | undefined => {\n  const projectDir = process.env.OPENCODE_ORCH_PROJECT_DIR || process.cwd();\n\n  const pathsToTry: string[] = [];\n\n  const homeDir = process.env.HOME || process.env.USERPROFILE || \"\";\n  if (homeDir) {\n    pathsToTry.push(join(homeDir, \".opencode\", \"orchestrator.json\"));\n  }\n\n  pathsToTry.push(join(projectDir, \".opencode\", \"orchestrator.json\"));\n\n  for (const configPath of pathsToTry) {\n    try {\n      if (!existsSync(configPath)) continue;\n\n      const content = readFileSync(configPath, \"utf8\");\n      const config = JSON.parse(content) as OrchestratorConfigFile;\n      const neo4j = config?.integrations?.neo4j;\n\n      if (neo4j?.enabled !== false && neo4j?.uri && neo4j?.username && neo4j?.password) {\n        return {\n          uri: neo4j.uri,\n          username: neo4j.username,\n          password: neo4j.password,\n          database: neo4j.database,\n        };\n      }\n    } catch {\n      // Ignore errors, try next path\n    }\n  }\n\n  return undefined;\n};\n\n/** Load Neo4j config from environment variables. */\nexport const loadNeo4jConfigFromEnv = (): Neo4jConfig | undefined => {\n  const uri = process.env.OPENCODE_NEO4J_URI;\n  const username = process.env.OPENCODE_NEO4J_USERNAME;\n  const password = process.env.OPENCODE_NEO4J_PASSWORD;\n  const database = process.env.OPENCODE_NEO4J_DATABASE;\n\n  if (!uri || !username || !password) return undefined;\n  return { uri, username, password, database };\n};\n\n/** Load Neo4j config from orchestrator integration settings. */\nexport const loadNeo4jConfigFromIntegrations = (): Neo4jConfig | undefined => {\n  const cfg = integrationsNeo4jConfig;\n  if (cfg) {\n    if (cfg.enabled === false) return undefined;\n    const uri = cfg.uri;\n    const username = cfg.username;\n    const password = cfg.password;\n    const database = cfg.database;\n    if (!uri || !username || !password) return undefined;\n    return { uri, username, password, database };\n  }\n\n  return loadNeo4jConfigFromFile();\n};\n\n/** Load Neo4j config using env-first precedence. */\nexport const loadNeo4jConfig = (): Neo4jConfig | undefined => {\n  const fromEnv = loadNeo4jConfigFromEnv();\n  if (fromEnv) return fromEnv;\n\n  return loadNeo4jConfigFromIntegrations();\n};\n"
  },
  {
    "path": "memory/neo4j-docker.ts",
    "content": "/* c8 ignore file */\nimport { execSync, spawn, spawnSync } from \"node:child_process\";\nimport neo4j from \"neo4j-driver\";\nimport type { Neo4jIntegrationConfig } from \"../types\";\nimport {\n  getNeo4jIntegrationsConfig,\n  loadNeo4jConfig,\n  NEO4J_CONTAINER_NAME,\n  NEO4J_DEFAULT_IMAGE,\n  NEO4J_HEALTH_CHECK_INTERVAL_MS,\n  NEO4J_STARTUP_TIMEOUT_MS,\n  type Neo4jConfig,\n} from \"./neo4j-config\";\nimport { isNeo4jAccessible } from \"./neo4j-driver\";\n\nexport type Neo4jDockerDeps = {\n  execSync?: typeof execSync;\n  spawn?: typeof spawn;\n  spawnSync?: typeof spawnSync;\n  neo4j?: typeof neo4j;\n  isNeo4jAccessible?: typeof isNeo4jAccessible;\n};\n\n/**\n * Validate Docker image name to prevent command injection.\n * Allows: alphanumeric, slashes, colons, hyphens, underscores, periods, @\n * Examples: \"neo4j:5.15\", \"library/neo4j:latest\", \"ghcr.io/org/neo4j@sha256:abc123\"\n */\nfunction isValidDockerImage(image: string): boolean {\n  if (!image || typeof image !== \"string\") return false;\n  // Max 256 chars, must match Docker image naming convention\n  if (image.length > 256) return false;\n  // Allow: alphanumeric, /, :, -, _, ., @\n  // Must start with alphanumeric or allowed registry prefix\n  const validPattern = /^[a-zA-Z0-9][a-zA-Z0-9._\\-/:@]*$/;\n  return validPattern.test(image);\n}\n\n/**\n * Sanitize container name for shell commands.\n * Only allows alphanumeric, hyphens, and underscores.\n */\nfunction sanitizeContainerName(name: string): string {\n  return name.replace(/[^a-zA-Z0-9_-]/g, \"\");\n}\n\nconst isDockerAvailable = (deps?: Neo4jDockerDeps): boolean => {\n  try {\n    const exec = deps?.execSync ?? execSync;\n    exec(\"docker --version\", { stdio: \"ignore\" });\n    return true;\n  } catch {\n    return false;\n  }\n};\n\nconst containerExists = (deps?: Neo4jDockerDeps): boolean => {\n  try {\n    const safeName = sanitizeContainerName(NEO4J_CONTAINER_NAME);\n    // Use spawnSync with array args to avoid shell injection\n    const spawnSyncFn = deps?.spawnSync ?? spawnSync;\n    const result = spawnSyncFn(\"docker\", [\"ps\", \"-a\", \"--filter\", `name=^${safeName}$`, \"--format\", \"{{.Names}}\"], {\n      encoding: \"utf8\",\n    });\n    if (result.error) return false;\n    return result.stdout.trim() === safeName;\n  } catch {\n    return false;\n  }\n};\n\nconst isContainerRunning = (deps?: Neo4jDockerDeps): boolean => {\n  try {\n    const safeName = sanitizeContainerName(NEO4J_CONTAINER_NAME);\n    // Use spawnSync with array args to avoid shell injection\n    const spawnSyncFn = deps?.spawnSync ?? spawnSync;\n    const result = spawnSyncFn(\"docker\", [\"ps\", \"--filter\", `name=^${safeName}$`, \"--format\", \"{{.Names}}\"], {\n      encoding: \"utf8\",\n    });\n    if (result.error) return false;\n    return result.stdout.trim() === safeName;\n  } catch {\n    return false;\n  }\n};\n\nconst startContainer = (deps?: Neo4jDockerDeps): void => {\n  const safeName = sanitizeContainerName(NEO4J_CONTAINER_NAME);\n  // Use spawnSync with array args to avoid shell injection\n  const spawnSyncFn = deps?.spawnSync ?? spawnSync;\n  const result = spawnSyncFn(\"docker\", [\"start\", safeName], { stdio: \"ignore\" });\n  if (result.error) throw result.error;\n};\n\nconst createContainer = (cfg: Neo4jIntegrationConfig, deps?: Neo4jDockerDeps): void => {\n  const username = cfg.username ?? \"neo4j\";\n  const password = cfg.password ?? \"opencode123\";\n  const image = cfg.image ?? NEO4J_DEFAULT_IMAGE;\n\n  // Validate image name to prevent command injection\n  if (!isValidDockerImage(image)) {\n    throw new Error(`Invalid Docker image name: ${image}. Image must match Docker naming conventions.`);\n  }\n\n  const uri = cfg.uri ?? \"bolt://localhost:7687\";\n  const portMatch = uri.match(/:([^/]+)(?:\\/|$)/);\n  const boltPort = portMatch ? portMatch[1] : \"7687\";\n\n  // Validate port is numeric\n  if (!/^\\d+$/.test(boltPort)) {\n    throw new Error(`Invalid port in URI: ${uri}`);\n  }\n\n  const safeName = sanitizeContainerName(NEO4J_CONTAINER_NAME);\n\n  const args = [\n    \"run\",\n    \"-d\",\n    \"--name\",\n    safeName,\n    \"-p\",\n    `${boltPort}:7687`,\n    \"-p\",\n    \"7474:7474\",\n    \"-e\",\n    `NEO4J_AUTH=${username}/${password}`,\n    \"-e\",\n    \"NEO4J_PLUGINS=[]\",\n    \"--restart\",\n    \"unless-stopped\",\n    image,\n  ];\n\n  // spawn with array args is safe from shell injection\n  const spawnFn = deps?.spawn ?? spawn;\n  spawnFn(\"docker\", args, { stdio: \"ignore\", detached: true }).unref();\n};\n\nconst waitForNeo4j = async (\n  cfg: Neo4jConfig,\n  timeoutMs: number = NEO4J_STARTUP_TIMEOUT_MS,\n  deps?: Neo4jDockerDeps,\n): Promise<boolean> => {\n  const start = Date.now();\n  const neo4jDriver = deps?.neo4j ?? neo4j;\n\n  while (Date.now() - start < timeoutMs) {\n    try {\n      const testDriver = neo4jDriver.driver(cfg.uri, neo4jDriver.auth.basic(cfg.username, cfg.password));\n      const session = testDriver.session();\n      try {\n        await session.run(\"RETURN 1\");\n        await session.close();\n        await testDriver.close();\n        return true;\n      } catch {\n        await session.close();\n        await testDriver.close();\n      }\n    } catch {\n      // Connection failed, keep waiting\n    }\n\n    await new Promise((resolve) => setTimeout(resolve, NEO4J_HEALTH_CHECK_INTERVAL_MS));\n  }\n\n  return false;\n};\n\nexport type EnsureNeo4jResult = {\n  status: \"already_running\" | \"started\" | \"created\" | \"failed\" | \"disabled\" | \"no_docker\" | \"no_config\";\n  message: string;\n};\n\n/** Ensure Neo4j is running, optionally starting a Docker container. */\nexport const ensureNeo4jRunning = async (\n  integrationsCfg?: Neo4jIntegrationConfig,\n  deps?: Neo4jDockerDeps,\n): Promise<EnsureNeo4jResult> => {\n  const accessibleFn = deps?.isNeo4jAccessible ?? isNeo4jAccessible;\n  const cfg = integrationsCfg ?? getNeo4jIntegrationsConfig();\n\n  if (cfg?.enabled === false) {\n    return { status: \"disabled\", message: \"Neo4j integration is disabled\" };\n  }\n\n  if (cfg?.autoStart === false) {\n    return { status: \"disabled\", message: \"Neo4j autoStart is disabled\" };\n  }\n\n  const neo4jCfg = loadNeo4jConfig();\n  if (!neo4jCfg) {\n    return { status: \"no_config\", message: \"No Neo4j configuration found\" };\n  }\n\n  if (await accessibleFn(neo4jCfg)) {\n    return { status: \"already_running\", message: \"Neo4j is already running\" };\n  }\n\n  if (!isDockerAvailable(deps)) {\n    return { status: \"no_docker\", message: \"Docker is not available - cannot auto-start Neo4j\" };\n  }\n\n  try {\n    if (containerExists(deps)) {\n      if (!isContainerRunning(deps)) {\n        startContainer(deps);\n      }\n      const ready = await waitForNeo4j(neo4jCfg, NEO4J_STARTUP_TIMEOUT_MS, deps);\n      if (ready) {\n        return { status: \"started\", message: `Started existing Neo4j container '${NEO4J_CONTAINER_NAME}'` };\n      }\n      return { status: \"failed\", message: \"Neo4j container started but failed to become responsive\" };\n    }\n\n    createContainer(cfg ?? {}, deps);\n\n    const ready = await waitForNeo4j(neo4jCfg, NEO4J_STARTUP_TIMEOUT_MS, deps);\n    if (ready) {\n      return { status: \"created\", message: `Created and started Neo4j container '${NEO4J_CONTAINER_NAME}'` };\n    }\n\n    return { status: \"failed\", message: \"Neo4j container created but failed to become responsive\" };\n  } catch (err) {\n    const msg = err instanceof Error ? err.message : String(err);\n    return { status: \"failed\", message: `Failed to start Neo4j: ${msg}` };\n  }\n};\n"
  },
  {
    "path": "memory/neo4j-driver.ts",
    "content": "/* c8 ignore file */\nimport neo4j, { type Driver, type Session } from \"neo4j-driver\";\nimport { loadNeo4jConfig, type Neo4jConfig } from \"./neo4j-config\";\n\nlet driver: Driver | undefined;\nlet driverKey: string | undefined;\n\nconst keyOf = (cfg: Neo4jConfig): string => `${cfg.uri}|${cfg.username}|${cfg.database ?? \"\"}`;\n\n/** Return a cached Neo4j driver for the given config. */\nexport const getNeo4jDriver = (cfg: Neo4jConfig): Driver => {\n  const nextKey = keyOf(cfg);\n  if (driver && driverKey === nextKey) return driver;\n\n  if (driver) {\n    try {\n      void driver.close();\n    } catch {\n      // ignore\n    }\n  }\n\n  driver = neo4j.driver(cfg.uri, neo4j.auth.basic(cfg.username, cfg.password), {\n    disableLosslessIntegers: true,\n  });\n  driverKey = nextKey;\n  return driver;\n};\n\n/** Open a Neo4j session, run a callback, and close the session. */\nexport const withNeo4jSession = async <T>(cfg: Neo4jConfig, fn: (session: Session) => Promise<T>): Promise<T> => {\n  const d = getNeo4jDriver(cfg);\n  const session = d.session(cfg.database ? { database: cfg.database } : undefined);\n  try {\n    return await fn(session);\n  } finally {\n    await session.close();\n  }\n};\n\n/** Check whether Neo4j is reachable with the provided config. */\nexport const isNeo4jAccessible = async (cfg?: Neo4jConfig): Promise<boolean> => {\n  const config = cfg ?? loadNeo4jConfig();\n  if (!config) return false;\n\n  try {\n    const testDriver = neo4j.driver(config.uri, neo4j.auth.basic(config.username, config.password));\n    const session = testDriver.session();\n    try {\n      await session.run(\"RETURN 1\");\n      return true;\n    } finally {\n      await session.close();\n      await testDriver.close();\n    }\n  } catch {\n    return false;\n  }\n};\n"
  },
  {
    "path": "memory/neo4j.ts",
    "content": "export type { Neo4jConfig } from \"./neo4j-config\";\nexport {\n  getNeo4jIntegrationsConfig,\n  loadNeo4jConfig,\n  loadNeo4jConfigFromEnv,\n  loadNeo4jConfigFromIntegrations,\n  setNeo4jIntegrationsConfig,\n} from \"./neo4j-config\";\nexport type { EnsureNeo4jResult } from \"./neo4j-docker\";\nexport { ensureNeo4jRunning } from \"./neo4j-docker\";\nexport { getNeo4jDriver, isNeo4jAccessible, withNeo4jSession } from \"./neo4j-driver\";\n"
  },
  {
    "path": "memory/store-file.ts",
    "content": "import { existsSync } from \"node:fs\";\nimport { readFile } from \"node:fs/promises\";\nimport { join } from \"node:path\";\nimport { getUserConfigDir } from \"../helpers/format\";\nimport { writeJsonAtomic } from \"../helpers/fs\";\nimport type { MemoryNode, MemoryScope } from \"./graph\";\n\ntype MemoryLink = {\n  fromKey: string;\n  toKey: string;\n  type: string;\n  createdAt: number;\n  updatedAt: number;\n};\n\ntype MemoryFile = {\n  version: 1;\n  updatedAt: number;\n  nodes: MemoryNode[];\n  links: MemoryLink[];\n};\n\nfunction requireProjectId(scope: MemoryScope, projectId: string | undefined): string | undefined {\n  if (scope !== \"project\") return undefined;\n  if (!projectId) throw new Error(\"projectId is required for project scope\");\n  return projectId;\n}\n\nfunction normalizeTags(tags: unknown): string[] {\n  if (!Array.isArray(tags)) return [];\n  return tags\n    .filter((t) => typeof t === \"string\")\n    .map((t) => t.trim())\n    .filter(Boolean);\n}\n\nfunction safeProjectId(projectId: string): string {\n  return encodeURIComponent(projectId);\n}\n\nfunction getMemoryFilePath(scope: MemoryScope, projectId: string | undefined): string {\n  const base = join(getUserConfigDir(), \"opencode\", \"orchestrator-memory\");\n  if (scope === \"global\") {\n    return join(base, \"global.json\");\n  }\n  const safe = safeProjectId(requireProjectId(scope, projectId) ?? \"unknown\");\n  return join(base, \"projects\", `${safe}.json`);\n}\n\nasync function readMemoryFile(path: string): Promise<MemoryFile> {\n  if (!existsSync(path)) {\n    return { version: 1, updatedAt: Date.now(), nodes: [], links: [] };\n  }\n  try {\n    const raw = JSON.parse(await readFile(path, \"utf8\")) as Partial<MemoryFile>;\n    const nodes = Array.isArray(raw.nodes) ? (raw.nodes as MemoryNode[]) : [];\n    const links = Array.isArray(raw.links) ? (raw.links as MemoryLink[]) : [];\n    return {\n      version: 1,\n      updatedAt: typeof raw.updatedAt === \"number\" ? raw.updatedAt : Date.now(),\n      nodes,\n      links,\n    };\n  } catch {\n    return { version: 1, updatedAt: Date.now(), nodes: [], links: [] };\n  }\n}\n\nasync function writeMemoryFile(path: string, file: MemoryFile): Promise<void> {\n  await writeJsonAtomic(path, file, { tmpPrefix: \"opencode-orch-memory\" });\n}\n\nexport async function upsertMemory(input: {\n  scope: MemoryScope;\n  projectId?: string;\n  key: string;\n  value: string;\n  tags?: string[];\n}): Promise<MemoryNode> {\n  const scope = input.scope;\n  const projectId = requireProjectId(scope, input.projectId);\n  const path = getMemoryFilePath(scope, projectId);\n  const file = await readMemoryFile(path);\n  const now = Date.now();\n\n  const idx = file.nodes.findIndex((n) => n.key === input.key);\n  const next: MemoryNode = {\n    scope,\n    ...(scope === \"project\" ? { projectId } : {}),\n    key: input.key,\n    value: input.value,\n    tags: normalizeTags(input.tags),\n    createdAt: idx >= 0 ? file.nodes[idx].createdAt : now,\n    updatedAt: now,\n  };\n\n  if (idx >= 0) file.nodes[idx] = next;\n  else file.nodes.push(next);\n\n  file.updatedAt = now;\n  await writeMemoryFile(path, file);\n  return next;\n}\n\nexport async function linkMemory(input: {\n  scope: MemoryScope;\n  projectId?: string;\n  fromKey: string;\n  toKey: string;\n  type?: string;\n}): Promise<{ ok: true }> {\n  const scope = input.scope;\n  const projectId = requireProjectId(scope, input.projectId);\n  const path = getMemoryFilePath(scope, projectId);\n  const file = await readMemoryFile(path);\n  const now = Date.now();\n  const type = input.type ?? \"relates_to\";\n\n  const idx = file.links.findIndex((l) => l.fromKey === input.fromKey && l.toKey === input.toKey && l.type === type);\n  if (idx >= 0) {\n    file.links[idx].updatedAt = now;\n  } else {\n    file.links.push({\n      fromKey: input.fromKey,\n      toKey: input.toKey,\n      type,\n      createdAt: now,\n      updatedAt: now,\n    });\n  }\n\n  file.updatedAt = now;\n  await writeMemoryFile(path, file);\n  return { ok: true };\n}\n\nexport async function getMemoryByKey(input: {\n  scope: MemoryScope;\n  projectId?: string;\n  key: string;\n}): Promise<MemoryNode | undefined> {\n  const scope = input.scope;\n  const projectId = requireProjectId(scope, input.projectId);\n  const path = getMemoryFilePath(scope, projectId);\n  const file = await readMemoryFile(path);\n  return file.nodes.find((n) => n.key === input.key);\n}\n\nexport async function searchMemory(input: {\n  scope: MemoryScope;\n  projectId?: string;\n  query: string;\n  limit?: number;\n}): Promise<MemoryNode[]> {\n  const scope = input.scope;\n  const projectId = requireProjectId(scope, input.projectId);\n  const path = getMemoryFilePath(scope, projectId);\n  const file = await readMemoryFile(path);\n  const limit = Math.floor(Math.max(1, Math.min(50, input.limit ?? 10)));\n  const q = input.query.toLowerCase();\n\n  return file.nodes\n    .filter((n) => {\n      if (n.key.toLowerCase().includes(q)) return true;\n      if (n.value.toLowerCase().includes(q)) return true;\n      return n.tags.some((t) => t.toLowerCase().includes(q));\n    })\n    .sort((a, b) => (b.updatedAt ?? 0) - (a.updatedAt ?? 0))\n    .slice(0, limit);\n}\n\nexport async function recentMemory(input: {\n  scope: MemoryScope;\n  projectId?: string;\n  limit?: number;\n}): Promise<MemoryNode[]> {\n  const scope = input.scope;\n  const projectId = requireProjectId(scope, input.projectId);\n  const path = getMemoryFilePath(scope, projectId);\n  const file = await readMemoryFile(path);\n  const limit = Math.floor(Math.max(1, Math.min(50, input.limit ?? 10)));\n\n  return file.nodes\n    .slice()\n    .sort((a, b) => (b.updatedAt ?? 0) - (a.updatedAt ?? 0))\n    .slice(0, limit);\n}\n\nexport async function trimMemoryByKeyPrefix(input: {\n  scope: MemoryScope;\n  projectId?: string;\n  keyPrefix: string;\n  keepLatest: number;\n}): Promise<{ deleted: number }> {\n  const scope = input.scope;\n  const projectId = requireProjectId(scope, input.projectId);\n  const path = getMemoryFilePath(scope, projectId);\n  const file = await readMemoryFile(path);\n  const keepLatest = Math.max(0, Math.floor(input.keepLatest));\n\n  const matches = file.nodes.filter((n) => n.key.startsWith(input.keyPrefix));\n  if (matches.length === 0) return { deleted: 0 };\n\n  let keep = new Set<string>();\n  if (keepLatest > 0) {\n    const sorted = matches.slice().sort((a, b) => (b.updatedAt ?? 0) - (a.updatedAt ?? 0));\n    keep = new Set(sorted.slice(0, keepLatest).map((n) => n.key));\n  }\n\n  const before = file.nodes.length;\n  file.nodes = file.nodes.filter((n) => !n.key.startsWith(input.keyPrefix) || keep.has(n.key));\n  const deleted = before - file.nodes.length;\n  if (deleted > 0) {\n    file.updatedAt = Date.now();\n    await writeMemoryFile(path, file);\n  }\n  return { deleted };\n}\n\nexport async function trimGlobalMessageProjects(input: {\n  keepProjects: number;\n}): Promise<{ projectsDropped: number; messagesDeleted: number }> {\n  const keepProjects = Math.max(0, Math.floor(input.keepProjects));\n  const path = getMemoryFilePath(\"global\", undefined);\n  const file = await readMemoryFile(path);\n\n  const messageNodes = file.nodes.filter((n) => n.key.startsWith(\"message:\"));\n  if (messageNodes.length === 0) return { projectsDropped: 0, messagesDeleted: 0 };\n\n  if (keepProjects <= 0) {\n    const before = file.nodes.length;\n    file.nodes = file.nodes.filter((n) => !n.key.startsWith(\"message:\"));\n    const deleted = before - file.nodes.length;\n    if (deleted > 0) {\n      file.updatedAt = Date.now();\n      await writeMemoryFile(path, file);\n    }\n    return { projectsDropped: 0, messagesDeleted: deleted };\n  }\n\n  const projectLastUpdated = new Map<string, number>();\n  for (const node of messageNodes) {\n    const parts = node.key.split(\":\");\n    const projectId = parts.length > 1 ? parts[1] : \"unknown\";\n    const updated = node.updatedAt ?? 0;\n    const prev = projectLastUpdated.get(projectId) ?? 0;\n    if (updated > prev) projectLastUpdated.set(projectId, updated);\n  }\n\n  const ordered = [...projectLastUpdated.entries()].sort((a, b) => b[1] - a[1]);\n  const drop = new Set(ordered.slice(keepProjects).map(([id]) => id));\n\n  if (drop.size === 0) return { projectsDropped: 0, messagesDeleted: 0 };\n\n  const before = file.nodes.length;\n  file.nodes = file.nodes.filter((n) => {\n    if (!n.key.startsWith(\"message:\")) return true;\n    const parts = n.key.split(\":\");\n    const projectId = parts.length > 1 ? parts[1] : \"unknown\";\n    return !drop.has(projectId);\n  });\n  const deleted = before - file.nodes.length;\n  if (deleted > 0) {\n    file.updatedAt = Date.now();\n    await writeMemoryFile(path, file);\n  }\n  return { projectsDropped: drop.size, messagesDeleted: deleted };\n}\n"
  },
  {
    "path": "memory/store.ts",
    "content": "import type { MemoryNode, MemoryScope } from \"./graph\";\nimport * as graph from \"./graph\";\nimport type { Neo4jConfig } from \"./neo4j\";\nimport { loadNeo4jConfig } from \"./neo4j\";\nimport * as fileStore from \"./store-file\";\n\nexport type MemoryBackend = \"neo4j\" | \"file\";\nexport type { MemoryNode, MemoryScope };\n\ntype MemoryStoreDeps = {\n  loadNeo4jConfig?: typeof loadNeo4jConfig;\n  graph?: typeof graph;\n  fileStore?: typeof fileStore;\n};\n\nfunction resolveBackend(cfg?: Neo4jConfig, deps?: MemoryStoreDeps): { backend: MemoryBackend; cfg?: Neo4jConfig } {\n  const resolved = cfg ?? (deps?.loadNeo4jConfig ?? loadNeo4jConfig)();\n  if (resolved) return { backend: \"neo4j\", cfg: resolved };\n  return { backend: \"file\" };\n}\n\nexport function getMemoryBackend(cfg?: Neo4jConfig, deps?: MemoryStoreDeps): MemoryBackend {\n  return resolveBackend(cfg, deps).backend;\n}\n\nexport async function upsertMemory(input: {\n  cfg?: Neo4jConfig;\n  scope: MemoryScope;\n  projectId?: string;\n  key: string;\n  value: string;\n  tags?: string[];\n  deps?: MemoryStoreDeps;\n}): Promise<MemoryNode> {\n  const { backend, cfg } = resolveBackend(input.cfg, input.deps);\n  const graphApi = input.deps?.graph ?? graph;\n  const fileApi = input.deps?.fileStore ?? fileStore;\n  if (backend === \"neo4j\") {\n    return await graphApi.upsertMemory({\n      cfg: cfg!,\n      scope: input.scope,\n      projectId: input.projectId,\n      key: input.key,\n      value: input.value,\n      tags: input.tags ?? [],\n    });\n  }\n  return await fileApi.upsertMemory({\n    scope: input.scope,\n    projectId: input.projectId,\n    key: input.key,\n    value: input.value,\n    tags: input.tags ?? [],\n  });\n}\n\nexport async function linkMemory(input: {\n  cfg?: Neo4jConfig;\n  scope: MemoryScope;\n  projectId?: string;\n  fromKey: string;\n  toKey: string;\n  type?: string;\n  deps?: MemoryStoreDeps;\n}): Promise<{ ok: true }> {\n  const { backend, cfg } = resolveBackend(input.cfg, input.deps);\n  const graphApi = input.deps?.graph ?? graph;\n  const fileApi = input.deps?.fileStore ?? fileStore;\n  if (backend === \"neo4j\") {\n    return await graphApi.linkMemory({\n      cfg: cfg!,\n      scope: input.scope,\n      projectId: input.projectId,\n      fromKey: input.fromKey,\n      toKey: input.toKey,\n      type: input.type,\n    });\n  }\n  return await fileApi.linkMemory({\n    scope: input.scope,\n    projectId: input.projectId,\n    fromKey: input.fromKey,\n    toKey: input.toKey,\n    type: input.type,\n  });\n}\n\nexport async function getMemoryByKey(input: {\n  cfg?: Neo4jConfig;\n  scope: MemoryScope;\n  projectId?: string;\n  key: string;\n  deps?: MemoryStoreDeps;\n}): Promise<MemoryNode | undefined> {\n  const { backend, cfg } = resolveBackend(input.cfg, input.deps);\n  const graphApi = input.deps?.graph ?? graph;\n  const fileApi = input.deps?.fileStore ?? fileStore;\n  if (backend === \"neo4j\") {\n    return await graphApi.getMemoryByKey({\n      cfg: cfg!,\n      scope: input.scope,\n      projectId: input.projectId,\n      key: input.key,\n    });\n  }\n  return await fileApi.getMemoryByKey({\n    scope: input.scope,\n    projectId: input.projectId,\n    key: input.key,\n  });\n}\n\nexport async function searchMemory(input: {\n  cfg?: Neo4jConfig;\n  scope: MemoryScope;\n  projectId?: string;\n  query: string;\n  limit?: number;\n  deps?: MemoryStoreDeps;\n}): Promise<MemoryNode[]> {\n  const { backend, cfg } = resolveBackend(input.cfg, input.deps);\n  const graphApi = input.deps?.graph ?? graph;\n  const fileApi = input.deps?.fileStore ?? fileStore;\n  if (backend === \"neo4j\") {\n    return await graphApi.searchMemory({\n      cfg: cfg!,\n      scope: input.scope,\n      projectId: input.projectId,\n      query: input.query,\n      limit: input.limit,\n    });\n  }\n  return await fileApi.searchMemory({\n    scope: input.scope,\n    projectId: input.projectId,\n    query: input.query,\n    limit: input.limit,\n  });\n}\n\nexport async function recentMemory(input: {\n  cfg?: Neo4jConfig;\n  scope: MemoryScope;\n  projectId?: string;\n  limit?: number;\n  deps?: MemoryStoreDeps;\n}): Promise<MemoryNode[]> {\n  const { backend, cfg } = resolveBackend(input.cfg, input.deps);\n  const graphApi = input.deps?.graph ?? graph;\n  const fileApi = input.deps?.fileStore ?? fileStore;\n  if (backend === \"neo4j\") {\n    return await graphApi.recentMemory({\n      cfg: cfg!,\n      scope: input.scope,\n      projectId: input.projectId,\n      limit: input.limit,\n    });\n  }\n  return await fileApi.recentMemory({\n    scope: input.scope,\n    projectId: input.projectId,\n    limit: input.limit,\n  });\n}\n\nexport async function trimMemoryByKeyPrefix(input: {\n  cfg?: Neo4jConfig;\n  scope: MemoryScope;\n  projectId?: string;\n  keyPrefix: string;\n  keepLatest: number;\n  deps?: MemoryStoreDeps;\n}): Promise<{ deleted: number }> {\n  const { backend, cfg } = resolveBackend(input.cfg, input.deps);\n  const graphApi = input.deps?.graph ?? graph;\n  const fileApi = input.deps?.fileStore ?? fileStore;\n  if (backend === \"neo4j\") {\n    return await graphApi.trimMemoryByKeyPrefix({\n      cfg: cfg!,\n      scope: input.scope,\n      projectId: input.projectId,\n      keyPrefix: input.keyPrefix,\n      keepLatest: input.keepLatest,\n    });\n  }\n  return await fileApi.trimMemoryByKeyPrefix({\n    scope: input.scope,\n    projectId: input.projectId,\n    keyPrefix: input.keyPrefix,\n    keepLatest: input.keepLatest,\n  });\n}\n\nexport async function trimGlobalMessageProjects(input: {\n  cfg?: Neo4jConfig;\n  keepProjects: number;\n  deps?: MemoryStoreDeps;\n}): Promise<{ projectsDropped: number; messagesDeleted: number }> {\n  const { backend, cfg } = resolveBackend(input.cfg, input.deps);\n  const graphApi = input.deps?.graph ?? graph;\n  const fileApi = input.deps?.fileStore ?? fileStore;\n  if (backend === \"neo4j\") {\n    return await graphApi.trimGlobalMessageProjects({\n      cfg: cfg!,\n      keepProjects: input.keepProjects,\n    });\n  }\n  return await fileApi.trimGlobalMessageProjects({\n    keepProjects: input.keepProjects,\n  });\n}\n"
  },
  {
    "path": "memory/text.ts",
    "content": "export function truncate(text: string, maxChars: number): string {\n  if (text.length <= maxChars) return text;\n  return text.slice(0, maxChars);\n}\n\nexport function stripCodeBlocks(input: string): string {\n  return input.replace(/```[\\s\\S]*?```/g, \"[code omitted]\");\n}\n\nexport function redactSecrets(input: string): string {\n  const patterns: RegExp[] = [\n    /\\bsk-[a-zA-Z0-9]{16,}\\b/g, // common API key prefix\n    /\\bAKIA[0-9A-Z]{16}\\b/g, // AWS access key\n    /\\bAIza[0-9A-Za-z\\-_]{20,}\\b/g, // Google API key\n    /\\bghp_[A-Za-z0-9]{20,}\\b/g, // GitHub token\n    /\\b(xox[baprs]-[0-9A-Za-z-]{10,})\\b/g, // Slack token\n    /\\b-----BEGIN [A-Z ]+PRIVATE KEY-----[\\s\\S]*?-----END [A-Z ]+PRIVATE KEY-----\\b/g,\n  ];\n  let out = input;\n  for (const re of patterns) out = out.replace(re, \"[REDACTED]\");\n  return out;\n}\n\nexport function normalizeForMemory(input: string, maxChars: number): string {\n  const cleaned = redactSecrets(stripCodeBlocks(input)).replace(/\\s+/g, \" \").trim();\n  return truncate(cleaned, maxChars);\n}\n\nexport function shortenWithMarker(text: string, maxChars: number, options?: { headRatio?: number }): string {\n  if (text.length <= maxChars) return text;\n  const headRatio = typeof options?.headRatio === \"number\" ? options.headRatio : 0.4;\n  const marker = `\\n\\n[... trimmed ${text.length - maxChars} chars ...]\\n\\n`;\n  const budget = Math.max(0, maxChars - marker.length);\n  const keepHead = Math.floor(budget * headRatio);\n  const keepTail = budget - keepHead;\n  return `${text.slice(0, keepHead)}${marker}${text.slice(text.length - keepTail)}`;\n}\n\nexport function appendRollingSummary(prev: string | undefined, entry: string, maxChars: number): string {\n  const next = prev && prev.trim().length > 0 ? `${prev.trim()}\\n${entry}` : entry;\n  return shortenWithMarker(next, maxChars, { headRatio: 0.35 });\n}\n"
  },
  {
    "path": "models/aliases.ts",
    "content": "export type ModelAliasMap = Record<string, string>;\n\nexport function normalizeAliases(input?: ModelAliasMap): ModelAliasMap {\n  const out: ModelAliasMap = {};\n  if (!input) return out;\n  for (const [key, value] of Object.entries(input)) {\n    if (typeof value !== \"string\") continue;\n    out[key.toLowerCase()] = value;\n  }\n  return out;\n}\n\nexport function resolveAlias(input: string, aliases?: ModelAliasMap): string | undefined {\n  if (!aliases) return undefined;\n  const normalized = input.trim().toLowerCase();\n  return aliases[normalized];\n}\n"
  },
  {
    "path": "models/capabilities.ts",
    "content": "import type { Model } from \"@opencode-ai/sdk\";\n\nexport interface ModelCapabilities {\n  supportsVision: boolean;\n  supportsTools: boolean;\n  supportsStreaming: boolean;\n  contextWindow: number;\n  maxOutputTokens: number;\n  supportsReasoning: boolean;\n  supportsWebSearch: boolean;\n  supportsPDFAnalysis: boolean;\n  supportsCodeExecution: boolean;\n  inputCostPer1kTokens?: number;\n  outputCostPer1kTokens?: number;\n  averageLatencyMs?: number;\n  throughputTokensPerSecond?: number;\n}\n\n/**\n * Minimal model shape needed for capability derivation.\n * This allows the function to handle both SDK Model type and raw objects.\n */\ntype ModelLike = {\n  capabilities?: {\n    attachment?: boolean;\n    toolcall?: boolean;\n    tools?: boolean;\n    function_calling?: boolean;\n    streaming?: boolean;\n    stream?: boolean;\n    reasoning?: boolean;\n    web?: boolean;\n    input?: { image?: boolean; pdf?: boolean };\n    output?: { pdf?: boolean };\n  };\n  limit?: { context?: number; output?: number };\n  cost?: { input?: number; output?: number };\n  latency?: number;\n  throughput?: number;\n};\n\nfunction inferFromName(name: string): Partial<ModelCapabilities> {\n  const lower = name.toLowerCase();\n  return {\n    supportsReasoning: /reasoning|thinking|r1|deepthink/.test(lower),\n    supportsVision: /vision|multimodal|image/.test(lower),\n    supportsWebSearch: /search|browse|web/.test(lower),\n    supportsPDFAnalysis: /pdf/.test(lower),\n  };\n}\n\nexport function deriveModelCapabilities(input: {\n  model: Model | Record<string, unknown> | undefined;\n  modelId: string;\n  modelName?: string;\n  overrides?: Partial<ModelCapabilities>;\n}): ModelCapabilities {\n  // Use ModelLike for safe property access - the function handles any shape of model object\n  const model = input.model as ModelLike | undefined;\n  const capabilities = model?.capabilities ?? {};\n  const inputCaps = capabilities?.input ?? {};\n  const outputCaps = capabilities?.output ?? {};\n\n  const inferred = inferFromName(`${input.modelName ?? \"\"} ${input.modelId}`.trim());\n\n  const base: ModelCapabilities = {\n    supportsVision: Boolean(capabilities?.attachment || inputCaps?.image) || Boolean(inferred.supportsVision),\n    supportsTools: Boolean(capabilities?.toolcall || capabilities?.tools || capabilities?.function_calling),\n    supportsStreaming: capabilities?.streaming ?? capabilities?.stream ?? true,\n    contextWindow: Number(model?.limit?.context ?? 0),\n    maxOutputTokens: Number(model?.limit?.output ?? 0),\n    supportsReasoning: Boolean(capabilities?.reasoning) || Boolean(inferred.supportsReasoning),\n    supportsWebSearch: Boolean(capabilities?.web) || Boolean(inferred.supportsWebSearch),\n    supportsPDFAnalysis: Boolean(inputCaps?.pdf || outputCaps?.pdf) || Boolean(inferred.supportsPDFAnalysis),\n    supportsCodeExecution: Boolean(capabilities?.toolcall || capabilities?.function_calling),\n    inputCostPer1kTokens: typeof model?.cost?.input === \"number\" ? model.cost.input : undefined,\n    outputCostPer1kTokens: typeof model?.cost?.output === \"number\" ? model.cost.output : undefined,\n    averageLatencyMs: typeof model?.latency === \"number\" ? model.latency : undefined,\n    throughputTokensPerSecond: typeof model?.throughput === \"number\" ? model.throughput : undefined,\n  };\n\n  return {\n    ...base,\n    ...(input.overrides ?? {}),\n  };\n}\n"
  },
  {
    "path": "models/capability-overrides.ts",
    "content": "import type { ModelCapabilities } from \"./capabilities\";\n\nexport type CapabilityOverrideMap = Record<string, Partial<ModelCapabilities>>;\n\nexport function resolveCapabilityOverride(\n  modelFullId: string,\n  overrides?: CapabilityOverrideMap,\n): Partial<ModelCapabilities> | undefined {\n  if (!overrides) return undefined;\n  if (overrides[modelFullId]) return overrides[modelFullId];\n  const lowered = modelFullId.toLowerCase();\n  const match = Object.entries(overrides).find(([key]) => key.toLowerCase() === lowered);\n  return match ? match[1] : undefined;\n}\n"
  },
  {
    "path": "models/catalog.ts",
    "content": "import type { Config, Model, Provider } from \"@opencode-ai/sdk\";\nimport { resolveModel } from \"./resolver\";\n\nexport type ModelCatalogEntry = {\n  /** Full ID in provider/model format */\n  full: string;\n  providerID: string;\n  modelID: string;\n  name: string;\n  status: Model[\"status\"];\n  capabilities: Model[\"capabilities\"];\n  limit: Model[\"limit\"];\n  cost: Model[\"cost\"];\n  providerSource: Provider[\"source\"];\n};\n\n/**\n * Type guard to treat a provider model entry as a full Model type.\n * The SDK's Provider.models type is Record<string, Model>, but Object.entries\n * loses the Model typing. This helper restores it.\n */\nfunction asModel(model: unknown): Model {\n  return model as Model;\n}\n\nexport function isFullModelID(value: string): boolean {\n  return value.includes(\"/\");\n}\n\nexport function parseFullModelID(value: string): { providerID: string; modelID: string } {\n  const [providerID, ...rest] = value.split(\"/\");\n  return { providerID, modelID: rest.join(\"/\") };\n}\n\nexport function fullModelID(providerID: string, modelID: string): string {\n  return `${providerID}/${modelID}`;\n}\n\nexport function flattenProviders(providers: Provider[]): ModelCatalogEntry[] {\n  const out: ModelCatalogEntry[] = [];\n  for (const provider of providers) {\n    const models = provider.models ?? {};\n    for (const [modelID, modelEntry] of Object.entries(models)) {\n      const model = asModel(modelEntry);\n      out.push({\n        full: fullModelID(provider.id, modelID),\n        providerID: provider.id,\n        modelID,\n        name: model.name ?? modelID,\n        status: model.status ?? \"active\",\n        capabilities: model.capabilities ?? {\n          temperature: true,\n          reasoning: false,\n          attachment: false,\n          toolcall: false,\n          input: { text: true, audio: false, image: false, video: false, pdf: false },\n          output: { text: true, audio: false, image: false, video: false, pdf: false },\n        },\n        limit: model.limit ?? { context: 0, output: 0 },\n        cost: model.cost ?? { input: 0, output: 0, cache: { read: 0, write: 0 } },\n        providerSource: provider.source,\n      });\n    }\n  }\n  return out;\n}\n\nexport function filterProviders(providers: Provider[], scope: \"configured\" | \"all\"): Provider[] {\n  if (scope === \"all\") return providers;\n\n  // Filter to only providers that are usable (have credentials or are explicitly configured).\n  //\n  // The SDK's Provider.source field tells us how the provider was registered:\n  //   - \"config\": Explicitly configured in opencode.json\n  //   - \"custom\": Custom provider (npm package, explicitly configured)\n  //   - \"env\": Auto-detected from environment variables (e.g., ANTHROPIC_API_KEY)\n  //   - \"api\": From SDK's built-in API catalog (may or may not have credentials)\n  //\n  // For \"configured\" scope, we include:\n  //   - \"config\" and \"custom\" sources (explicitly configured)\n  //   - \"env\" sources (have environment-based credentials)\n  //   - \"api\" sources that have a `key` set (connected via /connect)\n  // The \"opencode\" provider is special and always available.\n  return providers.filter((p) => {\n    if (p.id === \"opencode\") return true;\n\n    // Include explicitly configured providers\n    if (p.source === \"config\" || p.source === \"custom\") return true;\n\n    // Include environment-detected providers (they have API keys set)\n    if (p.source === \"env\") return true;\n\n    // For API catalog providers, check if they have credentials set.\n    // The SDK's Provider type has an optional `key` field that's populated when\n    // credentials are available (set via /connect command which stores in auth.json).\n    if (p.source === \"api\" && p.key) return true;\n\n    return false;\n  });\n}\n\nexport function resolveModelRef(\n  input: string,\n  providers: Provider[],\n): { full: string; providerID: string; modelID: string } | { error: string; suggestions?: string[] } {\n  const resolved = resolveModel(input, { providers });\n  if (\"error\" in resolved) return resolved;\n  return { full: resolved.full, providerID: resolved.providerID, modelID: resolved.modelID };\n}\n\nexport function pickVisionModel(models: ModelCatalogEntry[]): ModelCatalogEntry | undefined {\n  const score = (m: ModelCatalogEntry): number => {\n    let s = 0;\n    if (m.status === \"deprecated\") s -= 50;\n    if (m.capabilities.toolcall) s += 10;\n    if (m.capabilities.attachment) s += 10;\n    if (m.capabilities.input?.image) s += 100;\n    if (/\\bvision\\b/i.test(m.name) || /\\bvision\\b/i.test(m.modelID)) s += 20;\n    if (/\\bglm\\b/i.test(m.modelID) && /4\\\\.6v/i.test(m.modelID)) s += 15;\n    s += Math.min(Math.floor((m.limit?.context ?? 0) / 32000), 10);\n    return s;\n  };\n\n  const candidates = models\n    .filter((m) => m.capabilities?.attachment || m.capabilities?.input?.image)\n    .sort((a, b) => score(b) - score(a));\n  return candidates[0];\n}\n\nexport function pickFastModel(models: ModelCatalogEntry[]): ModelCatalogEntry | undefined {\n  const score = (m: ModelCatalogEntry): number => {\n    let s = 0;\n    if (m.status === \"deprecated\") s -= 50;\n    if (m.capabilities.toolcall) s += 5;\n    if (/(mini|small|flash|fast|haiku)/i.test(m.modelID) || /(mini|small|flash|fast|haiku)/i.test(m.name)) s += 10;\n    if ((m.cost?.input ?? 0) > 0) s -= Math.min(m.cost.input, 5);\n    if ((m.limit?.context ?? 0) > 0) s += Math.min(Math.floor(m.limit.context / 64000), 3);\n    return s;\n  };\n  return [...models].sort((a, b) => score(b) - score(a))[0];\n}\n\nexport function pickDocsModel(models: ModelCatalogEntry[]): ModelCatalogEntry | undefined {\n  const score = (m: ModelCatalogEntry): number => {\n    let s = 0;\n    if (m.status === \"deprecated\") s -= 50;\n    if (m.capabilities.toolcall) s += 10;\n    if (m.capabilities.reasoning) s += 3;\n    if (/minimax/i.test(m.modelID) || /minimax/i.test(m.name)) s += 8;\n    if (/m2/i.test(m.modelID) || /m2/i.test(m.name)) s += 3;\n    s += Math.min(Math.floor((m.limit?.context ?? 0) / 64000), 10);\n    return s;\n  };\n  return [...models].sort((a, b) => score(b) - score(a))[0];\n}\n\n/**\n * Expected shape of the config.providers response.\n * The SDK response type is complex, so we define the expected data shape here.\n */\ntype ProvidersResponseData = {\n  providers?: Provider[];\n  default?: Record<string, string>;\n};\n\nexport type CatalogClient = {\n  config: {\n    get: (args: { query: { directory: string } }) => Promise<{ data?: Config }>;\n    providers: (args: { query: { directory: string } }) => Promise<{ data?: ProvidersResponseData }>;\n  };\n};\n\nexport async function fetchOpencodeConfig(client: CatalogClient, directory: string): Promise<Config | undefined> {\n  const res = await client.config.get({ query: { directory } }).catch(() => undefined);\n  return res?.data;\n}\n\nexport async function fetchProviders(\n  client: CatalogClient,\n  directory: string,\n): Promise<{ providers: Provider[]; defaults: Record<string, string> }> {\n  const res = await client.config.providers({ query: { directory } });\n  return { providers: res.data?.providers ?? [], defaults: res.data?.default ?? {} };\n}\n"
  },
  {
    "path": "models/cost.ts",
    "content": "import type { OrchestratorConfig } from \"../types\";\nimport type { ModelCapabilities } from \"./capabilities\";\n\nexport function averageCostPer1kTokens(cap: ModelCapabilities): number | undefined {\n  const input = cap.inputCostPer1kTokens;\n  const output = cap.outputCostPer1kTokens;\n  if (typeof input !== \"number\" && typeof output !== \"number\") return undefined;\n  if (typeof input === \"number\" && typeof output === \"number\") return (input + output) / 2;\n  return typeof input === \"number\" ? input : output;\n}\n\nexport function scoreCost(\n  cap: ModelCapabilities,\n  selection?: OrchestratorConfig[\"modelSelection\"],\n): {\n  score: number;\n  tooExpensive: boolean;\n} {\n  const mode = selection?.mode ?? \"performance\";\n  const avg = averageCostPer1kTokens(cap);\n  const max = selection?.maxCostPer1kTokens;\n\n  if (typeof max === \"number\" && typeof avg === \"number\" && avg > max) {\n    return { score: -100, tooExpensive: true };\n  }\n\n  if (mode === \"performance\") {\n    return { score: 0, tooExpensive: false };\n  }\n\n  if (typeof avg !== \"number\") {\n    return { score: mode === \"economical\" ? -20 : -5, tooExpensive: false };\n  }\n\n  const penalty = mode === \"economical\" ? avg * 100 : avg * 40;\n  return { score: -penalty, tooExpensive: false };\n}\n"
  },
  {
    "path": "models/hydrate.ts",
    "content": "import type { OrchestratorConfig, WorkerProfile } from \"../types\";\nimport { normalizeAliases } from \"./aliases\";\nimport type { CatalogClient } from \"./catalog\";\nimport { fetchOpencodeConfig, fetchProviders } from \"./catalog\";\nimport { resolveModel } from \"./resolver\";\n\nexport type ProfileModelHydrationChange = {\n  profileId: string;\n  from: string;\n  to: string;\n  reason: string;\n};\n\nexport async function hydrateProfileModelsFromOpencode(input: {\n  client: CatalogClient;\n  directory: string;\n  profiles: Record<string, WorkerProfile>;\n  modelAliases?: OrchestratorConfig[\"modelAliases\"];\n  modelSelection?: OrchestratorConfig[\"modelSelection\"];\n}): Promise<{\n  profiles: Record<string, WorkerProfile>;\n  changes: ProfileModelHydrationChange[];\n  fallbackModel?: string;\n}> {\n  const [cfg, providersRes] = await Promise.all([\n    fetchOpencodeConfig(input.client, input.directory),\n    fetchProviders(input.client, input.directory),\n  ]);\n\n  const providersAll = providersRes.providers;\n  const aliases = normalizeAliases(input.modelAliases);\n\n  const fallbackCandidate =\n    cfg?.model ||\n    (providersRes.defaults?.opencode ? `opencode/${providersRes.defaults.opencode}` : undefined) ||\n    \"opencode/gpt-5-nano\";\n\n  const resolvedFallback = resolveModel(fallbackCandidate, {\n    providers: providersAll,\n    aliases,\n    selection: input.modelSelection,\n    defaults: providersRes.defaults,\n  });\n  const fallbackModel = \"error\" in resolvedFallback ? fallbackCandidate : resolvedFallback.full;\n\n  const changes: ProfileModelHydrationChange[] = [];\n\n  const next: Record<string, WorkerProfile> = {};\n  for (const [id, profile] of Object.entries(input.profiles)) {\n    let desired = profile.model;\n    let reason = \"\";\n\n    const modelSpec = profile.model.trim();\n    const isAutoTag = modelSpec.startsWith(\"auto\") || modelSpec.startsWith(\"node\");\n\n    const resolved = resolveModel(modelSpec, {\n      providers: providersAll,\n      defaults: providersRes.defaults,\n      aliases,\n      selection: input.modelSelection,\n    });\n\n    if (\"error\" in resolved) {\n      if (isAutoTag && !/vision/i.test(modelSpec)) {\n        desired = fallbackModel;\n        reason = `fallback to default model (${modelSpec})`;\n      } else {\n        const suffix = resolved.suggestions?.length ? `\\nSuggestions:\\n- ${resolved.suggestions.join(\"\\n- \")}` : \"\";\n        throw new Error(`Invalid model for profile \"${profile.id}\": ${resolved.error}${suffix}`);\n      }\n    } else {\n      desired = resolved.full;\n      reason = resolved.reason;\n      if (profile.supportsVision && !resolved.capabilities.supportsVision) {\n        throw new Error(\n          `Profile \"${profile.id}\" requires vision, but selected model \"${desired}\" does not appear vision-capable. ` +\n            `Choose a model with image input support.`,\n        );\n      }\n    }\n\n    next[id] = { ...profile, model: desired };\n\n    if (desired !== profile.model) {\n      changes.push({\n        profileId: id,\n        from: profile.model,\n        to: desired,\n        reason: reason || \"resolved\",\n      });\n    }\n  }\n\n  return { profiles: next, changes, fallbackModel };\n}\n"
  },
  {
    "path": "models/resolver.ts",
    "content": "import type { Model, Provider } from \"@opencode-ai/sdk\";\nimport type { OrchestratorConfig } from \"../types\";\nimport { type ModelAliasMap, resolveAlias } from \"./aliases\";\nimport { deriveModelCapabilities, type ModelCapabilities } from \"./capabilities\";\nimport { type CapabilityOverrideMap, resolveCapabilityOverride } from \"./capability-overrides\";\nimport { filterProviders, fullModelID, isFullModelID, parseFullModelID } from \"./catalog\";\nimport { scoreCost } from \"./cost\";\n\n/**\n * Type helper to treat a provider model entry as a full Model type.\n * The SDK's Provider.models type is Record<string, Model>, but Object.entries\n * loses the Model typing. This helper restores it.\n */\nfunction asModel(model: unknown): Model {\n  return model as Model;\n}\n\nexport type ModelResolutionContext = {\n  providers: Provider[];\n  defaults?: Record<string, string>;\n  aliases?: ModelAliasMap;\n  selection?: OrchestratorConfig[\"modelSelection\"];\n  capabilityOverrides?: CapabilityOverrideMap;\n};\n\nexport type ModelResolutionResult = {\n  full: string;\n  providerID: string;\n  modelID: string;\n  capabilities: ModelCapabilities;\n  reason: string;\n  score: number;\n};\n\nexport type ModelResolutionError = {\n  error: string;\n  suggestions?: string[];\n};\n\nfunction normalizeAutoTag(raw: string): string | undefined {\n  const value = raw.trim().toLowerCase();\n  if (!value) return undefined;\n  if (value === \"auto\" || value === \"node\") return \"auto\";\n  if (value.startsWith(\"auto:\")) return value;\n  if (value.startsWith(\"node:\")) return `auto:${value.slice(5)}`;\n  return undefined;\n}\n\nfunction providerPreferenceScore(providerId: string, selection?: OrchestratorConfig[\"modelSelection\"]): number {\n  const preferred = selection?.preferredProviders ?? [];\n  const idx = preferred.findIndex((id) => id.toLowerCase() === providerId.toLowerCase());\n  return idx >= 0 ? 15 - idx : 0;\n}\n\nfunction rankForTag(tag: string, modelId: string, modelName?: string): number {\n  const text = `${modelId} ${modelName ?? \"\"}`.toLowerCase();\n  if (tag === \"auto:fast\") {\n    if (/(mini|small|flash|fast|haiku)/i.test(text)) return 10;\n  }\n  if (tag === \"auto:vision\") {\n    if (/vision|multimodal|image/i.test(text)) return 8;\n  }\n  if (tag === \"auto:docs\") {\n    if (/doc|research|long|context/i.test(text)) return 6;\n  }\n  if (tag === \"auto:code\") {\n    if (/code|coder|instruct/i.test(text)) return 5;\n  }\n  return 0;\n}\n\nfunction capabilityRequirements(tag: string): {\n  requiresVision?: boolean;\n  requiresTools?: boolean;\n  requiresReasoning?: boolean;\n  minContext?: number;\n  maxContext?: number;\n} {\n  switch (tag) {\n    case \"auto:vision\":\n      return { requiresVision: true };\n    case \"auto:fast\":\n      return { maxContext: 32_000 };\n    case \"auto:docs\":\n      return { requiresReasoning: true, minContext: 64_000 };\n    case \"auto:code\":\n      return { requiresTools: true, minContext: 16_000 };\n    case \"auto:reasoning\":\n      return { requiresReasoning: true };\n    default:\n      return {};\n  }\n}\n\nfunction matchesRequirements(cap: ModelCapabilities, requirements: ReturnType<typeof capabilityRequirements>): boolean {\n  if (requirements.requiresVision && !cap.supportsVision) return false;\n  if (requirements.requiresTools && !cap.supportsTools) return false;\n  if (requirements.requiresReasoning && !cap.supportsReasoning) return false;\n  if (requirements.minContext && cap.contextWindow > 0 && cap.contextWindow < requirements.minContext) return false;\n  if (requirements.maxContext && cap.contextWindow > 0 && cap.contextWindow > requirements.maxContext) return false;\n  return true;\n}\n\nfunction pickDefaultModel(\n  providers: Provider[],\n  defaults?: Record<string, string>,\n  selection?: OrchestratorConfig[\"modelSelection\"],\n): ModelResolutionResult | undefined {\n  if (!defaults) return undefined;\n  const preferred = selection?.preferredProviders ?? [];\n  const candidates = preferred.length > 0 ? preferred : Object.keys(defaults);\n  for (const providerId of candidates) {\n    const modelId = defaults[providerId];\n    if (!modelId) continue;\n    const provider = providers.find((p) => p.id === providerId);\n    if (!provider || !(modelId in (provider.models ?? {}))) continue;\n    const model = asModel(provider.models?.[modelId]);\n    const capabilities = deriveModelCapabilities({ model, modelId, modelName: model?.name });\n    return {\n      full: fullModelID(providerId, modelId),\n      providerID: providerId,\n      modelID: modelId,\n      capabilities,\n      reason: \"default provider model\",\n      score: 0,\n    };\n  }\n  return undefined;\n}\n\nfunction collectSuggestions(providers: Provider[], query: string): string[] {\n  const needle = query.toLowerCase();\n  const out: string[] = [];\n  for (const provider of providers) {\n    for (const [modelId, modelEntry] of Object.entries(provider.models ?? {})) {\n      const model = asModel(modelEntry);\n      const name = model?.name ?? \"\";\n      const full = fullModelID(provider.id, modelId);\n      if (\n        modelId.toLowerCase().includes(needle) ||\n        provider.id.toLowerCase().includes(needle) ||\n        name.toLowerCase().includes(needle) ||\n        full.toLowerCase().includes(needle)\n      ) {\n        out.push(full);\n      }\n    }\n  }\n  return out.slice(0, 20);\n}\n\nexport function resolveModel(input: string, ctx: ModelResolutionContext): ModelResolutionResult | ModelResolutionError {\n  const raw = input.trim();\n  if (!raw) return { error: \"Model is required.\" };\n\n  const aliasTarget = resolveAlias(raw, ctx.aliases);\n  const normalizedInput = aliasTarget ?? raw;\n\n  const autoTag = normalizeAutoTag(normalizedInput);\n  const providersAll = ctx.providers;\n\n  if (autoTag) {\n    if (autoTag === \"auto\") {\n      const providerScope = filterProviders(providersAll, \"configured\");\n      const defaultPick = pickDefaultModel(providerScope, ctx.defaults, ctx.selection);\n      if (defaultPick) return defaultPick;\n    }\n\n    const providerScope = filterProviders(providersAll, \"configured\");\n    const requirements = capabilityRequirements(autoTag);\n\n    const candidates: ModelResolutionResult[] = [];\n\n    for (const provider of providerScope) {\n      for (const [modelId, modelEntry] of Object.entries(provider.models ?? {})) {\n        const model = asModel(modelEntry);\n        const full = fullModelID(provider.id, modelId);\n        const overrides = resolveCapabilityOverride(full, ctx.capabilityOverrides);\n        const caps = deriveModelCapabilities({\n          model,\n          modelId,\n          modelName: model?.name,\n          overrides,\n        });\n        if (!matchesRequirements(caps, requirements)) continue;\n\n        let score = 0;\n        if (model?.status === \"deprecated\") score -= 50;\n        score += rankForTag(autoTag, modelId, model?.name);\n\n        if (caps.contextWindow > 0) {\n          if (autoTag === \"auto:docs\") score += Math.min(Math.floor(caps.contextWindow / 64_000), 10);\n          if (autoTag === \"auto:fast\") score -= Math.min(Math.floor(caps.contextWindow / 32_000), 5);\n          if (autoTag === \"auto:code\") score += Math.min(Math.floor(caps.contextWindow / 32_000), 5);\n        }\n\n        if (autoTag === \"auto:cheap\") {\n          score += 5;\n        }\n\n        score += providerPreferenceScore(provider.id, ctx.selection);\n\n        const costScore = scoreCost(caps, ctx.selection);\n        if (costScore.tooExpensive) continue;\n        score += costScore.score;\n\n        candidates.push({\n          full,\n          providerID: provider.id,\n          modelID: modelId,\n          capabilities: caps,\n          reason: `auto-selected (${autoTag})`,\n          score,\n        });\n      }\n    }\n\n    if (candidates.length === 0) {\n      return {\n        error: `No models matched ${autoTag}. Configure a compatible model or set an explicit provider/model ID.`,\n        suggestions: collectSuggestions(providerScope, autoTag),\n      };\n    }\n\n    candidates.sort((a, b) => b.score - a.score);\n    return candidates[0];\n  }\n\n  if (isFullModelID(normalizedInput)) {\n    const parsed = parseFullModelID(normalizedInput);\n    const provider = providersAll.find((p) => p.id === parsed.providerID);\n    if (!provider) {\n      return {\n        error: `Unknown provider \"${parsed.providerID}\".`,\n        suggestions: providersAll.map((p) => p.id).slice(0, 20),\n      };\n    }\n    const modelEntry = provider.models?.[parsed.modelID];\n    if (!modelEntry) {\n      return {\n        error: `Model \"${parsed.modelID}\" not found for provider \"${provider.id}\".`,\n        suggestions: collectSuggestions([provider], parsed.modelID),\n      };\n    }\n    const model = asModel(modelEntry);\n    const overrides = resolveCapabilityOverride(normalizedInput, ctx.capabilityOverrides);\n    const caps = deriveModelCapabilities({\n      model,\n      modelId: parsed.modelID,\n      modelName: model?.name,\n      overrides,\n    });\n    return {\n      full: normalizedInput,\n      providerID: parsed.providerID,\n      modelID: parsed.modelID,\n      capabilities: caps,\n      reason: aliasTarget ? `alias (${raw})` : \"explicit\",\n      score: 0,\n    };\n  }\n\n  const matches: ModelResolutionResult[] = [];\n  for (const provider of providersAll) {\n    for (const [modelId, modelEntry] of Object.entries(provider.models ?? {})) {\n      if (modelId !== normalizedInput) continue;\n      const model = asModel(modelEntry);\n      const full = fullModelID(provider.id, modelId);\n      const overrides = resolveCapabilityOverride(full, ctx.capabilityOverrides);\n      const caps = deriveModelCapabilities({\n        model,\n        modelId,\n        modelName: model?.name,\n        overrides,\n      });\n      matches.push({\n        full,\n        providerID: provider.id,\n        modelID: modelId,\n        capabilities: caps,\n        reason: \"exact match\",\n        score: providerPreferenceScore(provider.id, ctx.selection),\n      });\n    }\n  }\n\n  if (matches.length > 0) {\n    matches.sort((a, b) => b.score - a.score);\n    return matches[0];\n  }\n\n  const suggestions = collectSuggestions(providersAll, normalizedInput);\n  return {\n    error: `Model \"${normalizedInput}\" not found.`,\n    suggestions,\n  };\n}\n"
  },
  {
    "path": "orchestrator/index.ts",
    "content": "import type { ApiService } from \"../api\";\nimport type { CommunicationService } from \"../communication\";\nimport { canAutoSpawn, canSpawnManually, canSpawnOnDemand } from \"../core/spawn-policy\";\nimport type { Factory, OrchestratorConfig, ServiceLifecycle, WorkerInstance } from \"../types\";\nimport type { WorkerManager } from \"../workers\";\nimport type { WorkerAttachment } from \"../workers/prompt\";\nimport type { WorkflowEngine } from \"../workflows/factory\";\nimport type { WorkflowRunResult } from \"../workflows/types\";\nimport { selectWorkerId } from \"./router\";\n\nexport type OrchestratorDeps = {\n  api: ApiService;\n  workers: WorkerManager;\n  workflows?: WorkflowEngine;\n  communication?: CommunicationService;\n};\n\nexport type OrchestratorService = ServiceLifecycle & {\n  ensureWorker: (input: {\n    workerId: string;\n    reason: \"manual\" | \"on-demand\";\n    parentSessionId?: string;\n  }) => Promise<WorkerInstance>;\n  delegateTask: (input: {\n    task: string;\n    attachments?: WorkerAttachment[];\n    autoSpawn?: boolean;\n    parentSessionId?: string;\n  }) => Promise<{ workerId: string; response: string }>;\n  runWorkflow: (input: {\n    workflowId: string;\n    task: string;\n    attachments?: WorkerAttachment[];\n    autoSpawn?: boolean;\n  }) => Promise<WorkflowRunResult>;\n};\n\nexport const createOrchestrator: Factory<OrchestratorConfig, OrchestratorDeps, OrchestratorService> = ({\n  config,\n  deps,\n}) => {\n  const ensureWorker = async (input: {\n    workerId: string;\n    reason: \"manual\" | \"on-demand\";\n    parentSessionId?: string;\n  }) => {\n    const existing = deps.workers.getWorker(input.workerId);\n    if (existing) return existing;\n\n    const allowedByPolicy =\n      input.reason === \"manual\"\n        ? canSpawnManually(config.spawnPolicy, input.workerId)\n        : canSpawnOnDemand(config.spawnPolicy, input.workerId);\n    if (!allowedByPolicy) {\n      throw new Error(`Spawning worker \"${input.workerId}\" is disabled by spawnPolicy.`);\n    }\n\n    // Note: Removed redundant spawnOnDemand whitelist check.\n    // The spawnPolicy check above already controls on-demand spawning.\n    // Vision and other workers should be spawnable on-demand by default.\n\n    return await deps.workers.spawnById(input.workerId, { parentSessionId: input.parentSessionId });\n  };\n\n  const delegateTask = async (input: {\n    task: string;\n    attachments?: WorkerAttachment[];\n    autoSpawn?: boolean;\n    parentSessionId?: string;\n  }) => {\n    const workerId = selectWorkerId({\n      task: input.task,\n      profiles: config.profiles,\n      attachments: input.attachments,\n    });\n    if (!workerId) throw new Error(\"No worker available for this task.\");\n\n    const instance =\n      input.autoSpawn === false\n        ? deps.workers.getWorker(workerId)\n        : await ensureWorker({ workerId, reason: \"on-demand\" });\n\n    if (!instance) {\n      throw new Error(`Worker \"${workerId}\" is not running.`);\n    }\n\n    const res = await deps.workers.send(workerId, input.task, {\n      attachments: input.attachments,\n      sessionId: input.parentSessionId,\n    });\n    if (!res.success || !res.response) {\n      throw new Error(res.error ?? \"Worker request failed\");\n    }\n\n    return { workerId, response: res.response };\n  };\n\n  const runWorkflow = async (input: {\n    workflowId: string;\n    task: string;\n    attachments?: WorkerAttachment[];\n    autoSpawn?: boolean;\n  }) => {\n    if (!deps.workflows) throw new Error(\"Workflows are not enabled.\");\n    return await deps.workflows.run(\n      {\n        workflowId: input.workflowId,\n        task: input.task,\n        attachments: input.attachments,\n        autoSpawn: input.autoSpawn,\n        limits: {\n          maxSteps: config.workflows?.roocodeBoomerang?.maxSteps ?? 6,\n          maxTaskChars: config.workflows?.roocodeBoomerang?.maxTaskChars ?? 4000,\n          maxCarryChars: config.workflows?.roocodeBoomerang?.maxCarryChars ?? 8000,\n          perStepTimeoutMs: config.workflows?.roocodeBoomerang?.perStepTimeoutMs ?? 300_000,\n        },\n      },\n      {\n        resolveWorker: async (workerId, autoSpawn) => {\n          if (autoSpawn === false) return workerId;\n          await ensureWorker({ workerId, reason: \"on-demand\" });\n          return workerId;\n        },\n        sendToWorker: async (workerId, message, options) =>\n          deps.workers.send(workerId, message, {\n            attachments: options.attachments,\n            timeout: options.timeoutMs,\n          }),\n      },\n    );\n  };\n\n  const start = async () => {\n    if (!config.autoSpawn) return;\n    const spawnIds = config.spawn ?? [];\n    // Don't block startup - spawn workers in background\n    if (spawnIds.length > 0) {\n      setTimeout(() => {\n        for (const id of spawnIds) {\n          if (!canAutoSpawn(config.spawnPolicy, id)) continue;\n          deps.workers.spawnById(id).catch(() => {});\n        }\n      }, 100);\n    }\n  };\n\n  const stop = async () => {\n    const workers = deps.workers.listWorkers();\n    await Promise.allSettled(workers.map((w) => deps.workers.stopWorker(w.profile.id)));\n  };\n\n  return {\n    ensureWorker,\n    delegateTask,\n    runWorkflow,\n    start,\n    stop,\n    health: async () => ({ ok: true }),\n  };\n};\n"
  },
  {
    "path": "orchestrator/router.ts",
    "content": "import { findProfile } from \"../profiles/discovery\";\nimport type { WorkerProfile } from \"../types\";\nimport type { WorkerAttachment } from \"../workers/prompt\";\n\nexport function selectWorkerId(input: {\n  task: string;\n  profiles: Record<string, WorkerProfile>;\n  attachments?: WorkerAttachment[];\n}): string | undefined {\n  const hasVision = input.attachments?.some((att) => att.type === \"image\");\n  if (hasVision && input.profiles.vision) return \"vision\";\n\n  const suggested = findProfile(input.task, input.profiles);\n  if (suggested) return suggested;\n\n  if (input.profiles.coder) return \"coder\";\n  return Object.keys(input.profiles)[0];\n}\n"
  },
  {
    "path": "permissions/schema.ts",
    "content": "import type { ToolPermissions } from \"../types\";\n\nexport type { ToolPermissions };\n\nexport type PermissionCategory = \"full\" | \"read\" | \"none\";\nexport type ExecutionPermission = \"full\" | \"sandboxed\" | \"none\";\nexport type NetworkPermission = \"full\" | \"localhost\" | \"none\";\n\nexport const defaultToolPermissions: ToolPermissions = {};\n"
  },
  {
    "path": "permissions/validator.ts",
    "content": "import type { ToolPermissions } from \"../types\";\n\nconst FILESYSTEM_READ_TOOLS = [\"read\", \"ls\", \"glob\", \"rg\", \"search\", \"stat\"];\nconst FILESYSTEM_WRITE_TOOLS = [\"write\", \"edit\", \"patch\", \"delete\", \"mv\", \"cp\", \"mkdir\", \"rmdir\"];\nconst EXECUTION_TOOLS = [\"bash\", \"exec\", \"command\", \"shell\", \"run\", \"process\"];\nconst NETWORK_TOOLS = [\"fetch\", \"curl\", \"wget\", \"http\", \"browser\", \"web_search\", \"web\"];\n\nfunction mergeArrays(base?: string[], override?: string[]): string[] | undefined {\n  const merged = [...(base ?? []), ...(override ?? [])].filter(\n    (value) => typeof value === \"string\" && value.length > 0,\n  );\n  if (merged.length === 0) return undefined;\n  return Array.from(new Set(merged));\n}\n\nexport function mergeToolPermissions(base?: ToolPermissions, override?: ToolPermissions): ToolPermissions | undefined {\n  if (!base && !override) return undefined;\n  if (!base) return override;\n  if (!override) return base;\n\n  return {\n    categories: { ...(base.categories ?? {}), ...(override.categories ?? {}) },\n    tools: { ...(base.tools ?? {}), ...(override.tools ?? {}) },\n    paths: {\n      allowed: mergeArrays(base.paths?.allowed, override.paths?.allowed),\n      denied: mergeArrays(base.paths?.denied, override.paths?.denied),\n    },\n  };\n}\n\nexport function buildToolConfigFromPermissions(input?: {\n  permissions?: ToolPermissions;\n  baseTools?: Record<string, boolean>;\n}): Record<string, boolean> | undefined {\n  const permissions = input?.permissions;\n  const baseTools = input?.baseTools;\n\n  if (!permissions && !baseTools) return undefined;\n\n  const resolved: Record<string, boolean> = { ...(baseTools ?? {}) };\n\n  const filesystem = permissions?.categories?.filesystem;\n  if (filesystem === \"none\") {\n    for (const id of [...FILESYSTEM_READ_TOOLS, ...FILESYSTEM_WRITE_TOOLS]) {\n      resolved[id] = false;\n    }\n  } else if (filesystem === \"read\") {\n    for (const id of FILESYSTEM_WRITE_TOOLS) {\n      resolved[id] = false;\n    }\n  }\n\n  const execution = permissions?.categories?.execution;\n  if (execution === \"none\") {\n    for (const id of EXECUTION_TOOLS) {\n      resolved[id] = false;\n    }\n  }\n\n  const network = permissions?.categories?.network;\n  if (network === \"none\") {\n    for (const id of NETWORK_TOOLS) {\n      resolved[id] = false;\n    }\n  }\n\n  if (permissions?.tools) {\n    for (const [toolId, rule] of Object.entries(permissions.tools)) {\n      if (typeof rule?.enabled === \"boolean\") {\n        resolved[toolId] = rule.enabled;\n      }\n    }\n  }\n\n  return resolved;\n}\n\nexport function summarizePermissions(permissions?: ToolPermissions): string | undefined {\n  if (!permissions) return undefined;\n\n  const parts: string[] = [];\n  if (permissions.categories?.filesystem) parts.push(`filesystem: ${permissions.categories.filesystem}`);\n  if (permissions.categories?.execution) parts.push(`execution: ${permissions.categories.execution}`);\n  if (permissions.categories?.network) parts.push(`network: ${permissions.categories.network}`);\n\n  if (permissions.paths?.allowed?.length) parts.push(`allowed paths: ${permissions.paths.allowed.join(\", \")}`);\n  if (permissions.paths?.denied?.length) parts.push(`denied paths: ${permissions.paths.denied.join(\", \")}`);\n\n  if (permissions.tools) {\n    const overrides = Object.entries(permissions.tools)\n      .map(([toolId, rule]) => `${toolId}: ${rule.enabled ? \"enabled\" : \"disabled\"}`)\n      .join(\", \");\n    if (overrides) parts.push(`tool overrides: ${overrides}`);\n  }\n\n  if (parts.length === 0) return undefined;\n  return parts.join(\"; \");\n}\n"
  },
  {
    "path": "profiles/discovery.ts",
    "content": "import type { WorkerProfile } from \"../types\";\n\nexport type ProfileSuggestion = {\n  id: string;\n  score: number;\n  reason: string;\n};\n\nconst keywordBoosts: Array<{ pattern: RegExp; profileId: string; score: number; reason: string }> = [\n  { pattern: /image|vision|screenshot|diagram|ocr/i, profileId: \"vision\", score: 40, reason: \"vision task\" },\n  {\n    pattern: /docs?|documentation|reference|api|research|cite|example/i,\n    profileId: \"docs\",\n    score: 35,\n    reason: \"documentation\",\n  },\n  { pattern: /code|implement|bug|fix|refactor|test|build/i, profileId: \"coder\", score: 30, reason: \"coding task\" },\n  { pattern: /architecture|design|plan|tradeoff|strategy/i, profileId: \"architect\", score: 25, reason: \"architecture\" },\n  { pattern: /search|find|locate|where|explore/i, profileId: \"explorer\", score: 20, reason: \"codebase search\" },\n  { pattern: /memory|neo4j|knowledge/i, profileId: \"memory\", score: 20, reason: \"memory system\" },\n];\n\nfunction tokenize(text: string): string[] {\n  const tokens = text.toLowerCase().match(/[a-z0-9]+/g);\n  return tokens ? Array.from(new Set(tokens)) : [];\n}\n\nexport function suggestProfiles(\n  query: string,\n  profiles: Record<string, WorkerProfile>,\n  options?: { limit?: number },\n): ProfileSuggestion[] {\n  const tokens = tokenize(query);\n  const suggestions: ProfileSuggestion[] = [];\n\n  for (const profile of Object.values(profiles)) {\n    let score = 0;\n    const reasons: string[] = [];\n\n    for (const boost of keywordBoosts) {\n      if (boost.profileId === profile.id && boost.pattern.test(query)) {\n        score += boost.score;\n        reasons.push(boost.reason);\n      }\n    }\n\n    const haystack = [profile.id, profile.name, profile.purpose, profile.whenToUse, ...(profile.tags ?? [])]\n      .join(\" \")\n      .toLowerCase();\n\n    for (const token of tokens) {\n      if (profile.id.toLowerCase().includes(token)) {\n        score += 12;\n        reasons.push(`id match: ${token}`);\n      } else if ((profile.tags ?? []).some((tag) => tag.toLowerCase().includes(token))) {\n        score += 8;\n        reasons.push(`tag match: ${token}`);\n      } else if (haystack.includes(token)) {\n        score += 4;\n        reasons.push(`text match: ${token}`);\n      }\n    }\n\n    if (score > 0) {\n      suggestions.push({\n        id: profile.id,\n        score,\n        reason: Array.from(new Set(reasons)).join(\", \") || \"matched\",\n      });\n    }\n  }\n\n  suggestions.sort((a, b) => b.score - a.score || a.id.localeCompare(b.id));\n  return suggestions.slice(0, options?.limit ?? 5);\n}\n\nexport function findProfile(query: string, profiles: Record<string, WorkerProfile>): string | undefined {\n  const suggestions = suggestProfiles(query, profiles, { limit: 1 });\n  return suggestions[0]?.id;\n}\n"
  },
  {
    "path": "prompts/index.ts",
    "content": "export { buildOrchestratorSystemPrompt, buildWorkerSummary } from \"./orchestrator-system\";\n"
  },
  {
    "path": "prompts/orchestrator-system.ts",
    "content": "import type { OrchestratorConfig, WorkerProfile } from \"../types\";\n\ntype OrchestratorPromptInput = {\n  config: OrchestratorConfig;\n  profiles: WorkerProfile[];\n  runningWorkers: Array<{ id: string; name: string; status: string }>;\n  memoryEnabled: boolean;\n};\n\n/**\n * Build the orchestrator system prompt that teaches the AI how to:\n * - Use workers intentionally (not auto-spawning)\n * - Update the memory graph at end of turns\n * - Delegate tasks appropriately\n */\nexport function buildOrchestratorSystemPrompt(input: OrchestratorPromptInput): string {\n  const { profiles, runningWorkers, memoryEnabled } = input;\n\n  const sections: string[] = [];\n\n  // Core orchestrator identity\n  sections.push(\n    `\n<orchestrator-role>\nYou are the OpenCode Orchestrator - a coordination layer that manages specialized AI workers.\nYour role is to understand tasks, select appropriate workers, and ensure work is completed effectively.\n\nIMPORTANT PRINCIPLES:\n1. Workers are spawned ON-DEMAND, not automatically. Only spawn workers when needed for a task.\n2. Prefer completing simple tasks yourself rather than delegating to workers.\n3. Use workers for specialized capabilities you lack (vision, specific models, domain expertise).\n4. Track work across multiple workers and synthesize results.\n</orchestrator-role>\n`.trim(),\n  );\n\n  // Available workers section\n  if (profiles.length > 0) {\n    const profileLines = profiles\n      .filter((p) => p.enabled !== false)\n      .map((p) => {\n        const capabilities: string[] = [];\n        if (p.supportsVision) capabilities.push(\"vision\");\n        if (p.supportsWeb) capabilities.push(\"web\");\n        const capStr = capabilities.length > 0 ? ` [${capabilities.join(\", \")}]` : \"\";\n        return `  - ${p.id}: ${p.name}${capStr}\\n    Purpose: ${p.purpose || \"General purpose worker\"}\\n    When to use: ${p.whenToUse || \"When specialized assistance is needed\"}`;\n      })\n      .join(\"\\n\\n\");\n\n    sections.push(\n      `\n<available-workers>\nThe following worker profiles are available. They are NOT running until you spawn them:\n\n${profileLines}\n\nTo use a worker:\n1. First spawn it: spawn_worker({ profileId: \"<id>\" })\n2. Then message it: ask_worker({ workerId: \"<id>\", message: \"<task>\" })\n3. Or delegate directly: delegate_task({ task: \"<task description>\" }) - auto-selects best worker\n\nSPAWN GUIDELINES:\n- Only spawn workers when you need their specific capabilities\n- Reuse already-running workers (check running workers below)\n- Stop workers when done with a long task sequence: stop_worker({ workerId: \"<id>\" })\n</available-workers>\n`.trim(),\n    );\n  }\n\n  // Running workers\n  if (runningWorkers.length > 0) {\n    const workerLines = runningWorkers.map((w) => `  - ${w.id} (${w.name})  ${w.status}`).join(\"\\n\");\n    sections.push(\n      `\n<running-workers>\nCurrently running workers (reuse these before spawning new ones):\n${workerLines}\n</running-workers>\n`.trim(),\n    );\n  } else {\n    sections.push(\n      `\n<running-workers>\nNo workers are currently running. Spawn workers on-demand as needed.\n</running-workers>\n`.trim(),\n    );\n  }\n\n  // Memory graph protocol\n  if (memoryEnabled) {\n    sections.push(\n      `\n<memory-protocol>\nMEMORY GRAPH INTEGRATION:\n\nAt the END of each turn where you learn something significant, update the memory graph:\n\n1. RECORD important information using memory_record:\n   - Key decisions made\n   - User preferences discovered\n   - Important context for future sessions\n   - Task outcomes and learnings\n\n2. QUERY relevant context using memory_query when starting new tasks:\n   - Check for prior work on similar topics\n   - Retrieve user preferences\n   - Find related decisions or context\n\n3. What to record:\n   - Facts: \"User prefers TypeScript over JavaScript\"\n   - Decisions: \"Chose React Query for data fetching because...\"\n   - Context: \"Project uses monorepo structure with Bun workspaces\"\n   - Outcomes: \"Refactored auth module, reduced bundle size by 30%\"\n\n4. What NOT to record:\n   - Transient debugging information\n   - Obvious or self-evident facts\n   - Sensitive credentials or secrets\n\nExample turn-end memory update:\n\\`\\`\\`\nmemory_record({\n  text: \"User prefers to see test coverage reports after each test run\",\n  metadata: { category: \"preference\", topic: \"testing\" }\n})\n\\`\\`\\`\n</memory-protocol>\n`.trim(),\n    );\n  }\n\n  // Vision/image handling convention\n  sections.push(\n    `\n<vision-convention>\nIMAGE HANDLING:\nWhen you see content wrapped in <pasted_image>...</pasted_image> tags, this is a TEXT DESCRIPTION of an image that was already analyzed by a vision worker.\n\n- The image has ALREADY been processed - do NOT try to view, read, or analyze the image yourself\n- The text inside <pasted_image> tags IS the image content - treat it as factual description\n- Respond to the user's question using this text description as your source of truth\n- Do NOT say \"I cannot see the image\" - you have the description, use it\n\nExample:\nUser sends: \"<pasted_image>A red button with 'Submit' text</pasted_image> What color is the button?\"\nYou respond: \"The button is red.\"\n\nNOT: \"I cannot view images\" or \"Let me analyze this image\"\n</vision-convention>\n`.trim(),\n  );\n\n  // Tool usage guidelines\n  sections.push(\n    `\n<tool-guidelines>\nWORKER TOOLS:\n- spawn_worker({ profileId }) - Start a worker (if not already running)\n- ask_worker({ workerId, message }) - Send a message and wait for response\n- ask_worker_async({ workerId, message }) - Send without waiting (for parallel work)\n- await_worker_job({ jobId }) - Wait for async job result\n- delegate_task({ task }) - Auto-select worker and complete task\n- stop_worker({ workerId }) - Stop a running worker\n- list_workers() - See all running workers\n\nMEMORY TOOLS (when enabled):\n- memory_record({ text, metadata? }) - Store information\n- memory_query({ query, limit? }) - Retrieve relevant context\n\nDECISION FRAMEWORK:\n1. Can I complete this myself?  Do it directly\n2. Do I need vision/special model?  Spawn appropriate worker\n3. Is the task complex with subtasks?  Consider delegate_task or workflow\n4. Am I learning something reusable?  Record to memory\n</tool-guidelines>\n`.trim(),\n  );\n\n  return sections.join(\"\\n\\n\");\n}\n\n/**\n * Build a concise worker summary for injection into system context.\n */\nexport function buildWorkerSummary(input: {\n  runningWorkers: Array<{ id: string; name: string; status: string }>;\n  maxWorkers?: number;\n}): string {\n  const { runningWorkers, maxWorkers = 12 } = input;\n  const workers = runningWorkers.slice(0, maxWorkers);\n\n  if (workers.length === 0) {\n    return \"No workers currently running. Use spawn_worker or delegate_task to start workers on-demand.\";\n  }\n\n  const lines = [\"## Running Workers\", \"\"];\n  if (runningWorkers.length > workers.length) {\n    lines.push(`(showing ${workers.length} of ${runningWorkers.length})`, \"\");\n  }\n  for (const w of workers) {\n    lines.push(`- ${w.id} (${w.name})  ${w.status}`);\n  }\n  lines.push(\"\", \"Use ask_worker({ workerId, message }) to message a worker.\");\n  return lines.join(\"\\n\");\n}\n"
  },
  {
    "path": "skills/builtin.ts",
    "content": "import type { Skill } from \"../types\";\n\n/**\n * Load builtin skills.\n *\n * With the new skill system, there are no hardcoded builtins.\n * All profiles come from .opencode/skill/ SKILL.md files.\n *\n * This function returns an empty map for backwards compatibility.\n * It will be removed in a future version.\n *\n * @deprecated Profiles are now loaded from .opencode/skill/\n */\nexport function loadBuiltinSkills(): Map<string, Skill> {\n  // No more hardcoded builtins - everything comes from SKILL.md files\n  return new Map();\n}\n"
  },
  {
    "path": "skills/convert.ts",
    "content": "import type { Skill, SkillFrontmatter, SkillSource, WorkerProfile } from \"../types\";\n\nfunction combineDescription(purpose?: string, whenToUse?: string): string {\n  const parts = [purpose?.trim(), whenToUse?.trim()].filter(Boolean) as string[];\n  if (parts.length === 0) return \"General-purpose skill.\";\n  if (parts.length === 1) return parts[0];\n  const combined = `${parts[0]} When to use: ${parts[1]}`;\n  return combined.length > 1024 ? `${combined.slice(0, 1021).trimEnd()}...` : combined;\n}\n\nexport function profileToSkill(profile: WorkerProfile, source: SkillSource): Skill {\n  const frontmatter: SkillFrontmatter = {\n    name: profile.id,\n    description: combineDescription(profile.purpose, profile.whenToUse),\n    model: profile.model,\n    providerID: profile.providerID,\n    temperature: profile.temperature,\n    tools: profile.tools,\n    permissions: profile.permissions,\n    tags: profile.tags,\n    supportsVision: profile.supportsVision,\n    supportsWeb: profile.supportsWeb,\n    injectRepoContext: profile.injectRepoContext,\n    extends: profile.extends,\n    compose: profile.compose,\n    // Session mode configuration\n    sessionMode: profile.sessionMode,\n    forwardEvents: profile.forwardEvents,\n    mcp: profile.mcp,\n    integrations: profile.integrations,\n    env: profile.env,\n    envPrefixes: profile.envPrefixes,\n    skillPermissions: profile.skillPermissions,\n  };\n\n  return {\n    id: profile.id,\n    source,\n    frontmatter,\n    systemPrompt: profile.systemPrompt ?? \"\",\n    filePath: source.type === \"builtin\" ? `builtin:${profile.id}` : \"\",\n    hasScripts: false,\n    hasReferences: false,\n    hasAssets: false,\n  };\n}\n\nexport function skillToProfile(skill: Skill): WorkerProfile {\n  return {\n    id: skill.frontmatter.name ?? skill.id,\n    name: skill.frontmatter.name ?? skill.id,\n    model: skill.frontmatter.model ?? \"auto\",\n    providerID: skill.frontmatter.providerID,\n    purpose: skill.frontmatter.description ?? \"General-purpose skill.\",\n    whenToUse: skill.frontmatter.description ?? \"General-purpose skill.\",\n    systemPrompt: skill.systemPrompt,\n    supportsVision: skill.frontmatter.supportsVision,\n    supportsWeb: skill.frontmatter.supportsWeb,\n    tools: skill.frontmatter.tools,\n    temperature: skill.frontmatter.temperature,\n    tags: skill.frontmatter.tags,\n    injectRepoContext: skill.frontmatter.injectRepoContext,\n    permissions: skill.frontmatter.permissions,\n    extends: skill.frontmatter.extends,\n    compose: skill.frontmatter.compose,\n    // Session mode configuration\n    sessionMode: skill.frontmatter.sessionMode,\n    forwardEvents: skill.frontmatter.forwardEvents,\n    mcp: skill.frontmatter.mcp,\n    integrations: skill.frontmatter.integrations,\n    env: skill.frontmatter.env,\n    envPrefixes: skill.frontmatter.envPrefixes,\n    skillPermissions: skill.frontmatter.skillPermissions,\n    source: skill.source,\n  };\n}\n"
  },
  {
    "path": "skills/crud.ts",
    "content": "import { existsSync } from \"node:fs\";\nimport { mkdir, rm, writeFile } from \"node:fs/promises\";\nimport { dirname, join } from \"node:path\";\nimport type { Skill, SkillInput, SkillScope } from \"../types\";\nimport { loadSkill, loadSkillOverrides } from \"./loader\";\nimport { serializeSkillFile } from \"./parse\";\nimport {\n  getGlobalSkillsDir,\n  getGlobalSubagentsDir,\n  getProjectSkillsDirs,\n  getProjectSubagentsDirs,\n  getSkillFilePath,\n  resolveProjectDir,\n} from \"./paths\";\nimport { validateSkillInput } from \"./validate\";\n\nfunction toValidationMessage(result: ReturnType<typeof validateSkillInput>): string {\n  return result.errors.map((err) => `${err.field}: ${err.message}`).join(\"; \");\n}\n\nfunction findScopedSkillFilePath(id: string, scope: SkillScope, projectDir?: string): string | null {\n  const resolvedProjectDir = scope === \"project\" ? resolveProjectDir(projectDir) : undefined;\n  const roots =\n    scope === \"global\"\n      ? [getGlobalSkillsDir(), getGlobalSubagentsDir()]\n      : resolvedProjectDir\n        ? [...getProjectSkillsDirs(resolvedProjectDir), ...getProjectSubagentsDirs(resolvedProjectDir)]\n        : [];\n\n  for (const root of roots) {\n    const filePath = join(root, id, \"SKILL.md\");\n    if (existsSync(filePath)) return filePath;\n  }\n\n  return null;\n}\n\nasync function writeSkillFile(filePath: string, input: SkillInput): Promise<void> {\n  await mkdir(dirname(filePath), { recursive: true });\n  const frontmatter = {\n    ...input.frontmatter,\n    name: input.frontmatter.name ?? input.id,\n  };\n  const content = serializeSkillFile(frontmatter, input.systemPrompt ?? \"\");\n  await writeFile(filePath, content, \"utf8\");\n}\n\nexport async function createSkill(input: SkillInput, scope: SkillScope, projectDir?: string): Promise<Skill> {\n  const validation = validateSkillInput(input);\n  if (!validation.valid) throw new Error(`Invalid skill input: ${toValidationMessage(validation)}`);\n\n  const resolvedProjectDir = scope === \"project\" ? resolveProjectDir(projectDir) : projectDir;\n  const filePath = getSkillFilePath(input.id, scope, resolvedProjectDir);\n  if (existsSync(filePath)) {\n    throw new Error(`Skill \"${input.id}\" already exists in ${scope} scope.`);\n  }\n\n  await writeSkillFile(filePath, input);\n  const skill = await loadSkill(input.id, projectDir);\n  if (!skill) throw new Error(`Skill \"${input.id}\" could not be loaded after creation.`);\n  return skill;\n}\n\nexport async function updateSkill(\n  id: string,\n  updates: Partial<SkillInput>,\n  scope: SkillScope,\n  projectDir?: string,\n): Promise<Skill> {\n  const lookupDir = scope === \"project\" ? resolveProjectDir(projectDir) : undefined;\n  const base = await loadSkill(id, lookupDir);\n  const filePath =\n    findScopedSkillFilePath(id, scope, lookupDir) ?? getSkillFilePath(id, scope, lookupDir ?? projectDir);\n\n  const merged: SkillInput = {\n    id,\n    frontmatter: {\n      ...(base?.frontmatter ?? {}),\n      ...(updates.frontmatter ?? {}),\n      name: updates.frontmatter?.name ?? base?.frontmatter.name ?? id,\n      description: updates.frontmatter?.description ?? base?.frontmatter.description ?? \"\",\n      model: updates.frontmatter?.model ?? base?.frontmatter.model ?? \"\",\n    },\n    systemPrompt: updates.systemPrompt ?? base?.systemPrompt ?? \"\",\n  };\n\n  const validation = validateSkillInput(merged);\n  if (!validation.valid) throw new Error(`Invalid skill input: ${toValidationMessage(validation)}`);\n\n  await writeSkillFile(filePath, merged);\n  const skill = await loadSkill(id, projectDir);\n  if (!skill) throw new Error(`Skill \"${id}\" could not be loaded after update.`);\n  return skill;\n}\n\nexport async function deleteSkill(id: string, scope: SkillScope, projectDir?: string): Promise<boolean> {\n  const lookupDir = scope === \"project\" ? resolveProjectDir(projectDir) : projectDir;\n  const filePath = findScopedSkillFilePath(id, scope, lookupDir);\n  if (!filePath) return false;\n  await rm(dirname(filePath), { recursive: true, force: true });\n  return true;\n}\n\nexport async function duplicateSkill(\n  sourceId: string,\n  newId: string,\n  scope: SkillScope,\n  projectDir?: string,\n): Promise<Skill> {\n  const source = await loadSkill(sourceId, projectDir);\n  if (!source) throw new Error(`Source skill \"${sourceId}\" not found.`);\n\n  const input: SkillInput = {\n    id: newId,\n    frontmatter: {\n      ...source.frontmatter,\n      name: newId,\n    },\n    systemPrompt: source.systemPrompt,\n  };\n\n  return await createSkill(input, scope, projectDir);\n}\n\nexport async function listSkillOverrides(projectDir?: string): Promise<Skill[]> {\n  const map = await loadSkillOverrides(projectDir);\n  return Array.from(map.values());\n}\n"
  },
  {
    "path": "skills/events.ts",
    "content": "import { EventEmitter } from \"node:events\";\nimport type { Skill, SkillScope } from \"../types\";\n\nexport type SkillEvent =\n  | { type: \"skill.created\"; skill: Skill }\n  | { type: \"skill.updated\"; skill: Skill }\n  | { type: \"skill.deleted\"; id: string; scope: SkillScope };\n\nexport type SkillsEvents = {\n  emit: (event: SkillEvent) => void;\n  on: (listener: (event: SkillEvent) => void) => () => void;\n};\n\nexport function createSkillsEvents(): SkillsEvents {\n  const emitter = new EventEmitter();\n\n  return {\n    emit: (event) => {\n      emitter.emit(\"event\", event);\n    },\n    on: (listener) => {\n      emitter.on(\"event\", listener);\n      return () => emitter.off(\"event\", listener);\n    },\n  };\n}\n"
  },
  {
    "path": "skills/index.ts",
    "content": "export * from \"./builtin\";\nexport * from \"./convert\";\nexport * from \"./crud\";\nexport * from \"./events\";\nexport * from \"./loader\";\nexport * from \"./parse\";\nexport * from \"./paths\";\nexport * from \"./service\";\nexport * from \"./validate\";\n"
  },
  {
    "path": "skills/loader.ts",
    "content": "import { existsSync } from \"node:fs\";\nimport { readdir, readFile, stat } from \"node:fs/promises\";\nimport { dirname, join } from \"node:path\";\nimport type { Skill, SkillSource } from \"../types\";\nimport { parseSkillFile } from \"./parse\";\nimport {\n  getGlobalSkillsDir,\n  getGlobalSubagentsDir,\n  getProjectSkillsDirs,\n  getProjectSubagentsDirs,\n  resolveProjectDir,\n} from \"./paths\";\nimport { validateSkillFrontmatter } from \"./validate\";\n\ntype SkillLocation = {\n  id: string;\n  filePath: string;\n  source: SkillSource;\n};\n\ntype SkillRoot = {\n  root: string;\n  source: SkillSource;\n};\n\nfunction getSkillRoots(projectDir?: string): SkillRoot[] {\n  const roots: SkillRoot[] = [];\n  const globalSkills = getGlobalSkillsDir();\n  const globalSubagents = getGlobalSubagentsDir();\n  const resolvedDir = resolveProjectDir(projectDir);\n\n  if (resolvedDir) {\n    const projectSkills = getProjectSkillsDirs(resolvedDir);\n    const projectSubagents = getProjectSubagentsDirs(resolvedDir);\n    for (const root of projectSkills) {\n      roots.push({ root, source: { type: \"project\", path: root } });\n    }\n    for (const root of projectSubagents) {\n      roots.push({ root, source: { type: \"project\", path: root } });\n    }\n  }\n\n  roots.push({ root: globalSkills, source: { type: \"global\", path: globalSkills } });\n  roots.push({ root: globalSubagents, source: { type: \"global\", path: globalSubagents } });\n\n  return roots;\n}\n\nasync function detectSkillDirs(root: string, source: SkillSource): Promise<SkillLocation[]> {\n  if (!existsSync(root)) return [];\n  const entries = await readdir(root, { withFileTypes: true });\n  const locations: SkillLocation[] = [];\n  for (const entry of entries) {\n    if (!entry.isDirectory()) continue;\n    const filePath = join(root, entry.name, \"SKILL.md\");\n    if (!existsSync(filePath)) continue;\n    locations.push({ id: entry.name, filePath, source });\n  }\n  return locations;\n}\n\nasync function loadSkillFile(location: SkillLocation): Promise<Skill> {\n  const raw = await readFile(location.filePath, \"utf8\");\n  const parsed = parseSkillFile(raw);\n  const frontmatter = {\n    ...(parsed.frontmatter as Record<string, unknown>),\n    name: (parsed.frontmatter as Record<string, unknown>).name ?? location.id,\n  } as Skill[\"frontmatter\"];\n\n  if (frontmatter.name !== location.id) {\n    throw new Error(`Skill name \"${frontmatter.name}\" must match directory \"${location.id}\".`);\n  }\n\n  const validation = validateSkillFrontmatter(frontmatter);\n  if (!validation.valid) {\n    const details = validation.errors.map((err) => `${err.field}: ${err.message}`).join(\"; \");\n    throw new Error(`Invalid skill \"${location.id}\": ${details}`);\n  }\n\n  const info = await stat(location.filePath);\n  const root = dirname(location.filePath);\n\n  return {\n    id: location.id,\n    source: location.source,\n    frontmatter,\n    systemPrompt: parsed.body,\n    filePath: location.filePath,\n    hasScripts: existsSync(join(root, \"scripts\")),\n    hasReferences: existsSync(join(root, \"references\")),\n    hasAssets: existsSync(join(root, \"assets\")),\n    createdAt: info.birthtime,\n    updatedAt: info.mtime,\n  };\n}\n\nexport async function loadSkill(id: string, projectDir?: string): Promise<Skill | undefined> {\n  const roots = getSkillRoots(projectDir).slice().reverse();\n  for (const root of roots) {\n    const filePath = join(root.root, id, \"SKILL.md\");\n    if (existsSync(filePath)) {\n      return await loadSkillFile({ id, filePath, source: root.source });\n    }\n  }\n\n  const { loadBuiltinSkills } = await import(\"./builtin\");\n  const builtins = loadBuiltinSkills();\n  return builtins.get(id);\n}\n\nexport async function loadSkillOverrides(projectDir?: string): Promise<Map<string, Skill>> {\n  const skills = new Map<string, Skill>();\n  const roots = getSkillRoots(projectDir);\n  for (const root of roots) {\n    const entries = await detectSkillDirs(root.root, root.source);\n    for (const location of entries) {\n      try {\n        skills.set(location.id, await loadSkillFile(location));\n      } catch {\n        // Ignore invalid skills in listing.\n      }\n    }\n  }\n\n  return skills;\n}\n\nexport async function loadAllSkills(projectDir?: string): Promise<Map<string, Skill>> {\n  const { loadBuiltinSkills } = await import(\"./builtin\");\n  const skills = loadBuiltinSkills();\n  const overrides = await loadSkillOverrides(projectDir);\n\n  for (const [id, skill] of overrides) {\n    skills.set(id, skill);\n  }\n\n  return skills;\n}\n"
  },
  {
    "path": "skills/parse.ts",
    "content": "import { parse as parseYaml, stringify as stringifyYaml } from \"yaml\";\n\nexport type ParsedSkillFile = {\n  frontmatter: Record<string, unknown>;\n  body: string;\n};\n\nexport function parseSkillFile(contents: string): ParsedSkillFile {\n  const normalized = contents.replace(/^\\uFEFF/, \"\");\n  const lines = normalized.split(/\\r?\\n/);\n  if (lines.length === 0 || lines[0].trim() !== \"---\") {\n    throw new Error(\"Skill file must start with YAML frontmatter (---).\");\n  }\n\n  let endIndex = -1;\n  for (let i = 1; i < lines.length; i += 1) {\n    if (lines[i].trim() === \"---\") {\n      endIndex = i;\n      break;\n    }\n  }\n\n  if (endIndex === -1) {\n    throw new Error(\"Skill frontmatter must be closed with ---.\");\n  }\n\n  const yamlText = lines.slice(1, endIndex).join(\"\\n\");\n  const parsed = parseYaml(yamlText);\n  if (!parsed || typeof parsed !== \"object\" || Array.isArray(parsed)) {\n    throw new Error(\"Skill frontmatter must be a YAML object.\");\n  }\n\n  const body = lines\n    .slice(endIndex + 1)\n    .join(\"\\n\")\n    .trim();\n\n  return {\n    frontmatter: parsed as Record<string, unknown>,\n    body,\n  };\n}\n\nexport function serializeSkillFile(frontmatter: Record<string, unknown>, body: string): string {\n  const yaml = stringifyYaml(frontmatter).trimEnd();\n  const trimmedBody = body.trim();\n  return `---\\n${yaml}\\n---\\n\\n${trimmedBody}\\n`;\n}\n"
  },
  {
    "path": "skills/paths.ts",
    "content": "import { existsSync } from \"node:fs\";\nimport { homedir } from \"node:os\";\nimport { dirname, join } from \"node:path\";\nimport { fileURLToPath } from \"node:url\";\nimport type { SkillScope } from \"../types\";\n\n// Skills are stored in .opencode/skill/\n// Subagents are stored in .opencode/agent/subagents/\n// Both are treated as skill sources.\nconst SKILL_DIR_PATH = [\"skill\"];\nconst SUBAGENT_DIR_PATH = [\"agent\", \"subagents\"];\nconst ORCHESTRA_DIR = \"orchestra\";\nconst SKILL_DIR_MARKERS = [\n  [\".opencode\", ...SKILL_DIR_PATH],\n  [\".opencode\", ...SUBAGENT_DIR_PATH],\n  [ORCHESTRA_DIR, \".opencode\", ...SKILL_DIR_PATH],\n  [ORCHESTRA_DIR, \".opencode\", ...SUBAGENT_DIR_PATH],\n];\n\nconst MODULE_ROOT = (() => {\n  const moduleDir = dirname(fileURLToPath(import.meta.url));\n  return dirname(dirname(moduleDir));\n})();\n\nfunction uniquePaths(paths: string[]): string[] {\n  const seen = new Set<string>();\n  const result: string[] = [];\n  for (const path of paths) {\n    if (seen.has(path)) continue;\n    seen.add(path);\n    result.push(path);\n  }\n  return result;\n}\n\nexport function hasProjectSkillDirs(projectDir: string): boolean {\n  return SKILL_DIR_MARKERS.some((parts) => existsSync(join(projectDir, ...parts)));\n}\n\nexport function inferProjectDir(startDir: string = process.cwd()): string | undefined {\n  let current = startDir;\n  while (true) {\n    if (hasProjectSkillDirs(current)) return current;\n    const parent = dirname(current);\n    if (parent === current) return undefined;\n    current = parent;\n  }\n}\n\nexport function resolveProjectDir(projectDir?: string): string | undefined {\n  const explicitDir =\n    projectDir ?? process.env.OPENCODE_PROJECT_DIR ?? process.env.OPENCODE_WORKDIR ?? process.env.OPENCODE_WORKTREE;\n  if (explicitDir) {\n    if (hasProjectSkillDirs(explicitDir)) return explicitDir;\n    return inferProjectDir(explicitDir) ?? explicitDir;\n  }\n  if (hasProjectSkillDirs(MODULE_ROOT)) return MODULE_ROOT;\n  const inferred = inferProjectDir();\n  return inferred;\n}\n\nexport function getProjectSkillsDir(projectDir: string): string {\n  const candidates = getProjectSkillsDirs(projectDir);\n  for (const candidate of candidates) {\n    if (existsSync(candidate)) return candidate;\n  }\n  return candidates[0];\n}\n\nexport function getGlobalSkillsDir(): string {\n  const home = process.env.OPENCODE_SKILLS_HOME ?? homedir();\n  return join(home, \".opencode\", ...SKILL_DIR_PATH);\n}\n\nexport function getProjectSkillsDirs(projectDir: string): string[] {\n  return uniquePaths([\n    join(projectDir, \".opencode\", ...SKILL_DIR_PATH),\n    join(projectDir, ORCHESTRA_DIR, \".opencode\", ...SKILL_DIR_PATH),\n  ]);\n}\n\nexport function getProjectSubagentsDir(projectDir: string): string {\n  const candidates = getProjectSubagentsDirs(projectDir);\n  for (const candidate of candidates) {\n    if (existsSync(candidate)) return candidate;\n  }\n  return candidates[0];\n}\n\nexport function getGlobalSubagentsDir(): string {\n  const home = process.env.OPENCODE_SKILLS_HOME ?? homedir();\n  return join(home, \".opencode\", ...SUBAGENT_DIR_PATH);\n}\n\nexport function getProjectSubagentsDirs(projectDir: string): string[] {\n  return uniquePaths([\n    join(projectDir, \".opencode\", ...SUBAGENT_DIR_PATH),\n    join(projectDir, ORCHESTRA_DIR, \".opencode\", ...SUBAGENT_DIR_PATH),\n  ]);\n}\n\nexport function getSkillDir(id: string, scope: SkillScope, projectDir?: string): string {\n  if (scope === \"global\") return join(getGlobalSkillsDir(), id);\n  if (!projectDir) throw new Error(\"Project directory is required for project-scoped skills.\");\n  return join(getProjectSkillsDir(projectDir), id);\n}\n\nexport function getSubagentDir(id: string, scope: SkillScope, projectDir?: string): string {\n  if (scope === \"global\") return join(getGlobalSubagentsDir(), id);\n  if (!projectDir) throw new Error(\"Project directory is required for project-scoped skills.\");\n  return join(getProjectSubagentsDir(projectDir), id);\n}\n\nexport function getSkillFilePath(id: string, scope: SkillScope, projectDir?: string): string {\n  return join(getSkillDir(id, scope, projectDir), \"SKILL.md\");\n}\n\nexport function getSubagentFilePath(id: string, scope: SkillScope, projectDir?: string): string {\n  return join(getSubagentDir(id, scope, projectDir), \"SKILL.md\");\n}\n"
  },
  {
    "path": "skills/service.ts",
    "content": "import type { Skill, SkillInput, SkillScope } from \"../types\";\nimport { createSkill, deleteSkill, duplicateSkill, updateSkill } from \"./crud\";\nimport { createSkillsEvents, type SkillsEvents } from \"./events\";\nimport { loadAllSkills, loadSkill } from \"./loader\";\nimport { resolveProjectDir } from \"./paths\";\n\nexport interface SkillsService {\n  events: SkillsEvents;\n  list(projectDir?: string): Promise<Skill[]>;\n  get(id: string, projectDir?: string): Promise<Skill | undefined>;\n  create(input: SkillInput, scope: SkillScope, projectDir?: string): Promise<Skill>;\n  update(id: string, updates: Partial<SkillInput>, scope: SkillScope, projectDir?: string): Promise<Skill>;\n  delete(id: string, scope: SkillScope, projectDir?: string): Promise<boolean>;\n  duplicate(sourceId: string, newId: string, scope: SkillScope, projectDir?: string): Promise<Skill>;\n}\n\nexport function createSkillsService(projectDir?: string): SkillsService {\n  const events = createSkillsEvents();\n  const resolvedDir = resolveProjectDir(projectDir);\n\n  return {\n    events,\n    async list() {\n      const skills = await loadAllSkills(resolvedDir);\n      return Array.from(skills.values());\n    },\n\n    async get(id) {\n      return loadSkill(id, resolvedDir);\n    },\n\n    async create(input, scope) {\n      const skill = await createSkill(input, scope, resolvedDir);\n      events.emit({ type: \"skill.created\", skill });\n      return skill;\n    },\n\n    async update(id, updates, scope) {\n      const skill = await updateSkill(id, updates, scope, resolvedDir);\n      events.emit({ type: \"skill.updated\", skill });\n      return skill;\n    },\n\n    async delete(id, scope) {\n      const ok = await deleteSkill(id, scope, resolvedDir);\n      if (ok) events.emit({ type: \"skill.deleted\", id, scope });\n      return ok;\n    },\n\n    async duplicate(sourceId, newId, scope) {\n      const skill = await duplicateSkill(sourceId, newId, scope, resolvedDir);\n      events.emit({ type: \"skill.created\", skill });\n      return skill;\n    },\n  };\n}\n"
  },
  {
    "path": "skills/validate.ts",
    "content": "import type {\n  SkillFrontmatter,\n  SkillInput,\n  SkillValidationError,\n  SkillValidationResult,\n  ToolPermissions,\n} from \"../types\";\n\nconst NAME_PATTERN = /^[a-z0-9]+(-[a-z0-9]+)*$/;\n\nfunction isPlainObject(value: unknown): value is Record<string, unknown> {\n  return typeof value === \"object\" && value !== null && !Array.isArray(value);\n}\n\nfunction isBooleanRecord(value: unknown): value is Record<string, boolean> {\n  if (!isPlainObject(value)) return false;\n  return Object.values(value).every((v) => typeof v === \"boolean\");\n}\n\nfunction isStringArray(value: unknown): value is string[] {\n  return Array.isArray(value) && value.every((v) => typeof v === \"string\");\n}\n\nfunction validatePermissions(permissions: unknown, errors: SkillValidationError[]): ToolPermissions | undefined {\n  if (!permissions) return undefined;\n  if (!isPlainObject(permissions)) {\n    errors.push({ field: \"permissions\", message: \"Permissions must be an object.\" });\n    return undefined;\n  }\n\n  const out: ToolPermissions = {};\n\n  if (isPlainObject(permissions.categories)) {\n    out.categories = {};\n    const categories = permissions.categories as Record<string, unknown>;\n    if (categories.filesystem === \"full\" || categories.filesystem === \"read\" || categories.filesystem === \"none\") {\n      out.categories.filesystem = categories.filesystem;\n    } else if (categories.filesystem !== undefined) {\n      errors.push({ field: \"permissions.categories.filesystem\", message: \"Invalid filesystem category.\" });\n    }\n    if (categories.execution === \"full\" || categories.execution === \"sandboxed\" || categories.execution === \"none\") {\n      out.categories.execution = categories.execution;\n    } else if (categories.execution !== undefined) {\n      errors.push({ field: \"permissions.categories.execution\", message: \"Invalid execution category.\" });\n    }\n    if (categories.network === \"full\" || categories.network === \"localhost\" || categories.network === \"none\") {\n      out.categories.network = categories.network;\n    } else if (categories.network !== undefined) {\n      errors.push({ field: \"permissions.categories.network\", message: \"Invalid network category.\" });\n    }\n  } else if (permissions.categories !== undefined) {\n    errors.push({ field: \"permissions.categories\", message: \"Permissions categories must be an object.\" });\n  }\n\n  if (isPlainObject(permissions.tools)) {\n    out.tools = {};\n    for (const [toolId, cfg] of Object.entries(permissions.tools as Record<string, unknown>)) {\n      if (!isPlainObject(cfg) || typeof cfg.enabled !== \"boolean\") {\n        errors.push({ field: `permissions.tools.${toolId}`, message: \"Tool permission must include enabled boolean.\" });\n        continue;\n      }\n      out.tools[toolId] = {\n        enabled: cfg.enabled,\n        constraints: isPlainObject(cfg.constraints) ? (cfg.constraints as Record<string, unknown>) : undefined,\n      };\n    }\n  } else if (permissions.tools !== undefined) {\n    errors.push({ field: \"permissions.tools\", message: \"Permissions tools must be an object.\" });\n  }\n\n  if (isPlainObject(permissions.paths)) {\n    const paths = permissions.paths as Record<string, unknown>;\n    const allowed = paths.allowed;\n    const denied = paths.denied;\n    if ((allowed !== undefined && !isStringArray(allowed)) || (denied !== undefined && !isStringArray(denied))) {\n      errors.push({ field: \"permissions.paths\", message: \"Permissions paths must be string arrays.\" });\n    } else if (allowed || denied) {\n      out.paths = { allowed: allowed as string[] | undefined, denied: denied as string[] | undefined };\n    }\n  } else if (permissions.paths !== undefined) {\n    errors.push({ field: \"permissions.paths\", message: \"Permissions paths must be an object.\" });\n  }\n\n  return out;\n}\n\nexport function validateSkillFrontmatter(frontmatter: SkillFrontmatter): SkillValidationResult {\n  const errors: SkillValidationError[] = [];\n\n  if (!frontmatter.name || typeof frontmatter.name !== \"string\") {\n    errors.push({ field: \"name\", message: \"Name is required.\" });\n  } else {\n    if (!NAME_PATTERN.test(frontmatter.name)) {\n      errors.push({ field: \"name\", message: \"Name must be lowercase alphanumeric with single hyphens.\" });\n    }\n    if (frontmatter.name.length < 1 || frontmatter.name.length > 64) {\n      errors.push({ field: \"name\", message: \"Name must be 1-64 characters.\" });\n    }\n  }\n\n  if (!frontmatter.description || typeof frontmatter.description !== \"string\") {\n    errors.push({ field: \"description\", message: \"Description is required.\" });\n  } else if (frontmatter.description.length < 1 || frontmatter.description.length > 1024) {\n    errors.push({ field: \"description\", message: \"Description must be 1-1024 characters.\" });\n  }\n\n  if (!frontmatter.model || typeof frontmatter.model !== \"string\") {\n    errors.push({ field: \"model\", message: \"Model is required.\" });\n  }\n\n  if (frontmatter.temperature !== undefined) {\n    if (typeof frontmatter.temperature !== \"number\" || frontmatter.temperature < 0 || frontmatter.temperature > 2) {\n      errors.push({ field: \"temperature\", message: \"Temperature must be a number between 0 and 2.\" });\n    }\n  }\n\n  if (frontmatter.tools !== undefined && !isBooleanRecord(frontmatter.tools)) {\n    errors.push({ field: \"tools\", message: \"Tools must be a record of booleans.\" });\n  }\n\n  if (frontmatter.tags !== undefined && !isStringArray(frontmatter.tags)) {\n    errors.push({ field: \"tags\", message: \"Tags must be an array of strings.\" });\n  }\n\n  if (frontmatter.supportsVision !== undefined && typeof frontmatter.supportsVision !== \"boolean\") {\n    errors.push({ field: \"supportsVision\", message: \"supportsVision must be boolean.\" });\n  }\n\n  if (frontmatter.supportsWeb !== undefined && typeof frontmatter.supportsWeb !== \"boolean\") {\n    errors.push({ field: \"supportsWeb\", message: \"supportsWeb must be boolean.\" });\n  }\n\n  if (frontmatter.injectRepoContext !== undefined && typeof frontmatter.injectRepoContext !== \"boolean\") {\n    errors.push({ field: \"injectRepoContext\", message: \"injectRepoContext must be boolean.\" });\n  }\n\n  if (frontmatter.extends !== undefined && typeof frontmatter.extends !== \"string\") {\n    errors.push({ field: \"extends\", message: \"extends must be a string.\" });\n  }\n\n  if (frontmatter.compose !== undefined && !isStringArray(frontmatter.compose)) {\n    errors.push({ field: \"compose\", message: \"compose must be an array of strings.\" });\n  }\n\n  validatePermissions(frontmatter.permissions, errors);\n\n  return { valid: errors.length === 0, errors };\n}\n\nexport function validateSkillInput(input: SkillInput): SkillValidationResult {\n  const errors: SkillValidationError[] = [];\n\n  if (!input.id || typeof input.id !== \"string\") {\n    errors.push({ field: \"id\", message: \"ID is required.\" });\n  } else {\n    if (!NAME_PATTERN.test(input.id)) {\n      errors.push({ field: \"id\", message: \"ID must be lowercase alphanumeric with single hyphens.\" });\n    }\n    if (input.id.length < 1 || input.id.length > 64) {\n      errors.push({ field: \"id\", message: \"ID must be 1-64 characters.\" });\n    }\n  }\n\n  if (typeof input.systemPrompt !== \"string\") {\n    errors.push({ field: \"systemPrompt\", message: \"System prompt must be a string.\" });\n  }\n\n  const frontmatter = {\n    ...input.frontmatter,\n    name: input.frontmatter.name ?? input.id,\n  } as SkillFrontmatter;\n\n  const frontmatterResult = validateSkillFrontmatter(frontmatter);\n  errors.push(...frontmatterResult.errors);\n\n  return { valid: errors.length === 0, errors };\n}\n"
  },
  {
    "path": "tools/hooks.ts",
    "content": "import { canSpawnManually, canSpawnOnDemand } from \"../core/spawn-policy\";\nimport { buildOrchestratorSystemPrompt } from \"../prompts/orchestrator-system\";\nimport type { OrchestratorConfig } from \"../types\";\nimport type { WorkerManager } from \"../workers\";\n\nexport function createToolGuard(config: OrchestratorConfig) {\n  type ToolArgs = Record<string, unknown>;\n  const readString = (value: unknown): string =>\n    typeof value === \"string\" ? value : value == null ? \"\" : String(value);\n\n  // Get orchestrator agent name for permission checks\n  const orchestratorName = config.agent?.name ?? \"orchestrator\";\n\n  return async (input: { tool: string; agent?: string }, output: { args?: ToolArgs }) => {\n    const args = output.args ?? {};\n    const agentId = input.agent ?? orchestratorName;\n\n    // spawn_worker is only available to the orchestrator agent\n    if (input.tool === \"spawn_worker\") {\n      if (agentId !== orchestratorName) {\n        throw new Error(`Tool \"spawn_worker\" is only available to the orchestrator. Use \"ask_worker\" or \"delegate_task\" instead.`);\n      }\n      const profileId = readString(args.profileId);\n      if (profileId && !canSpawnManually(config.spawnPolicy, profileId))\n        throw new Error(`Spawning worker \"${profileId}\" is disabled by spawnPolicy.`);\n    }\n\n    // Prevent workers from spawning themselves via delegation\n    if (input.tool === \"delegate_task\" || input.tool === \"ask_worker\" || input.tool === \"ask_worker_async\") {\n      const workerId = readString(args.workerId);\n\n      // Prevent self-spawning (worker trying to spawn itself)\n      if (workerId && workerId === agentId) {\n        throw new Error(`Worker \"${agentId}\" cannot delegate to itself. Choose a different worker.`);\n      }\n\n      const autoSpawn = args.autoSpawn !== false;\n      if (autoSpawn && workerId && !canSpawnOnDemand(config.spawnPolicy, workerId))\n        throw new Error(`On-demand spawn for worker \"${workerId}\" is disabled by spawnPolicy.`);\n    }\n\n    // run_workflow is only available to the orchestrator agent\n    if (input.tool === \"run_workflow\") {\n      if (agentId !== orchestratorName) {\n        throw new Error(`Tool \"run_workflow\" is only available to the orchestrator.`);\n      }\n    }\n  };\n}\n\nexport function createSystemTransform(config: OrchestratorConfig, workers: WorkerManager) {\n  return async (_input: Record<string, never>, output: { system: string[] }) => {\n    if (config.ui?.injectSystemContext === false) return;\n\n    // Build comprehensive orchestrator system prompt\n    const runningWorkers = workers.listWorkers().map((w) => ({\n      id: w.profile.id,\n      name: w.profile.name,\n      status: w.status,\n    }));\n\n    const orchestratorPrompt = buildOrchestratorSystemPrompt({\n      config,\n      profiles: workers.listProfiles(),\n      runningWorkers,\n      memoryEnabled: config.memory?.enabled !== false,\n    });\n\n    output.system.push(orchestratorPrompt);\n\n    // Inject pending vision jobs so orchestrator knows to await them\n    const pendingJobs = workers.jobs.list().filter((j) => j.status === \"running\" && j.workerId === \"vision\");\n    if (pendingJobs.length > 0) {\n      output.system.push(\n        `\n<pending-vision-analysis>\nIMPORTANT: Vision analysis is in progress for ${pendingJobs.length} image(s).\nYou MUST call await_worker_job to get the results before responding about the image content:\n${pendingJobs.map((j) => `- await_worker_job({ jobId: \"${j.id}\" })`).join(\"\\n\")}\n</pending-vision-analysis>\n      `.trim(),\n      );\n    }\n  };\n}\n\nexport function createCompactionTransform(config: OrchestratorConfig, workers: WorkerManager) {\n  return async (_input: { sessionID: string }, output: { context: string[]; prompt?: string }) => {\n    if (config.ui?.injectSystemContext === false) return;\n    output.context.push(workers.getSummary({ maxWorkers: config.ui?.systemContextMaxWorkers }));\n  };\n}\n"
  },
  {
    "path": "tools/index.ts",
    "content": "import type { ToolDefinition } from \"@opencode-ai/plugin\";\nimport { getIntegrationTools } from \"../integrations/registry\";\nimport type { OrchestratorService } from \"../orchestrator\";\nimport type { Factory, OrchestratorConfig, ServiceLifecycle } from \"../types\";\nimport type { WorkerManager } from \"../workers\";\nimport type { WorkflowEngine } from \"../workflows/factory\";\nimport { createCompactionTransform, createSystemTransform, createToolGuard } from \"./hooks\";\nimport { createWorkerTools } from \"./worker-tools\";\nimport { createWorkflowTools } from \"./workflow-tools\";\n\nexport type ToolsConfig = OrchestratorConfig;\n\nexport type ToolsDeps = {\n  orchestrator: OrchestratorService;\n  workers: WorkerManager;\n  workflows?: WorkflowEngine;\n};\n\nexport type ToolsService = ServiceLifecycle & {\n  /** All orchestrator tools (full access) */\n  tool: Record<string, ToolDefinition>;\n  /** Worker tools (limited, no orchestration) */\n  workerTool: Record<string, ToolDefinition>;\n  /** Agent tools (workers with skillPermissions: \"inherit\" can delegate to other workers) */\n  agentTool: Record<string, ToolDefinition>;\n  guard: ReturnType<typeof createToolGuard>;\n  systemTransform: ReturnType<typeof createSystemTransform>;\n  compaction: ReturnType<typeof createCompactionTransform>;\n};\n\nexport const createTools: Factory<ToolsConfig, ToolsDeps, ToolsService> = ({ config, deps }) => {\n  const workerTools = createWorkerTools({ orchestrator: deps.orchestrator, workers: deps.workers });\n  const workflowTools = createWorkflowTools({ orchestrator: deps.orchestrator, workflows: deps.workflows });\n  const integrationTools = getIntegrationTools(config.integrations);\n\n  // Orchestrator gets all tools (including Linear write tools)\n  const tool = {\n    ...workerTools,\n    ...workflowTools,\n    ...integrationTools.orchestrator,\n  };\n\n  // Workers get limited tools (Linear read only)\n  const workerTool = {\n    ...integrationTools.workers,\n  };\n\n  // Agent tools - for workers with skillPermissions: \"inherit\"\n  // These can delegate to other workers but don't have full orchestrator access\n  const agentTool = {\n    ask_worker: workerTools.ask_worker,\n    ask_worker_async: workerTools.ask_worker_async,\n    await_worker_job: workerTools.await_worker_job,\n    delegate_task: workerTools.delegate_task,\n    list_workers: workerTools.list_workers,\n    list_profiles: workerTools.list_profiles,\n    ...integrationTools.workers,\n  };\n\n  return {\n    tool,\n    workerTool,\n    agentTool,\n    guard: createToolGuard(config),\n    systemTransform: createSystemTransform(config, deps.workers),\n    compaction: createCompactionTransform(config, deps.workers),\n    start: async () => {},\n    stop: async () => {},\n    health: async () => ({ ok: true }),\n  };\n};\n"
  },
  {
    "path": "tools/linear-tools.ts",
    "content": "import { tool } from \"@opencode-ai/plugin\";\nimport {\n  addComment,\n  addLabel,\n  createIssue,\n  getIssue,\n  type LinearConfig,\n  resolveLinearConfig,\n  setEstimate,\n  syncTaskStatus,\n  updateIssue,\n} from \"../integrations/linear\";\nimport type { LinearIntegrationConfig } from \"../types\";\n\ntype ToolDefinition = ReturnType<typeof tool>;\n\nfunction serialize(value: unknown): string {\n  return JSON.stringify(value, null, 2);\n}\n\nexport type LinearToolsDeps = {\n  config?: LinearIntegrationConfig;\n  api?: {\n    resolveConfig?: typeof resolveLinearConfig;\n    createIssue?: typeof createIssue;\n    updateIssue?: typeof updateIssue;\n    addComment?: typeof addComment;\n    addLabel?: typeof addLabel;\n    setEstimate?: typeof setEstimate;\n    syncTaskStatus?: typeof syncTaskStatus;\n    getIssue?: typeof getIssue;\n  };\n};\n\n/** Create Linear tools for orchestrator (write) and workers (read). */\nexport function createLinearTools(deps: LinearToolsDeps): {\n  orchestrator: Record<string, ToolDefinition>;\n  workers: Record<string, ToolDefinition>;\n} {\n  const api = deps.api ?? {};\n  let cfg: LinearConfig | undefined;\n  const getConfig = (): LinearConfig => {\n    if (!cfg) cfg = (api.resolveConfig ?? resolveLinearConfig)(deps.config);\n    return cfg;\n  };\n\n  // === WRITE TOOLS (orchestrator only) ===\n\n  const linearCreateIssue = tool({\n    description: \"Create a new issue in Linear\",\n    args: {\n      title: tool.schema.string().describe(\"Issue title\"),\n      description: tool.schema.string().optional().describe(\"Issue description (markdown)\"),\n      priority: tool.schema.number().optional().describe(\"Priority (0=none, 1=urgent, 2=high, 3=medium, 4=low)\"),\n      estimate: tool.schema.number().optional().describe(\"Estimate points\"),\n    },\n    async execute(args) {\n      const issue = await (api.createIssue ?? createIssue)({\n        cfg: getConfig(),\n        title: args.title,\n        description: args.description,\n        priority: args.priority,\n        estimate: args.estimate,\n      });\n      return serialize({\n        id: issue.issueId,\n        identifier: issue.identifier,\n        title: args.title,\n        url: issue.url,\n      });\n    },\n  });\n\n  const linearUpdateIssue = tool({\n    description: \"Update an existing Linear issue\",\n    args: {\n      issueId: tool.schema.string().describe(\"Issue ID\"),\n      title: tool.schema.string().optional().describe(\"New title\"),\n      description: tool.schema.string().optional().describe(\"New description\"),\n      priority: tool.schema.number().optional().describe(\"New priority\"),\n    },\n    async execute(args) {\n      const issue = await (api.updateIssue ?? updateIssue)({\n        cfg: getConfig(),\n        issueId: args.issueId,\n        title: args.title,\n        description: args.description,\n        priority: args.priority,\n      });\n      return serialize({ id: issue.issueId, title: issue.title ?? args.title, url: issue.url });\n    },\n  });\n\n  const linearAddComment = tool({\n    description: \"Add a comment to a Linear issue\",\n    args: {\n      issueId: tool.schema.string().describe(\"Issue ID\"),\n      body: tool.schema.string().describe(\"Comment body (markdown)\"),\n    },\n    async execute(args) {\n      const comment = await (api.addComment ?? addComment)({\n        cfg: getConfig(),\n        issueId: args.issueId,\n        body: args.body,\n      });\n      return serialize({ id: comment.commentId, issueId: args.issueId, url: comment.url });\n    },\n  });\n\n  const linearAddLabel = tool({\n    description: \"Add a label to a Linear issue\",\n    args: {\n      issueId: tool.schema.string().describe(\"Issue ID\"),\n      labelId: tool.schema.string().describe(\"Label ID to add\"),\n    },\n    async execute(args) {\n      const issue = await (api.addLabel ?? addLabel)({\n        cfg: getConfig(),\n        issueId: args.issueId,\n        labelId: args.labelId,\n      });\n      return serialize({ id: issue.issueId, labelIds: issue.labelIds });\n    },\n  });\n\n  const linearSetEstimate = tool({\n    description: \"Set estimate points on a Linear issue\",\n    args: {\n      issueId: tool.schema.string().describe(\"Issue ID\"),\n      estimate: tool.schema.number().describe(\"Estimate points\"),\n    },\n    async execute(args) {\n      const issue = await (api.setEstimate ?? setEstimate)({\n        cfg: getConfig(),\n        issueId: args.issueId,\n        estimate: args.estimate,\n      });\n      return serialize({ id: issue.issueId, estimate: issue.estimate });\n    },\n  });\n\n  const linearSyncStatus = tool({\n    description: \"Sync a task status to Linear (maps status labels to workflow states)\",\n    args: {\n      issueId: tool.schema.string().describe(\"Issue ID\"),\n      status: tool.schema\n        .string()\n        .describe(\"Status label (e.g., 'todo', 'in_progress', 'in-progress', 'done', 'canceled')\"),\n    },\n    async execute(args) {\n      const issue = await (api.syncTaskStatus ?? syncTaskStatus)({\n        cfg: getConfig(),\n        issueId: args.issueId,\n        status: args.status,\n      });\n      return serialize({ id: issue.issueId, stateId: issue.stateId, status: args.status });\n    },\n  });\n\n  // === READ/UPDATE TOOLS (available to all workers) ===\n\n  const linearGetConfig = tool({\n    description: \"Check if Linear is configured and get team info\",\n    args: {},\n    async execute() {\n      try {\n        const config = getConfig();\n        return serialize({ configured: true, teamId: config.teamId, apiUrl: config.apiUrl });\n      } catch {\n        return serialize({ configured: false, error: \"Linear not configured\" });\n      }\n    },\n  });\n\n  const linearGetIssue = tool({\n    description: \"Get details of a Linear issue by ID\",\n    args: {\n      issueId: tool.schema.string().describe(\"Issue ID or identifier (e.g., 'ABC-123')\"),\n    },\n    async execute(args) {\n      const issue = await (api.getIssue ?? getIssue)({ cfg: getConfig(), issueId: args.issueId });\n      return serialize(issue);\n    },\n  });\n\n  // Shared tools that workers can also use\n  const sharedTools = {\n    linear_get_config: linearGetConfig,\n    linear_get_issue: linearGetIssue,\n    linear_update_issue: linearUpdateIssue,\n    linear_add_comment: linearAddComment,\n    linear_add_label: linearAddLabel,\n    linear_set_estimate: linearSetEstimate,\n    linear_sync_status: linearSyncStatus,\n  };\n\n  return {\n    // Orchestrator gets create (+ all shared tools)\n    orchestrator: {\n      linear_create_issue: linearCreateIssue,\n      ...sharedTools,\n    },\n    // Workers get read + update tools (no create/delete)\n    workers: sharedTools,\n  };\n}\n"
  },
  {
    "path": "tools/worker-tools.ts",
    "content": "import { tool } from \"@opencode-ai/plugin\";\nimport type { OrchestratorService } from \"../orchestrator\";\nimport type { WorkerManager } from \"../workers\";\nimport type { WorkerAttachment } from \"../workers/prompt\";\n\nexport type WorkerToolsDeps = {\n  orchestrator: OrchestratorService;\n  workers: WorkerManager;\n};\n\ntype ToolDefinition = ReturnType<typeof tool>;\n\nfunction attachmentSchema() {\n  return tool.schema.object({\n    type: tool.schema.enum([\"image\", \"file\"]),\n    path: tool.schema.string().optional(),\n    base64: tool.schema.string().optional(),\n    mimeType: tool.schema.string().optional(),\n  });\n}\n\nfunction serialize(value: unknown): string {\n  return JSON.stringify(value, null, 2);\n}\n\nexport function createWorkerTools(deps: WorkerToolsDeps): Record<string, ToolDefinition> {\n  const spawnWorker = tool({\n    description: \"Spawn a worker by profile ID\",\n    args: {\n      profileId: tool.schema.string().describe(\"Worker profile ID\"),\n    },\n    async execute(args, ctx) {\n      const worker = await deps.orchestrator.ensureWorker({\n        workerId: args.profileId,\n        reason: \"manual\",\n        parentSessionId: ctx?.sessionID,\n      });\n      return serialize({\n        id: worker.profile.id,\n        status: worker.status,\n        port: worker.port,\n        model: worker.profile.model,\n      });\n    },\n  });\n\n  const stopWorker = tool({\n    description: \"Stop a running worker\",\n    args: {\n      workerId: tool.schema.string().describe(\"Worker ID\"),\n    },\n    async execute(args) {\n      const ok = await deps.workers.stopWorker(args.workerId);\n      return ok ? `Stopped ${args.workerId}.` : `Worker \"${args.workerId}\" not found.`;\n    },\n  });\n\n  const listWorkers = tool({\n    description: \"List running workers\",\n    args: {},\n    async execute() {\n      return serialize(\n        deps.workers.listWorkers().map((w) => ({\n          id: w.profile.id,\n          name: w.profile.name,\n          model: w.profile.model,\n          status: w.status,\n          port: w.port,\n          serverUrl: w.serverUrl,\n        })),\n      );\n    },\n  });\n\n  const listProfiles = tool({\n    description: \"List available worker profiles\",\n    args: {},\n    async execute() {\n      return serialize(\n        deps.workers.listProfiles().map((p) => ({\n          id: p.id,\n          name: p.name,\n          model: p.model,\n          purpose: p.purpose,\n          whenToUse: p.whenToUse,\n          supportsVision: Boolean(p.supportsVision),\n          supportsWeb: Boolean(p.supportsWeb),\n        })),\n      );\n    },\n  });\n\n  const askWorker = tool({\n    description: \"Send a message to a worker and wait for the response\",\n    args: {\n      workerId: tool.schema.string().describe(\"Worker ID\"),\n      message: tool.schema.string().describe(\"Message to send\"),\n      attachments: tool.schema.array(attachmentSchema()).optional(),\n      autoSpawn: tool.schema.boolean().optional().describe(\"Auto-spawn missing workers (default: true)\"),\n    },\n    async execute(args, ctx) {\n      if (args.autoSpawn !== false) {\n        await deps.orchestrator.ensureWorker({\n          workerId: args.workerId,\n          reason: \"on-demand\",\n          parentSessionId: ctx?.sessionID,\n        });\n      }\n      const res = await deps.workers.send(args.workerId, args.message, {\n        attachments: args.attachments as WorkerAttachment[] | undefined,\n        sessionId: ctx?.sessionID,\n      });\n      if (!res.success) return res.error ?? \"Worker request failed\";\n      return res.response ?? \"\";\n    },\n  });\n\n  const askWorkerAsync = tool({\n    description: \"Send a message to a worker asynchronously and return a job ID\",\n    args: {\n      workerId: tool.schema.string().describe(\"Worker ID\"),\n      message: tool.schema.string().describe(\"Message to send\"),\n      attachments: tool.schema.array(attachmentSchema()).optional(),\n      autoSpawn: tool.schema.boolean().optional().describe(\"Auto-spawn missing workers (default: true)\"),\n    },\n    async execute(args, ctx) {\n      if (args.autoSpawn !== false) {\n        await deps.orchestrator.ensureWorker({\n          workerId: args.workerId,\n          reason: \"on-demand\",\n          parentSessionId: ctx?.sessionID,\n        });\n      }\n      const job = deps.workers.jobs.create({\n        workerId: args.workerId,\n        message: args.message,\n        sessionId: ctx?.sessionID,\n        requestedBy: ctx?.agent,\n      });\n\n      void (async () => {\n        const res = await deps.workers.send(args.workerId, args.message, {\n          attachments: args.attachments as WorkerAttachment[] | undefined,\n          jobId: job.id,\n          from: ctx?.agent,\n          sessionId: ctx?.sessionID,\n        });\n        if (!res.success) {\n          deps.workers.jobs.setResult(job.id, { error: res.error ?? \"worker failed\" });\n          return;\n        }\n        deps.workers.jobs.setResult(job.id, { responseText: res.response ?? \"\" });\n      })();\n\n      return serialize({ jobId: job.id, workerId: args.workerId });\n    },\n  });\n\n  const awaitWorkerJob = tool({\n    description: \"Wait for an async job result\",\n    args: {\n      jobId: tool.schema.string().describe(\"Job ID\"),\n      timeoutMs: tool.schema.number().optional().describe(\"Timeout in ms\"),\n    },\n    async execute(args) {\n      const job = await deps.workers.jobs.await(args.jobId, { timeoutMs: args.timeoutMs });\n      return serialize(job);\n    },\n  });\n\n  const delegateTask = tool({\n    description: \"Route a task to the best worker and return the response\",\n    args: {\n      task: tool.schema.string().describe(\"Task to delegate\"),\n      attachments: tool.schema.array(attachmentSchema()).optional(),\n      autoSpawn: tool.schema.boolean().optional().describe(\"Auto-spawn missing workers (default: true)\"),\n    },\n    async execute(args, ctx) {\n      const res = await deps.orchestrator.delegateTask({\n        task: args.task,\n        attachments: args.attachments as WorkerAttachment[] | undefined,\n        autoSpawn: args.autoSpawn,\n        parentSessionId: ctx?.sessionID,\n      });\n      return res.response;\n    },\n  });\n\n  return {\n    spawn_worker: spawnWorker,\n    stop_worker: stopWorker,\n    list_workers: listWorkers,\n    list_profiles: listProfiles,\n    ask_worker: askWorker,\n    ask_worker_async: askWorkerAsync,\n    await_worker_job: awaitWorkerJob,\n    delegate_task: delegateTask,\n  } as const;\n}\n"
  },
  {
    "path": "tools/workflow-tools.ts",
    "content": "import { tool } from \"@opencode-ai/plugin\";\nimport type { OrchestratorService } from \"../orchestrator\";\nimport type { WorkerAttachment } from \"../workers/prompt\";\nimport type { WorkflowEngine } from \"../workflows/factory\";\n\nexport type WorkflowToolsDeps = {\n  orchestrator: OrchestratorService;\n  workflows?: WorkflowEngine;\n};\n\ntype ToolDefinition = ReturnType<typeof tool>;\n\nfunction serialize(value: unknown): string {\n  return JSON.stringify(value, null, 2);\n}\n\nfunction attachmentSchema() {\n  return tool.schema.object({\n    type: tool.schema.enum([\"image\", \"file\"]),\n    path: tool.schema.string().optional(),\n    base64: tool.schema.string().optional(),\n    mimeType: tool.schema.string().optional(),\n  });\n}\n\nexport function createWorkflowTools(deps: WorkflowToolsDeps): Record<string, ToolDefinition> {\n  if (!deps.workflows) return {};\n\n  const listWorkflows = tool({\n    description: \"List available workflows\",\n    args: {},\n    async execute() {\n      return serialize(deps.workflows?.list() ?? []);\n    },\n  });\n\n  const runWorkflow = tool({\n    description: \"Run a workflow by id\",\n    args: {\n      workflowId: tool.schema.string().describe(\"Workflow ID\"),\n      task: tool.schema.string().describe(\"Task to run\"),\n      attachments: tool.schema.array(attachmentSchema()).optional(),\n      autoSpawn: tool.schema.boolean().optional(),\n    },\n    async execute(args) {\n      const res = await deps.orchestrator.runWorkflow({\n        workflowId: args.workflowId,\n        task: args.task,\n        attachments: args.attachments as WorkerAttachment[] | undefined,\n        autoSpawn: args.autoSpawn,\n      });\n      return serialize(res);\n    },\n  });\n\n  return {\n    list_workflows: listWorkflows,\n    run_workflow: runWorkflow,\n  } as const;\n}\n"
  },
  {
    "path": "types/config.ts",
    "content": "import type { IntegrationsConfig, TelemetryConfig } from \"./integrations\";\nimport type { MemoryConfig } from \"./memory\";\nimport type { WorkerProfile } from \"./worker\";\nimport type { SecurityConfig, WorkflowsConfig } from \"./workflow\";\n\nexport type SpawnPolicy = {\n  /** Allow auto-spawn at orchestrator startup */\n  autoSpawn?: boolean;\n  /** Allow on-demand spawns (vision routing, delegate_task, etc.) */\n  onDemand?: boolean;\n  /** Allow manual spawns via tools */\n  allowManual?: boolean;\n  /** Allow warm pool pre-spawns */\n  warmPool?: boolean;\n  /** Deprecated: device registry reuse was removed; this flag is ignored. */\n  reuseExisting?: boolean;\n};\n\nexport type SpawnPolicyConfig = {\n  /** Default policy applied to any profile without an override */\n  default?: SpawnPolicy;\n  /** Per-profile policy overrides */\n  profiles?: Record<string, SpawnPolicy>;\n};\n\nexport interface OrchestratorConfig {\n  /** Base port to start assigning from */\n  basePort: number;\n  /** Available worker profiles (built-ins + overrides + custom) */\n  profiles: Record<string, WorkerProfile>;\n  /** Profile IDs to auto-spawn on startup */\n  spawn: string[];\n  /** Auto-spawn workers on plugin init */\n  autoSpawn: boolean;\n  /** Worker IDs allowed to auto-spawn on demand */\n  spawnOnDemand?: string[];\n  /** Per-profile spawn policy overrides */\n  spawnPolicy?: SpawnPolicyConfig;\n  /** Timeout for worker startup (ms) */\n  startupTimeout: number;\n  /** Health check interval (ms) */\n  healthCheckInterval: number;\n  /** Health check settings */\n  healthCheck?: {\n    enabled?: boolean;\n    intervalMs?: number;\n    timeoutMs?: number;\n    maxRetries?: number;\n  };\n  /** Warm pool pre-spawn settings */\n  warmPool?: {\n    enabled?: boolean;\n    profiles?: Record<string, { size?: number; idleTimeoutMs?: number }>;\n  };\n  /** Model selection preferences */\n  modelSelection?: {\n    mode?: \"performance\" | \"balanced\" | \"economical\";\n    maxCostPer1kTokens?: number;\n    preferredProviders?: string[];\n  };\n  /** Model alias table */\n  modelAliases?: Record<string, string>;\n  /** UX and prompt injection settings */\n  ui?: {\n    /** Show OpenCode toasts for orchestrator events */\n    toasts?: boolean;\n    /** Inject available workers into system prompt */\n    injectSystemContext?: boolean;\n    /** Maximum workers to include in system context */\n    systemContextMaxWorkers?: number;\n    /** Default tool output format */\n    defaultListFormat?: \"markdown\" | \"json\";\n    /** Enable debug logging for orchestrator internals */\n    debug?: boolean;\n    /** Allow logs to print to console (default: false) */\n    logToConsole?: boolean;\n    /**\n     * First-run demo behavior (no config file detected):\n     * - true: auto-run `orchestrator.demo` once per machine/user\n     * - false: only show a toast tip\n     */\n    firstRunDemo?: boolean;\n    /**\n     * Inject a prompt into the orchestrator session when workers send wakeups.\n     * This allows async workers to actually \"wake up\" the orchestrator instead of\n     * just storing events to poll.\n     * Default: true\n     */\n    wakeupInjection?: boolean;\n  };\n  /** Optional idle notifications */\n  notifications?: {\n    idle?: {\n      enabled?: boolean;\n      title?: string;\n      message?: string;\n      delayMs?: number;\n    };\n  };\n  /** Inject an orchestrator agent definition into OpenCode config */\n  agent?: {\n    enabled?: boolean;\n    name?: string;\n    model?: string;\n    prompt?: string;\n    mode?: \"primary\" | \"subagent\";\n    color?: string;\n    /** If true, also override the built-in `build` agent model */\n    applyToBuild?: boolean;\n  };\n  /** Inject command shortcuts into OpenCode config */\n  commands?: {\n    enabled?: boolean;\n    /** Prefix for generated command names (default: \"orchestrator.\") */\n    prefix?: string;\n  };\n  /** Context pruning settings (DCP-inspired) */\n  pruning?: {\n    enabled?: boolean;\n    /** Max chars to keep for completed tool outputs */\n    maxToolOutputChars?: number;\n    /** Max chars to keep for tool inputs (write/edit) */\n    maxToolInputChars?: number;\n    /** Tools that should never be pruned */\n    protectedTools?: string[];\n  };\n  /** Workflow configuration */\n  workflows?: WorkflowsConfig;\n  /** Security limits */\n  security?: SecurityConfig;\n  /** Memory graph settings */\n  memory?: MemoryConfig;\n  /** External integration settings */\n  integrations?: IntegrationsConfig;\n  /** Telemetry settings (PostHog) */\n  telemetry?: TelemetryConfig;\n}\n\nexport type OrchestratorConfigFile = {\n  $schema?: string;\n  basePort?: number;\n  autoSpawn?: boolean;\n  spawnOnDemand?: string[];\n  spawnPolicy?: SpawnPolicyConfig;\n  startupTimeout?: number;\n  healthCheckInterval?: number;\n  healthCheck?: OrchestratorConfig[\"healthCheck\"];\n  warmPool?: OrchestratorConfig[\"warmPool\"];\n  modelSelection?: OrchestratorConfig[\"modelSelection\"];\n  modelAliases?: OrchestratorConfig[\"modelAliases\"];\n  ui?: OrchestratorConfig[\"ui\"];\n  notifications?: OrchestratorConfig[\"notifications\"];\n  agent?: OrchestratorConfig[\"agent\"];\n  commands?: OrchestratorConfig[\"commands\"];\n  pruning?: OrchestratorConfig[\"pruning\"];\n  workflows?: OrchestratorConfig[\"workflows\"];\n  security?: OrchestratorConfig[\"security\"];\n  memory?: OrchestratorConfig[\"memory\"];\n  integrations?: OrchestratorConfig[\"integrations\"];\n  telemetry?: OrchestratorConfig[\"telemetry\"];\n  /** Profiles available to spawn (overrides/custom). Strings reference built-ins. */\n  profiles?: Array<string | WorkerProfile>;\n  /** Profiles to auto-spawn. Strings reference profiles by id. */\n  workers?: Array<string | WorkerProfile>;\n};\n"
  },
  {
    "path": "types/events.ts",
    "content": "import type { WorkerInstance, WorkerResponse } from \"./worker\";\n\n/** Payload sent by workers to wake up the orchestrator */\nexport interface WakeupPayload {\n  /** Worker ID that triggered the wakeup */\n  workerId: string;\n  /** Optional job ID if related to an async job */\n  jobId?: string;\n  /** Reason for the wakeup */\n  reason: \"result_ready\" | \"needs_attention\" | \"error\" | \"progress\" | \"custom\";\n  /** Optional summary or message */\n  summary?: string;\n  /** Optional structured data */\n  data?: Record<string, unknown>;\n  /** Timestamp when the wakeup was triggered */\n  timestamp: number;\n}\n\nexport interface OrchestratorEvents {\n  \"worker:spawned\": { worker: WorkerInstance };\n  \"worker:ready\": { worker: WorkerInstance };\n  \"worker:busy\": { worker: WorkerInstance };\n  \"worker:error\": { worker: WorkerInstance; error: string };\n  \"worker:dead\": { worker: WorkerInstance };\n  \"worker:stopped\": { worker: WorkerInstance };\n  \"worker:response\": { worker: WorkerInstance; response: WorkerResponse };\n  \"worker:wakeup\": { payload: WakeupPayload };\n  \"registry:updated\": { registry: { workers: Map<string, WorkerInstance> } };\n}\n"
  },
  {
    "path": "types/factory.ts",
    "content": "export type HealthResult = {\n  ok: boolean;\n  info?: unknown;\n};\n\nexport type ServiceLifecycle = {\n  start(): Promise<void>;\n  stop(): Promise<void>;\n  health(): Promise<HealthResult>;\n};\n\nexport type Factory<TConfig, TDeps, TService> = (input: { config: TConfig; deps: TDeps }) => TService;\n"
  },
  {
    "path": "types/index.ts",
    "content": "export * from \"./config\";\nexport * from \"./events\";\nexport * from \"./factory\";\nexport * from \"./integrations\";\nexport * from \"./memory\";\nexport * from \"./permissions\";\nexport * from \"./skill\";\nexport * from \"./worker\";\nexport * from \"./workflow\";\n"
  },
  {
    "path": "types/integrations.ts",
    "content": "export type TelemetryConfig = {\n  enabled?: boolean;\n  /** PostHog API key (or set POSTHOG_API_KEY env var) */\n  apiKey?: string;\n  /** PostHog host (default: https://us.i.posthog.com) */\n  host?: string;\n};\n\nexport type LinearIntegrationConfig = {\n  enabled?: boolean;\n  apiKey?: string;\n  teamId?: string;\n  apiUrl?: string;\n  projectPrefix?: string;\n};\n\nexport type Neo4jIntegrationConfig = {\n  enabled?: boolean;\n  uri?: string;\n  username?: string;\n  password?: string;\n  database?: string;\n  /** Auto-start Neo4j Docker container if not running (default: true) */\n  autoStart?: boolean;\n  /** Docker image to use (default: neo4j:community) */\n  image?: string;\n};\n\nexport type MonitoringIntegrationConfig = {\n  enabled?: boolean;\n  port?: number;\n  metricsPath?: string;\n};\n\nexport type IntegrationsConfig = {\n  linear?: LinearIntegrationConfig;\n  neo4j?: Neo4jIntegrationConfig;\n  monitoring?: MonitoringIntegrationConfig;\n  [key: string]: unknown;\n};\n"
  },
  {
    "path": "types/memory.ts",
    "content": "export type MemoryConfig = {\n  enabled?: boolean;\n  autoSpawn?: boolean;\n  autoRecord?: boolean;\n  /** Inject memory into the system prompt for each message */\n  autoInject?: boolean;\n  scope?: \"project\" | \"global\";\n  /** Max characters stored per raw message snippet */\n  maxChars?: number;\n  /** Rolling summaries (session/project) */\n  summaries?: {\n    enabled?: boolean;\n    sessionMaxChars?: number;\n    projectMaxChars?: number;\n  };\n  /** Automatic trimming of stored message nodes */\n  trim?: {\n    maxMessagesPerSession?: number;\n    maxMessagesPerProject?: number;\n    maxMessagesGlobal?: number;\n    maxProjectsGlobal?: number;\n  };\n  /** Memory injection limits */\n  inject?: {\n    maxChars?: number;\n    maxEntries?: number;\n    includeMessages?: boolean;\n    includeSessionSummary?: boolean;\n    includeProjectSummary?: boolean;\n    includeGlobal?: boolean;\n    maxGlobalEntries?: number;\n  };\n};\n"
  },
  {
    "path": "types/permissions.ts",
    "content": "export type ToolPermissions = {\n  categories?: {\n    filesystem?: \"full\" | \"read\" | \"none\";\n    execution?: \"full\" | \"sandboxed\" | \"none\";\n    network?: \"full\" | \"localhost\" | \"none\";\n  };\n  tools?: {\n    [toolName: string]: {\n      enabled: boolean;\n      constraints?: Record<string, unknown>;\n    };\n  };\n  paths?: {\n    allowed?: string[];\n    denied?: string[];\n  };\n};\n\n/**\n * Skill permission value for OpenCode's permission.skill config.\n * - \"allow\": Skill loads immediately\n * - \"deny\": Skill hidden from agent, access rejected\n * - \"ask\": User prompted for approval before loading\n */\nexport type SkillPermissionValue = \"allow\" | \"deny\" | \"ask\";\n\n/**\n * Skill permissions map using glob patterns.\n * Supports wildcards like \"internal-*\" to match multiple skills.\n *\n * @example\n * {\n *   \"memory\": \"allow\",      // Allow memory skill\n *   \"coder\": \"deny\",        // Deny coder skill\n *   \"*\": \"deny\"             // Deny all others by default\n * }\n */\nexport type SkillPermissions = Record<string, SkillPermissionValue>;\n"
  },
  {
    "path": "types/skill.ts",
    "content": "/**\n * Skill type definitions following the Agent Skills Standard\n * with OpenCode extensions for profile configuration.\n *\n * @see https://agentskills.io\n * @see https://opencode.ai/docs/skills/\n */\n\nimport type { SkillPermissions, ToolPermissions } from \"./permissions\";\nimport type { WorkerForwardEvent, WorkerMcpConfig, WorkerSessionMode } from \"./worker\";\n\n// ============================================================================\n// Standard Agent Skills Frontmatter (per specification)\n// ============================================================================\n\n/**\n * Standard Agent Skills frontmatter fields.\n * These fields are defined by the Agent Skills specification.\n */\nexport interface SkillFrontmatterBase {\n  /**\n   * Unique identifier for the skill.\n   * Must be lowercase alphanumeric with single hyphens.\n   * Pattern: ^[a-z0-9]+(-[a-z0-9]+)*$\n   * Length: 1-64 characters\n   * Must match the containing directory name.\n   */\n  name: string;\n\n  /**\n   * Description of what the skill does and when to use it.\n   * This is the primary mechanism for skill selection.\n   * Length: 1-1024 characters\n   */\n  description: string;\n\n  /**\n   * License for the skill (e.g., \"MIT\", \"Apache-2.0\").\n   * Optional standard field.\n   */\n  license?: string;\n\n  /**\n   * Custom metadata key-value pairs.\n   * Optional standard field.\n   */\n  metadata?: Record<string, unknown>;\n}\n\n// ============================================================================\n// OpenCode Profile Extensions\n// ============================================================================\n\nexport type IntegrationSelection = {\n  inheritAll?: boolean;\n  include?: string[];\n  exclude?: string[];\n};\n\n/**\n * OpenCode-specific extensions for profile configuration.\n * These fields extend the standard with model/tool configuration.\n */\nexport interface ProfileExtensions {\n  /**\n   * Model specification for this profile.\n   * Can be a node tag (node:fast, node:code, node:reasoning, node:vision, node:docs)\n   * or a specific provider/model identifier.\n   */\n  model: string;\n\n  /**\n   * Provider ID for model resolution.\n   */\n  providerID?: string;\n\n  /**\n   * Model temperature setting (0-2).\n   * Lower = more focused/deterministic, Higher = more creative.\n   */\n  temperature?: number;\n\n  /**\n   * Tool enable/disable configuration.\n   * Keys are tool names, values are whether the tool is enabled.\n   */\n  tools?: Record<string, boolean>;\n\n  /**\n   * Permission constraints for this profile.\n   */\n  permissions?: ToolPermissions;\n\n  /**\n   * Keywords/tags for matching and categorization.\n   */\n  tags?: string[];\n\n  /**\n   * Whether this profile supports vision/image input.\n   */\n  supportsVision?: boolean;\n\n  /**\n   * Whether this profile has web access.\n   */\n  supportsWeb?: boolean;\n\n  /**\n   * Whether to inject repository context on auto-launch.\n   */\n  injectRepoContext?: boolean;\n\n  /**\n   * Extend another profile by ID (single inheritance).\n   */\n  extends?: string;\n\n  /**\n   * Compose multiple profiles (multi-inheritance).\n   */\n  compose?: string[];\n\n  // === Session Mode Configuration ===\n\n  /**\n   * How this worker's session relates to the parent orchestrator.\n   * - \"child\": Session is a child of parent - visible in TUI, shares context\n   * - \"isolated\": Separate server/session - fully independent\n   * - \"linked\": Separate server but events forwarded for visibility\n   * Default: \"linked\"\n   */\n  sessionMode?: WorkerSessionMode;\n\n  /**\n   * For linked mode: which events to forward to parent.\n   * Default: [\"tool\", \"message\", \"error\", \"complete\", \"progress\"]\n   */\n  forwardEvents?: WorkerForwardEvent[];\n\n  /**\n   * MCP server configuration for this worker.\n   * Use inheritAll: true to pass all parent MCP servers.\n   * Or specify servers: [\"neo4j\", \"linear\"] for specific ones.\n   */\n  mcp?: WorkerMcpConfig;\n\n  /**\n   * Integration selection for this worker.\n   */\n  integrations?: IntegrationSelection;\n\n  /**\n   * Explicit environment variables to set for this worker.\n   */\n  env?: Record<string, string>;\n\n  /**\n   * Environment variable prefixes to auto-forward.\n   * E.g., [\"OPENCODE_NEO4J_\", \"LINEAR_\"] to pass all Neo4j and Linear vars.\n   */\n  envPrefixes?: string[];\n\n  /**\n   * Skill permissions for this worker.\n   * Controls which skills this worker can access.\n   *\n   * Special value \"inherit\" means inherit all skills from parent (for agents).\n   * Default behavior (undefined) isolates worker to only its own skill.\n   *\n   * @example\n   * skillPermissions:\n   *   memory: allow\n   *   \"*\": deny\n   */\n  skillPermissions?: SkillPermissions | \"inherit\";\n}\n\n// ============================================================================\n// Combined Skill Types\n// ============================================================================\n\n/**\n * Complete skill frontmatter combining standard fields with OpenCode extensions.\n */\nexport interface SkillFrontmatter extends SkillFrontmatterBase, ProfileExtensions {}\n\n/**\n * Source location of a skill.\n */\nexport type SkillSource = { type: \"builtin\" } | { type: \"global\"; path: string } | { type: \"project\"; path: string };\n\n/**\n * Complete skill definition with parsed content.\n */\nexport interface Skill {\n  /**\n   * Unique identifier (directory name).\n   */\n  id: string;\n\n  /**\n   * Source location of this skill.\n   */\n  source: SkillSource;\n\n  /**\n   * Parsed YAML frontmatter.\n   */\n  frontmatter: SkillFrontmatter;\n\n  /**\n   * System prompt / instructions (markdown body).\n   */\n  systemPrompt: string;\n\n  /**\n   * Full file path to SKILL.md.\n   */\n  filePath: string;\n\n  /**\n   * Whether the skill has a scripts/ subdirectory.\n   */\n  hasScripts: boolean;\n\n  /**\n   * Whether the skill has a references/ subdirectory.\n   */\n  hasReferences: boolean;\n\n  /**\n   * Whether the skill has an assets/ subdirectory.\n   */\n  hasAssets: boolean;\n\n  /**\n   * When the skill was created (from file system).\n   */\n  createdAt?: Date;\n\n  /**\n   * When the skill was last modified (from file system).\n   */\n  updatedAt?: Date;\n}\n\n// ============================================================================\n// Input Types for CRUD Operations\n// ============================================================================\n\n/**\n * Input for creating or updating a skill.\n */\nexport interface SkillInput {\n  /**\n   * Skill ID (will become directory name).\n   */\n  id: string;\n\n  /**\n   * Frontmatter configuration.\n   */\n  frontmatter: Omit<SkillFrontmatter, \"name\"> & { name?: string };\n\n  /**\n   * System prompt / instructions content.\n   */\n  systemPrompt: string;\n}\n\n/**\n * Scope for skill storage operations.\n */\nexport type SkillScope = \"project\" | \"global\";\n\n// ============================================================================\n// Validation Types\n// ============================================================================\n\n/**\n * Validation error for a specific field.\n */\nexport interface SkillValidationError {\n  field: string;\n  message: string;\n}\n\n/**\n * Result of skill validation.\n */\nexport interface SkillValidationResult {\n  valid: boolean;\n  errors: SkillValidationError[];\n}\n"
  },
  {
    "path": "types/worker.ts",
    "content": "import type { SkillPermissions, ToolPermissions } from \"./permissions\";\nimport type { IntegrationSelection, SkillSource } from \"./skill\";\n\nexport type WorkerStatus = \"starting\" | \"ready\" | \"busy\" | \"error\" | \"stopped\";\n\n/**\n * Session mode determines how a worker's session relates to the parent orchestrator.\n * - \"child\": Session is a child of the parent - visible in TUI, shares context\n * - \"isolated\": Separate server/session - fully independent, no visibility\n * - \"linked\": Separate server but events are forwarded to parent for visibility\n */\nexport type WorkerSessionMode = \"child\" | \"isolated\" | \"linked\";\n\n/**\n * Events that can be forwarded from linked worker sessions to the parent.\n */\nexport type WorkerForwardEvent = \"tool\" | \"message\" | \"error\" | \"complete\" | \"progress\";\n\n/**\n * MCP server configuration to forward to workers.\n */\nexport type WorkerMcpConfig = {\n  /** MCP servers to enable for this worker */\n  servers?: string[];\n  /** Inherit all MCP servers from parent config */\n  inheritAll?: boolean;\n};\n\nexport interface WorkerProfile {\n  /** Unique identifier for this worker */\n  id: string;\n  /** Human-readable name */\n  name: string;\n  /** Model to use (provider/model or auto/node tag) */\n  model: string;\n  /** Provider ID */\n  providerID?: string;\n  /** What this worker specializes in */\n  purpose: string;\n  /** When to use this worker (injected into context) */\n  whenToUse: string;\n  /** Optional system prompt override */\n  systemPrompt?: string;\n  /** Port assigned to this worker's opencode instance */\n  port?: number;\n  /** Whether this worker can see images */\n  supportsVision?: boolean;\n  /** Whether this worker has web access */\n  supportsWeb?: boolean;\n  /** Custom tools to enable/disable */\n  tools?: Record<string, boolean>;\n  /** Temperature setting */\n  temperature?: number;\n  /** Max output tokens for this worker (if supported by provider) */\n  maxTokens?: number;\n  /** Whether this worker profile is enabled */\n  enabled?: boolean;\n  /** Optional keywords/tags to improve matching */\n  tags?: string[];\n  /** Whether to inject repo context on auto-launch (for docs worker) */\n  injectRepoContext?: boolean;\n  /** Optional tool permission constraints */\n  permissions?: ToolPermissions;\n  /** Extend another profile */\n  extends?: string;\n  /** Compose multiple profiles */\n  compose?: string[];\n\n  // === Session Mode Configuration ===\n\n  /** How this worker's session relates to the parent (default: \"linked\") */\n  sessionMode?: WorkerSessionMode;\n  /** For linked mode: which events to forward to parent */\n  forwardEvents?: WorkerForwardEvent[];\n  /** MCP server configuration for this worker */\n  mcp?: WorkerMcpConfig;\n  /** Integration selection for this worker */\n  integrations?: IntegrationSelection;\n  /** Environment variables to forward to this worker */\n  env?: Record<string, string>;\n  /** Environment variable prefixes to auto-forward (e.g., [\"OPENCODE_NEO4J_\"]) */\n  envPrefixes?: string[];\n  /** Origin of the profile definition (builtin, project, global). */\n  source?: SkillSource;\n\n  // === Skill Isolation Configuration ===\n\n  /**\n   * Skill permissions for this worker.\n   * Controls which skills this worker can access.\n   * Uses OpenCode's permission.skill config format with glob patterns.\n   *\n   * Special values:\n   * - \"inherit\": Inherit all skills from parent (for agents)\n   * - undefined: Default isolation (only own skill + explicitly allowed)\n   *\n   * @example\n   * {\n   *   \"memory\": \"allow\",   // Allow memory skill\n   *   \"*\": \"deny\"          // Deny all others\n   * }\n   */\n  skillPermissions?: SkillPermissions | \"inherit\";\n}\n\nexport interface WorkerInstance {\n  profile: WorkerProfile;\n  status: WorkerStatus;\n  port: number;\n  /** PID of the spawned `opencode serve` process (when spawned by orchestrator) */\n  pid?: number;\n  /** Base URL of the worker server */\n  serverUrl?: string;\n  /** Directory context for tool execution (query.directory) */\n  directory?: string;\n  sessionId?: string;\n  /** Session ID created in the parent OpenCode server for UI display */\n  uiSessionId?: string;\n  client?: ReturnType<typeof import(\"@opencode-ai/sdk\").createOpencodeClient>;\n  /** If this worker was spawned in-process, this shuts down its server */\n  shutdown?: () => void | Promise<void>;\n  startedAt: Date;\n  lastActivity?: Date;\n  error?: string;\n  warning?: string;\n  currentTask?: string;\n  /** Most recent completed output (for UI) */\n  lastResult?: {\n    at: Date;\n    jobId?: string;\n    response: string;\n    report?: {\n      summary?: string;\n      details?: string;\n      issues?: string[];\n      notes?: string;\n    };\n    durationMs?: number;\n  };\n  /** How the worker model was resolved */\n  modelResolution?: string;\n\n  // === Session Mode State ===\n\n  /** The resolved session mode for this instance */\n  sessionMode?: WorkerSessionMode;\n  /** Parent session ID (for child mode) */\n  parentSessionId?: string;\n  /** Event forwarding subscription handle (for linked mode) */\n  eventForwardingHandle?: { stop: () => void; isActive: () => boolean; setTurboMode: (enabled: boolean) => void };\n  /** Messages processed by this worker (for activity tracking) */\n  messageCount?: number;\n  /** Tools executed by this worker */\n  toolCount?: number;\n}\n\nexport interface Registry {\n  workers: Map<string, WorkerInstance>;\n  getWorker(id: string): WorkerInstance | undefined;\n  getWorkersByCapability(capability: string): WorkerInstance[];\n  getActiveWorkers(): WorkerInstance[];\n}\n\nexport interface MessageToWorker {\n  workerId: string;\n  content: string;\n  attachments?: Array<{\n    type: \"image\" | \"file\";\n    path?: string;\n    base64?: string;\n    mimeType?: string;\n  }>;\n  /** Wait for response */\n  waitForResponse?: boolean;\n  /** Timeout in ms */\n  timeout?: number;\n}\n\nexport interface WorkerResponse {\n  workerId: string;\n  content: string;\n  success: boolean;\n  error?: string;\n  duration?: number;\n}\n"
  },
  {
    "path": "types/workflow.ts",
    "content": "export type WorkflowSecurityConfig = {\n  /** Maximum steps allowed in a workflow */\n  maxSteps?: number;\n  /** Maximum characters allowed in the initial task */\n  maxTaskChars?: number;\n  /** Maximum characters allowed to carry between steps */\n  maxCarryChars?: number;\n  /** Timeout per step (ms) */\n  perStepTimeoutMs?: number;\n};\n\nexport type WorkflowStepConfig = {\n  id: string;\n  title?: string;\n  workerId?: string;\n  prompt?: string;\n  carry?: boolean;\n};\n\nexport type WorkflowsConfig = {\n  enabled?: boolean;\n  roocodeBoomerang?: {\n    enabled?: boolean;\n    steps?: WorkflowStepConfig[];\n    maxSteps?: number;\n    maxTaskChars?: number;\n    maxCarryChars?: number;\n    perStepTimeoutMs?: number;\n  };\n};\n\nexport type SecurityConfig = {\n  workflows?: WorkflowSecurityConfig;\n};\n"
  },
  {
    "path": "ux/repo-context.ts",
    "content": "/**\n * Repo Context - Gathers context about the repository for worker injection\n *\n * Used primarily for the docs worker to understand the project it's helping with.\n */\n\nimport { execSync } from \"node:child_process\";\nimport { existsSync, readdirSync, statSync } from \"node:fs\";\nimport { readFile } from \"node:fs/promises\";\nimport { basename, join } from \"node:path\";\n\nexport type RepoContext = {\n  /** Root directory of the repo */\n  root: string;\n  /** Project name (from package.json or directory name) */\n  name: string;\n  /** Project description (from package.json) */\n  description?: string;\n  /** Package.json contents (parsed) */\n  packageJson?: Record<string, unknown>;\n  /** README content (truncated) */\n  readme?: string;\n  /** Directory structure (top-level) */\n  structure: string[];\n  /** Git branch info */\n  git?: {\n    branch?: string;\n    remoteUrl?: string;\n    hasUncommittedChanges?: boolean;\n  };\n  /** Whether content was truncated */\n  truncated: boolean;\n  /** Formatted markdown for injection */\n  markdown: string;\n};\n\ntype RepoContextDeps = {\n  existsSync?: typeof existsSync;\n  readdirSync?: typeof readdirSync;\n  statSync?: typeof statSync;\n  readFile?: typeof readFile;\n  execSync?: typeof execSync;\n};\n\nfunction clampText(input: string, maxChars: number): { text: string; truncated: boolean } {\n  if (input.length <= maxChars) return { text: input, truncated: false };\n  return { text: `${input.slice(0, Math.max(0, maxChars))}\\n\\n...(truncated)\\n`, truncated: true };\n}\n\n/**\n * Check if a directory is a git repository by looking for .git directory.\n * This is faster and safer than running git commands.\n */\nfunction isGitRepository(directory: string, deps: RepoContextDeps): boolean {\n  const existsSyncFn = deps.existsSync ?? existsSync;\n  try {\n    return existsSyncFn(join(directory, \".git\"));\n  } catch {\n    return false;\n  }\n}\n\nfunction getGitInfo(directory: string, deps: RepoContextDeps): RepoContext[\"git\"] | undefined {\n  // Check for .git directory first to avoid unnecessary process spawning\n  if (!isGitRepository(directory, deps)) {\n    return undefined;\n  }\n\n  try {\n    const execSyncFn = deps.execSync ?? execSync;\n    const branch = execSyncFn(\"git rev-parse --abbrev-ref HEAD\", {\n      cwd: directory,\n      encoding: \"utf8\",\n      stdio: [\"pipe\", \"pipe\", \"pipe\"],\n      timeout: 5000, // 5 second timeout to prevent hanging\n    }).trim();\n\n    let remoteUrl: string | undefined;\n    try {\n      remoteUrl = execSyncFn(\"git remote get-url origin\", {\n        cwd: directory,\n        encoding: \"utf8\",\n        stdio: [\"pipe\", \"pipe\", \"pipe\"],\n        timeout: 5000,\n      }).trim();\n    } catch {\n      // No remote configured\n    }\n\n    let hasUncommittedChanges = false;\n    try {\n      const status = execSyncFn(\"git status --porcelain\", {\n        cwd: directory,\n        encoding: \"utf8\",\n        stdio: [\"pipe\", \"pipe\", \"pipe\"],\n        timeout: 10000, // Longer timeout for status as it can be slower\n      }).trim();\n      hasUncommittedChanges = status.length > 0;\n    } catch {\n      // Git status failed\n    }\n\n    return { branch, remoteUrl, hasUncommittedChanges };\n  } catch {\n    return undefined;\n  }\n}\n\nfunction getDirectoryStructure(directory: string, maxItems = 30, deps: RepoContextDeps = {}): string[] {\n  const readdirSyncFn = deps.readdirSync ?? readdirSync;\n  const statSyncFn = deps.statSync ?? statSync;\n  try {\n    const entries = readdirSyncFn(directory);\n    const result: string[] = [];\n\n    // Prioritize important files/dirs\n    const priority = [\n      \"package.json\",\n      \"tsconfig.json\",\n      \"README.md\",\n      \"src\",\n      \"lib\",\n      \"app\",\n      \"pages\",\n      \"components\",\n      \"test\",\n      \"tests\",\n      \"__tests__\",\n    ];\n\n    const sorted = entries.sort((a, b) => {\n      const aIdx = priority.indexOf(a);\n      const bIdx = priority.indexOf(b);\n      if (aIdx !== -1 && bIdx !== -1) return aIdx - bIdx;\n      if (aIdx !== -1) return -1;\n      if (bIdx !== -1) return 1;\n      return a.localeCompare(b);\n    });\n\n    for (const entry of sorted) {\n      if (result.length >= maxItems) break;\n      if (entry.startsWith(\".\") && entry !== \".github\") continue;\n      if (entry === \"node_modules\" || entry === \"dist\" || entry === \"build\") continue;\n\n      try {\n        const stat = statSyncFn(join(directory, entry));\n        const suffix = stat.isDirectory() ? \"/\" : \"\";\n        result.push(entry + suffix);\n      } catch {\n        result.push(entry);\n      }\n    }\n\n    return result;\n  } catch {\n    return [];\n  }\n}\n\nexport async function getRepoContext(options: {\n  directory: string;\n  maxReadmeChars?: number;\n  maxTotalChars?: number;\n  deps?: RepoContextDeps;\n}): Promise<RepoContext | undefined> {\n  const { directory } = options;\n  const maxReadmeChars = options.maxReadmeChars ?? 8000;\n  const maxTotalChars = options.maxTotalChars ?? 16000;\n  const deps = options.deps ?? {};\n  const existsSyncFn = deps.existsSync ?? existsSync;\n  const readFileFn = deps.readFile ?? readFile;\n\n  if (!existsSyncFn(directory)) return undefined;\n\n  let name = basename(directory);\n  let description: string | undefined;\n  let packageJson: Record<string, unknown> | undefined;\n\n  // Try to read package.json\n  const pkgPath = join(directory, \"package.json\");\n  if (existsSyncFn(pkgPath)) {\n    try {\n      const raw = await readFileFn(pkgPath, \"utf8\");\n      packageJson = JSON.parse(raw);\n      if (packageJson && typeof packageJson.name === \"string\") name = packageJson.name;\n      if (packageJson && typeof packageJson.description === \"string\") description = packageJson.description;\n    } catch {\n      // Ignore parse errors\n    }\n  }\n\n  // Try to read README\n  let readme: string | undefined;\n  let readmeTruncated = false;\n  const readmeNames = [\"README.md\", \"readme.md\", \"README\", \"README.txt\"];\n  for (const readmeName of readmeNames) {\n    const readmePath = join(directory, readmeName);\n    if (existsSyncFn(readmePath)) {\n      try {\n        const raw = await readFileFn(readmePath, \"utf8\");\n        const clamped = clampText(raw, maxReadmeChars);\n        readme = clamped.text;\n        readmeTruncated = clamped.truncated;\n      } catch {\n        // Ignore read errors\n      }\n      break;\n    }\n  }\n\n  // Get directory structure\n  const structure = getDirectoryStructure(directory, 30, deps);\n\n  // Get git info\n  const git = getGitInfo(directory, deps);\n\n  // Build markdown\n  const sections: string[] = [];\n  sections.push(`# Project Context: ${name}`);\n  sections.push(\"\");\n\n  if (description) {\n    sections.push(`> ${description}`);\n    sections.push(\"\");\n  }\n\n  if (git) {\n    sections.push(\"## Git Info\");\n    if (git.branch) sections.push(`- Branch: \\`${git.branch}\\``);\n    if (git.remoteUrl) sections.push(`- Remote: \\`${git.remoteUrl}\\``);\n    if (git.hasUncommittedChanges) sections.push(`- Has uncommitted changes`);\n    sections.push(\"\");\n  }\n\n  sections.push(\"## Directory Structure\");\n  sections.push(\"```\");\n  sections.push(structure.join(\"\\n\"));\n  sections.push(\"```\");\n  sections.push(\"\");\n\n  if (packageJson) {\n    sections.push(\"## package.json (summary)\");\n    const deps = Object.keys((packageJson.dependencies as Record<string, string>) ?? {});\n    const devDeps = Object.keys((packageJson.devDependencies as Record<string, string>) ?? {});\n    const scripts = Object.keys((packageJson.scripts as Record<string, string>) ?? {});\n\n    if (scripts.length > 0) {\n      sections.push(`- Scripts: ${scripts.slice(0, 10).join(\", \")}${scripts.length > 10 ? \"...\" : \"\"}`);\n    }\n    if (deps.length > 0) {\n      sections.push(`- Dependencies: ${deps.slice(0, 10).join(\", \")}${deps.length > 10 ? \"...\" : \"\"}`);\n    }\n    if (devDeps.length > 0) {\n      sections.push(`- Dev dependencies: ${devDeps.slice(0, 10).join(\", \")}${devDeps.length > 10 ? \"...\" : \"\"}`);\n    }\n    sections.push(\"\");\n  }\n\n  if (readme) {\n    sections.push(\"## README\");\n    sections.push(readme);\n    sections.push(\"\");\n  }\n\n  let markdown = sections.join(\"\\n\");\n  let truncated = readmeTruncated;\n\n  // Final clamp\n  if (markdown.length > maxTotalChars) {\n    const clamped = clampText(markdown, maxTotalChars);\n    markdown = clamped.text;\n    truncated = true;\n  }\n\n  return {\n    root: directory,\n    name,\n    description,\n    packageJson,\n    readme,\n    structure,\n    git,\n    truncated,\n    markdown,\n  };\n}\n\n/**\n * Get repo context formatted for worker prompt injection.\n * Returns undefined if no context can be gathered.\n */\nexport async function getRepoContextForWorker(directory: string, deps?: RepoContextDeps): Promise<string | undefined> {\n  const context = await getRepoContext({\n    directory,\n    maxReadmeChars: 6000,\n    maxTotalChars: 12000,\n    deps,\n  });\n\n  if (!context) return undefined;\n\n  return `<repo-context>\\n${context.markdown}\\n</repo-context>`;\n}\n"
  },
  {
    "path": "ux/vision-attachments.ts",
    "content": "import { execFile } from \"node:child_process\";\nimport { readFile, unlink } from \"node:fs/promises\";\nimport { tmpdir } from \"node:os\";\nimport { join } from \"node:path\";\nimport { fileURLToPath } from \"node:url\";\nimport { promisify } from \"node:util\";\nimport type { WorkerAttachment } from \"../workers/prompt\";\nimport { normalizeBase64Image } from \"../workers/prompt\";\nimport { isImagePart } from \"./vision-parts\";\nimport type { VisionPart } from \"./vision-types\";\n\nconst execFileAsync = promisify(execFile);\n\nconst inferMimeType = (path: string): string => {\n  const ext = path.toLowerCase().split(\".\").pop();\n  const mimeMap: Record<string, string> = {\n    png: \"image/png\",\n    jpg: \"image/jpeg\",\n    jpeg: \"image/jpeg\",\n    gif: \"image/gif\",\n    webp: \"image/webp\",\n    svg: \"image/svg+xml\",\n  };\n  return mimeMap[ext ?? \"\"] ?? \"image/png\";\n};\n\ntype ClipboardDeps = {\n  execFileAsync?: typeof execFileAsync;\n  readFile?: typeof readFile;\n  unlink?: typeof unlink;\n  tmpdir?: typeof tmpdir;\n  platform?: string;\n};\n\nconst readClipboardImage = async (\n  deps: ClipboardDeps = {},\n): Promise<{ mimeType: string; base64: string } | undefined> => {\n  const platform = deps.platform ?? process.platform;\n  const exec = deps.execFileAsync ?? execFileAsync;\n  const read = deps.readFile ?? readFile;\n  const remove = deps.unlink ?? unlink;\n  const tempDir = deps.tmpdir ?? tmpdir;\n\n  if (platform === \"darwin\") {\n    const outPath = join(tempDir(), `opencode-clipboard-${process.pid}.png`);\n    const script = [\n      `set outPath to \"${outPath.replace(/\"/g, '\\\\\"')}\"`,\n      `set outFile to POSIX file outPath`,\n      `set f to open for access outFile with write permission`,\n      `set eof f to 0`,\n      `write (the clipboard as \\u00abclass PNGf\\u00bb) to f`,\n      `close access f`,\n      `return outPath`,\n    ].join(\"\\n\");\n\n    await exec(\"osascript\", [\"-e\", script], { timeout: 2000 });\n    try {\n      const buf = await read(outPath);\n      if (buf.length === 0) return undefined;\n      return { mimeType: \"image/png\", base64: buf.toString(\"base64\") };\n    } finally {\n      await remove(outPath).catch(() => {});\n    }\n  }\n\n  if (platform === \"linux\") {\n    try {\n      const { stdout } = (await exec(\"wl-paste\", [\"--no-newline\", \"--type\", \"image/png\"], {\n        encoding: null,\n        timeout: 2000,\n        maxBuffer: 20 * 1024 * 1024,\n      })) as { stdout: Buffer | string };\n      const buf = Buffer.isBuffer(stdout) ? stdout : Buffer.from(stdout);\n      if (buf.length > 0) return { mimeType: \"image/png\", base64: buf.toString(\"base64\") };\n    } catch {\n      try {\n        const { stdout } = (await exec(\"xclip\", [\"-selection\", \"clipboard\", \"-t\", \"image/png\", \"-o\"], {\n          encoding: null,\n          timeout: 2000,\n          maxBuffer: 20 * 1024 * 1024,\n        })) as { stdout: Buffer | string };\n        const buf = Buffer.isBuffer(stdout) ? stdout : Buffer.from(stdout);\n        if (buf.length > 0) return { mimeType: \"image/png\", base64: buf.toString(\"base64\") };\n      } catch {\n        // ignore\n      }\n    }\n  }\n\n  return undefined;\n};\n\ntype VisionAttachmentDeps = {\n  readFile?: typeof readFile;\n  readClipboardImage?: (deps?: ClipboardDeps) => Promise<{ mimeType: string; base64: string } | undefined>;\n  clipboardDeps?: ClipboardDeps;\n};\n\nconst extractSingleImage = async (part: VisionPart, deps?: VisionAttachmentDeps): Promise<WorkerAttachment | null> => {\n  try {\n    const partUrl = typeof part.url === \"string\" ? part.url : undefined;\n    const mimeType =\n      typeof part.mime === \"string\" ? part.mime : typeof part.mimeType === \"string\" ? part.mimeType : undefined;\n    const readFileFn = deps?.readFile ?? readFile;\n    const readClipboardImageFn = deps?.readClipboardImage ?? readClipboardImage;\n\n    if (partUrl?.startsWith(\"file://\")) {\n      const path = fileURLToPath(partUrl);\n      const buf = await readFileFn(path);\n      return { type: \"image\", mimeType: mimeType ?? inferMimeType(path), base64: buf.toString(\"base64\") };\n    }\n\n    if (partUrl && (partUrl.startsWith(\"/\") || /^[A-Za-z]:[\\\\/]/.test(partUrl))) {\n      const buf = await readFileFn(partUrl);\n      return { type: \"image\", mimeType: mimeType ?? inferMimeType(partUrl), base64: buf.toString(\"base64\") };\n    }\n\n    if (partUrl?.startsWith(\"data:\")) {\n      const match = partUrl.match(/^data:(image\\/[^;]+);base64,(.*)$/);\n      if (match) {\n        return { type: \"image\", mimeType: match[1], base64: match[2] };\n      }\n    }\n\n    if (partUrl === \"clipboard\" || partUrl?.startsWith(\"clipboard:\")) {\n      const clip = await readClipboardImageFn(deps?.clipboardDeps);\n      if (clip) return { type: \"image\", mimeType: clip.mimeType, base64: clip.base64 };\n    }\n\n    if (part.base64 && typeof part.base64 === \"string\") {\n      return { type: \"image\", mimeType: mimeType ?? \"image/png\", base64: normalizeBase64Image(part.base64) };\n    }\n  } catch {\n    return null;\n  }\n\n  return null;\n};\n\n/** Convert image parts into worker attachments that can be sent to vision models. */\nexport const extractVisionAttachments = async (\n  parts: VisionPart[],\n  deps?: VisionAttachmentDeps,\n): Promise<WorkerAttachment[]> => {\n  if (!Array.isArray(parts)) return [];\n  const imageParts = parts.filter((part) => isImagePart(part));\n  if (imageParts.length === 0) return [];\n  const results = await Promise.all(imageParts.map((part) => extractSingleImage(part, deps)));\n  return results.filter((result): result is WorkerAttachment => Boolean(result));\n};\n\nexport const __test__ = { readClipboardImage };\n"
  },
  {
    "path": "ux/vision-parts.ts",
    "content": "import type { VisionPart } from \"./vision-types\";\n\nconst isImagePart = (part: VisionPart): boolean => {\n  if (!part) return false;\n  if (part.type === \"image\") return true;\n  const mime = typeof part.mime === \"string\" ? part.mime : typeof part.mimeType === \"string\" ? part.mimeType : \"\";\n  if (part.type === \"file\" && mime.startsWith(\"image/\")) return true;\n  if (part.type === \"file\" && typeof part.url === \"string\" && part.url.startsWith(\"data:image/\")) return true;\n  if (typeof part.url === \"string\" && (part.url === \"clipboard\" || part.url.startsWith(\"clipboard:\"))) return true;\n  return false;\n};\n\n/** Check whether any parts represent image data. */\nexport const hasVisionParts = (parts: VisionPart[]): boolean => {\n  if (!Array.isArray(parts)) return false;\n  return parts.some((part) => isImagePart(part));\n};\n\n/**\n * Wrap vision results in a formatted block with explicit instructions.\n * The instructions tell the model this is a TEXT DESCRIPTION of an image,\n * not the image itself, so it should use this description directly.\n */\nexport const formatVisionAnalysis = (input: { response?: string; error?: string }): string => {\n  const instruction =\n    \"[This is a TEXT DESCRIPTION of an image the user pasted. The image has already been analyzed. \" +\n    \"Use this description to answer the user's question. Do NOT say you cannot see images.]\";\n\n  if (input.response) {\n    const trimmed = input.response.trim();\n    if (trimmed) return `<pasted_image>\\n${instruction}\\n\\n${trimmed}\\n</pasted_image>`;\n  }\n  if (input.error) {\n    const trimmed = input.error.trim();\n    if (trimmed) return `<pasted_image>\\n${instruction}\\n\\n[Image could not be analyzed: ${trimmed}]\\n</pasted_image>`;\n  }\n  return `<pasted_image>\\n${instruction}\\n\\n[Image could not be analyzed]\\n</pasted_image>`;\n};\n\n/** Replace image parts with a text summary of the vision analysis. */\nexport const replaceImagesWithText = (\n  parts: VisionPart[],\n  text: string,\n  meta?: { sessionID?: string; messageID?: string },\n): VisionPart[] => {\n  if (!Array.isArray(parts)) return parts;\n  const withoutImages = parts.filter((part) => !isImagePart(part));\n  if (withoutImages.length === parts.length) return parts;\n\n  // Find first text part and prepend image description to it\n  for (let i = 0; i < withoutImages.length; i += 1) {\n    const part = withoutImages[i];\n    if (part?.type !== \"text\" || typeof part.text !== \"string\") continue;\n    part.text = `${text}\\n\\n${part.text}`;\n    return withoutImages;\n  }\n\n  // No text part found - create one with just the image description\n  withoutImages.unshift({\n    type: \"text\",\n    text,\n    id: `${meta?.messageID ?? \"msg\"}-vision-placeholder`,\n    sessionID: meta?.sessionID ?? \"\",\n    messageID: meta?.messageID ?? \"\",\n    synthetic: true,\n  });\n\n  return withoutImages;\n};\n\n/** Predicate for image-like parts (images, files, or clipboard references). */\nexport { isImagePart };\n"
  },
  {
    "path": "ux/vision-routing.ts",
    "content": "import type { Message, Part } from \"@opencode-ai/sdk\";\nimport { extractVisionAttachments } from \"./vision-attachments\";\nimport { formatVisionAnalysis, hasVisionParts, replaceImagesWithText } from \"./vision-parts\";\nimport type { VisionChatInput, VisionChatOutput, VisionRoutingDeps, VisionRoutingState } from \"./vision-types\";\n\nexport { extractVisionAttachments } from \"./vision-attachments\";\nexport { formatVisionAnalysis, hasVisionParts, replaceImagesWithText } from \"./vision-parts\";\nexport type {\n  VisionChatInput,\n  VisionChatOutput,\n  VisionPart,\n  VisionRoutingDeps,\n  VisionRoutingState,\n} from \"./vision-types\";\n\nconst DEFAULT_PROMPT =\n  \"Describe this image precisely and concisely. Include: any visible text (exact wording), code snippets, UI elements, error messages, diagrams, or data. Be factual - do not interpret or answer questions about the image.\";\n\nconst VISION_PLACEHOLDER =\n  \"[VISION ANALYSIS IN PROGRESS]\\n\" +\n  \"An image is being analyzed by the vision worker. \" +\n  \"The orchestrator will receive the analysis results automatically via the await_worker_job tool.\\n\" +\n  \"Do NOT respond about the image until the analysis is complete.\";\n\n/** Create a tracking state for processed vision messages. */\nexport function createVisionRoutingState(): VisionRoutingState {\n  return { processedMessageIds: new Set() };\n}\n\n/**\n * Route image-bearing user messages through the vision worker.\n * Uses async job-based approach: immediately replaces images with placeholder,\n * starts analysis in background, orchestrator uses await_worker_job to get results.\n */\nexport async function routeVisionMessage(\n  input: VisionChatInput,\n  output: VisionChatOutput,\n  deps: VisionRoutingDeps,\n  state: VisionRoutingState,\n): Promise<string | undefined> {\n  const role =\n    typeof output.message?.role === \"string\"\n      ? output.message?.role\n      : typeof input.role === \"string\"\n        ? input.role\n        : undefined;\n  if (role && role !== \"user\") return undefined;\n\n  const originalParts = Array.isArray(output.parts) ? output.parts : [];\n  if (!hasVisionParts(originalParts)) return undefined;\n\n  const messageId = typeof input.messageID === \"string\" ? input.messageID : undefined;\n  if (messageId && state.processedMessageIds.has(messageId)) return undefined;\n\n  const agentId = typeof input.agent === \"string\" ? input.agent : undefined;\n  const agentProfile = agentId ? deps.profiles[agentId] : undefined;\n  const agentSupportsVision = Boolean(agentProfile?.supportsVision) || agentId === \"vision\";\n  if (agentSupportsVision) return undefined;\n\n  const visionProfile = deps.profiles.vision;\n  const visionModel = visionProfile?.model ?? \"vision\";\n\n  if (messageId) state.processedMessageIds.add(messageId);\n\n  const timeoutMs = deps.timeoutMs ?? 300_000;\n  const prompt = deps.prompt ?? DEFAULT_PROMPT;\n  const startedAt = Date.now();\n\n  // Extract attachments FIRST to check if we have valid images\n  const attachments = await extractVisionAttachments(originalParts);\n  if (attachments.length === 0) {\n    const error = \"No valid image attachments found\";\n    output.parts = replaceImagesWithText(originalParts, formatVisionAnalysis({ error }), {\n      sessionID: input.sessionID,\n      messageID: input.messageID,\n    });\n    try {\n      await deps.logSink?.({\n        status: \"failed\",\n        error,\n        sessionId: input.sessionID,\n        messageId,\n        workerId: \"vision\",\n        model: visionModel,\n        startedAt,\n        finishedAt: Date.now(),\n      });\n    } catch {\n      // ignore log sink failures\n    }\n    return undefined;\n  }\n\n  // Create a job for async vision analysis\n  const job = deps.workers.jobs.create({\n    workerId: \"vision\",\n    message: prompt,\n    sessionId: input.sessionID,\n    requestedBy: agentId ?? \"orchestrator\",\n  });\n\n  // IMMEDIATELY replace images with placeholder showing analysis is in progress\n  // This allows the hook to return quickly and the UI to show the message\n  const placeholderText =\n    `<pasted_image job=\"${job.id}\">\\n` +\n    VISION_PLACEHOLDER +\n    `\\nJob ID: ${job.id} - Use await_worker_job({ jobId: \"${job.id}\" }) to get results.\\n` +\n    `</pasted_image>`;\n\n  const placeholderParts = replaceImagesWithText(originalParts, placeholderText, {\n    sessionID: input.sessionID,\n    messageID: input.messageID,\n  });\n\n  // Mutate output.parts in place\n  output.parts.length = 0;\n  output.parts.push(...placeholderParts);\n\n  // Emit vision started event for UI feedback\n  deps.communication?.emit(\n    \"orchestra.vision.started\",\n    { sessionId: input.sessionID, messageId, jobId: job.id },\n    { source: \"vision\" },\n  );\n\n  // Run vision analysis in background (non-blocking)\n  void (async () => {\n    try {\n      // Ensure vision worker is running\n      if (deps.ensureWorker) {\n        await deps.ensureWorker({ workerId: \"vision\", reason: \"on-demand\" });\n      } else if (!deps.workers.getWorker(\"vision\")) {\n        await deps.workers.spawnById(\"vision\");\n      }\n\n      const res = await deps.workers.send(\"vision\", prompt, {\n        attachments,\n        timeout: timeoutMs,\n        from: agentId ?? \"orchestrator\",\n        jobId: job.id,\n      });\n\n      const trimmedResponse = typeof res.response === \"string\" ? res.response.trim() : \"\";\n      const succeeded = res.success && trimmedResponse.length > 0;\n      const durationMs = Date.now() - startedAt;\n\n      // Set the job result so await_worker_job can retrieve it\n      if (succeeded) {\n        const analysisText = formatVisionAnalysis({ response: trimmedResponse });\n        deps.workers.jobs.setResult(job.id, { responseText: analysisText });\n      } else {\n        deps.workers.jobs.setResult(job.id, { error: res.error ?? \"Vision analysis failed\" });\n      }\n\n      // Emit vision completed event for UI feedback\n      deps.communication?.emit(\n        \"orchestra.vision.completed\",\n        { success: succeeded, error: succeeded ? undefined : res.error, durationMs, jobId: job.id },\n        { source: \"vision\" },\n      );\n\n      // Auto-stop vision worker after successful analysis (default: true)\n      if (succeeded && deps.autoStopVisionWorker !== false) {\n        try {\n          await deps.workers.stopWorker(\"vision\");\n        } catch {\n          // Ignore stop errors - worker may have already stopped\n        }\n      }\n\n      try {\n        await deps.logSink?.({\n          status: succeeded ? \"succeeded\" : \"failed\",\n          analysis: succeeded ? trimmedResponse : undefined,\n          error: succeeded ? undefined : (res.error ?? \"Vision analysis failed\"),\n          sessionId: input.sessionID,\n          messageId,\n          workerId: \"vision\",\n          model: visionModel,\n          attachments: attachments.length,\n          requestedBy: agentId,\n          startedAt,\n          finishedAt: Date.now(),\n          durationMs,\n          jobId: job.id,\n        });\n      } catch {\n        // ignore log sink failures\n      }\n    } catch (err) {\n      const error = err instanceof Error ? err.message : String(err);\n      const durationMs = Date.now() - startedAt;\n\n      // Set error result on the job\n      deps.workers.jobs.setResult(job.id, { error });\n\n      // Emit vision failed event for UI feedback\n      deps.communication?.emit(\n        \"orchestra.vision.completed\",\n        { success: false, error, durationMs, jobId: job.id },\n        { source: \"vision\" },\n      );\n\n      try {\n        await deps.logSink?.({\n          status: \"failed\",\n          error,\n          sessionId: input.sessionID,\n          messageId,\n          workerId: \"vision\",\n          model: visionModel,\n          startedAt,\n          finishedAt: Date.now(),\n          durationMs,\n          jobId: job.id,\n        });\n      } catch {\n        // ignore log sink failures\n      }\n    }\n  })();\n\n  // Return the job ID so callers know analysis is pending\n  return job.id;\n}\n\n/** Backfill processed vision message IDs by scanning message outputs. */\nexport function syncVisionProcessedMessages(\n  output: { messages: Array<{ info?: Message; parts?: Part[] }> },\n  state: VisionRoutingState,\n) {\n  const messages = output.messages ?? [];\n  for (const msg of messages) {\n    const info = msg?.info;\n    if (info?.role !== \"user\") continue;\n    const messageId = typeof info?.id === \"string\" ? info.id : undefined;\n    if (!messageId || state.processedMessageIds.has(messageId)) continue;\n    const parts = Array.isArray(msg.parts) ? msg.parts : [];\n    const hasMarker = parts.some(\n      (part) =>\n        part.type === \"text\" &&\n        typeof part.text === \"string\" &&\n        (part.text.includes(\"<pasted_image>\") || part.text.includes(\"[VISION ANALYSIS\")),\n    );\n    if (hasMarker) state.processedMessageIds.add(messageId);\n  }\n}\n"
  },
  {
    "path": "ux/vision-types.ts",
    "content": "import type { CommunicationService } from \"../communication\";\nimport type { WorkerInstance } from \"../types\";\nimport type { WorkerManager } from \"../workers\";\n\nexport type VisionPart = {\n  type?: string;\n  url?: string;\n  base64?: string;\n  mime?: string;\n  mimeType?: string;\n  text?: string;\n  id?: string;\n  sessionID?: string;\n  messageID?: string;\n  synthetic?: boolean;\n};\n\nexport type VisionRoutingState = {\n  processedMessageIds: Set<string>;\n};\n\nexport type VisionRoutingDeps = {\n  workers: Pick<WorkerManager, \"getWorker\" | \"spawnById\" | \"send\" | \"jobs\" | \"stopWorker\">;\n  ensureWorker?: (input: { workerId: string; reason: \"manual\" | \"on-demand\" }) => Promise<WorkerInstance>;\n  profiles: Record<string, { id: string; name?: string; model?: string; supportsVision?: boolean }>;\n  communication?: Pick<CommunicationService, \"emit\">;\n  timeoutMs?: number;\n  prompt?: string;\n  logSink?: (entry: Record<string, unknown>) => Promise<void> | void;\n  /** If true, stop the vision worker after successful analysis. Default: true */\n  autoStopVisionWorker?: boolean;\n};\n\nexport type VisionChatInput = {\n  sessionID: string;\n  agent?: string;\n  messageID?: string;\n  role?: string;\n};\n\nexport type VisionChatOutput = {\n  message?: { role?: string };\n  parts: VisionPart[];\n};\n"
  },
  {
    "path": "workers/attachments.ts",
    "content": "import { copyFile, mkdir, unlink, writeFile } from \"node:fs/promises\";\nimport { extname, isAbsolute, join, relative, resolve } from \"node:path\";\nimport { normalizeBase64Image, type WorkerAttachment } from \"./prompt\";\n\nfunction isPathInside(baseDir: string, targetPath: string): boolean {\n  const base = resolve(baseDir);\n  const target = resolve(targetPath);\n  const rel = relative(base, target);\n  return rel === \"\" || (!rel.startsWith(\"..\") && !isAbsolute(rel));\n}\n\nexport async function prepareWorkerAttachments(input: {\n  attachments?: WorkerAttachment[];\n  baseDir: string;\n  workerId: string;\n}): Promise<{ attachments?: WorkerAttachment[]; cleanup: () => Promise<void> }> {\n  if (!input.attachments || input.attachments.length === 0) {\n    return { attachments: input.attachments, cleanup: async () => {} };\n  }\n\n  const tempDir = join(input.baseDir, \".opencode\", \"attachments\");\n  const created: string[] = [];\n  const normalized: WorkerAttachment[] = [];\n\n  const ensureTempDir = async () => {\n    await mkdir(tempDir, { recursive: true });\n  };\n\n  const extForMime = (mimeType?: string, fallbackPath?: string): string => {\n    if (fallbackPath) {\n      const ext = extname(fallbackPath);\n      if (ext) return ext;\n    }\n    if (!mimeType) return \".png\";\n    if (mimeType.includes(\"png\")) return \".png\";\n    if (mimeType.includes(\"jpeg\") || mimeType.includes(\"jpg\")) return \".jpg\";\n    if (mimeType.includes(\"webp\")) return \".webp\";\n    if (mimeType.includes(\"gif\")) return \".gif\";\n    return \".bin\";\n  };\n\n  let counter = 0;\n  for (const attachment of input.attachments) {\n    if (attachment.type !== \"image\") {\n      normalized.push(attachment);\n    } else if (attachment.path) {\n      if (isPathInside(input.baseDir, attachment.path)) {\n        normalized.push(attachment);\n      } else {\n        await ensureTempDir();\n        const ext = extForMime(attachment.mimeType, attachment.path);\n        const dest = join(tempDir, `${input.workerId}-${Date.now()}-${counter++}${ext}`);\n        await copyFile(attachment.path, dest);\n        created.push(dest);\n        normalized.push({ ...attachment, path: dest, base64: undefined });\n      }\n    } else if (attachment.base64) {\n      await ensureTempDir();\n      const ext = extForMime(attachment.mimeType);\n      const dest = join(tempDir, `${input.workerId}-${Date.now()}-${counter++}${ext}`);\n      const decoded = Buffer.from(normalizeBase64Image(attachment.base64), \"base64\");\n      await writeFile(dest, decoded);\n      created.push(dest);\n      normalized.push({ type: \"image\", path: dest, mimeType: attachment.mimeType });\n    } else {\n      normalized.push(attachment);\n    }\n  }\n\n  return {\n    attachments: normalized,\n    cleanup: async () => {\n      await Promise.all(\n        created.map(async (path) => {\n          try {\n            await unlink(path);\n          } catch {\n            // ignore\n          }\n        }),\n      );\n    },\n  };\n}\n"
  },
  {
    "path": "workers/event-forwarding.ts",
    "content": "import type { CommunicationService } from \"../communication\";\nimport type { WorkerForwardEvent, WorkerInstance } from \"../types/worker\";\nimport type { WorkerSessionManager } from \"./session-manager\";\n\n/**\n * Event forwarding handle that can be stopped.\n */\nexport interface EventForwardingHandle {\n  stop: () => void;\n  isActive: () => boolean;\n  /** Enable turbo mode for faster polling during active tasks */\n  setTurboMode: (enabled: boolean) => void;\n}\n\n/**\n * Configuration for event forwarding.\n */\nexport interface EventForwardingConfig {\n  /** Events to forward */\n  events: WorkerForwardEvent[];\n  /** Polling interval in ms (for SDK clients without streaming) */\n  pollIntervalMs?: number;\n  /** Maximum events to process per poll */\n  maxEventsPerPoll?: number;\n}\n\nconst DEFAULT_POLL_INTERVAL_MS = 1000;\n/** Fast polling interval for active tasks */\nconst TURBO_POLL_INTERVAL_MS = 150;\nconst DEFAULT_MAX_EVENTS_PER_POLL = 20;\n/** Maximum consecutive errors before stopping polling */\nconst MAX_CONSECUTIVE_ERRORS = 5;\n/** Maximum backoff interval in milliseconds */\nconst MAX_BACKOFF_MS = 30000;\n/** Base backoff interval in milliseconds */\nconst BASE_BACKOFF_MS = 1000;\n\ntype MessageInfo = { id?: string; role?: string };\ntype SessionMessage = { info?: MessageInfo; parts?: unknown[] };\ntype ToolInvocation = { toolName?: string; args?: unknown; state?: string };\ntype MessagePart = {\n  type?: string;\n  text?: string;\n  error?: string;\n  reasoning?: { content?: string };\n  toolInvocation?: ToolInvocation;\n};\n\nconst asRecord = (value: unknown): value is Record<string, unknown> => typeof value === \"object\" && value !== null;\n\nconst readSessionMessages = (result: unknown): SessionMessage[] => {\n  const data = asRecord(result) && \"data\" in result ? (result as { data?: unknown }).data : result;\n  if (!Array.isArray(data)) return [];\n  return data as SessionMessage[];\n};\n\n/**\n * Start forwarding events from a worker session to the session manager.\n * This enables visibility into linked worker sessions.\n */\nexport function startEventForwarding(\n  instance: WorkerInstance,\n  sessionManager: WorkerSessionManager,\n  _communication: CommunicationService,\n  config?: Partial<EventForwardingConfig>,\n): EventForwardingHandle {\n  const events = config?.events ?? [\"tool\", \"message\", \"error\", \"complete\", \"progress\"];\n  const pollIntervalMs = config?.pollIntervalMs ?? DEFAULT_POLL_INTERVAL_MS;\n  const maxEventsPerPoll = config?.maxEventsPerPoll ?? DEFAULT_MAX_EVENTS_PER_POLL;\n\n  let active = true;\n  let turboMode = false;\n  let lastMessageId: string | undefined;\n  let pollTimer: ReturnType<typeof setTimeout> | undefined;\n  let consecutiveErrors = 0;\n  let currentBackoff = pollIntervalMs;\n\n  const getEffectivePollInterval = () => (turboMode ? TURBO_POLL_INTERVAL_MS : pollIntervalMs);\n\n  const poll = async () => {\n    if (!active || !instance.client || !instance.sessionId) return;\n\n    try {\n      // Fetch messages from the worker session\n      const result = await instance.client.session.messages({\n        path: { id: instance.sessionId },\n        query: { directory: instance.directory ?? process.cwd() },\n      });\n\n      const messages = readSessionMessages(result);\n\n      // Reset backoff on successful poll\n      consecutiveErrors = 0;\n      currentBackoff = getEffectivePollInterval();\n\n      if (messages.length === 0) {\n        // Schedule next poll if still active\n        if (active) {\n          pollTimer = setTimeout(poll, getEffectivePollInterval());\n        }\n        return;\n      }\n\n      // Process new messages\n      let foundLast = !lastMessageId;\n      let processed = 0;\n\n      for (const msg of messages) {\n        const msgId = msg?.info?.id;\n        if (!msgId) continue;\n\n        // Skip until we find our last seen message\n        if (!foundLast) {\n          if (msgId === lastMessageId) foundLast = true;\n          continue;\n        }\n\n        // Skip if this is the last message itself\n        if (msgId === lastMessageId) continue;\n\n        // Process this message\n        await processMessage(msg, instance, sessionManager, _communication, events);\n        lastMessageId = msgId;\n        processed++;\n\n        if (processed >= maxEventsPerPoll) break;\n      }\n\n      // Update instance activity\n      if (processed > 0) {\n        instance.lastActivity = new Date();\n        instance.messageCount = (instance.messageCount ?? 0) + processed;\n      }\n    } catch (error) {\n      const errMsg = error instanceof Error ? error.message : String(error);\n\n      // Check for terminal errors that should stop polling\n      const isTerminalError = errMsg.includes(\"not found\") || errMsg.includes(\"closed\");\n\n      if (isTerminalError) {\n        // Session is gone, stop polling\n        active = false;\n        return;\n      }\n\n      // Increment error count and apply exponential backoff\n      consecutiveErrors++;\n\n      // Check if we've exceeded max errors (circuit breaker)\n      if (consecutiveErrors >= MAX_CONSECUTIVE_ERRORS) {\n        // Record error and stop polling\n        if (instance.sessionId) {\n          sessionManager.updateStatus(\n            instance.sessionId,\n            \"error\",\n            `Event forwarding stopped after ${MAX_CONSECUTIVE_ERRORS} consecutive errors: ${errMsg}`,\n          );\n        }\n        active = false;\n        return;\n      }\n\n      // Apply exponential backoff: base * 2^(errors-1), capped at max\n      currentBackoff = Math.min(BASE_BACKOFF_MS * 2 ** (consecutiveErrors - 1), MAX_BACKOFF_MS);\n\n      // Record transient error but continue with backoff\n      if (instance.sessionId && consecutiveErrors === 1) {\n        // Only log on first error to avoid spam\n        sessionManager.updateStatus(instance.sessionId, \"error\", errMsg);\n      }\n    }\n\n    // Schedule next poll if still active (with potentially increased backoff)\n    if (active) {\n      pollTimer = setTimeout(poll, currentBackoff);\n    }\n  };\n\n  // Start polling\n  pollTimer = setTimeout(poll, pollIntervalMs);\n\n  return {\n    stop: () => {\n      active = false;\n      if (pollTimer) {\n        clearTimeout(pollTimer);\n        pollTimer = undefined;\n      }\n    },\n    isActive: () => active,\n    setTurboMode: (enabled: boolean) => {\n      turboMode = enabled;\n      // If enabling turbo mode and we have a pending poll, reschedule it faster\n      if (enabled && active && pollTimer) {\n        clearTimeout(pollTimer);\n        pollTimer = setTimeout(poll, TURBO_POLL_INTERVAL_MS);\n      }\n    },\n  };\n}\n\n/**\n * Process a message from a worker session and emit appropriate events.\n */\nasync function processMessage(\n  msg: SessionMessage,\n  instance: WorkerInstance,\n  sessionManager: WorkerSessionManager,\n  _communication: CommunicationService,\n  events: WorkerForwardEvent[],\n): Promise<void> {\n  const info = msg?.info;\n  const parts = Array.isArray(msg?.parts) ? msg.parts : [];\n  const role = info?.role;\n  const msgId = info?.id;\n\n  if (!msgId) return;\n\n  // Determine event type based on message content\n  for (const part of parts) {\n    if (!asRecord(part)) continue;\n    const partType = typeof part.type === \"string\" ? part.type : undefined;\n    const typedPart = part as MessagePart;\n\n    // Tool events\n    if (partType === \"tool-invocation\" && events.includes(\"tool\")) {\n      const toolName = typedPart.toolInvocation?.toolName ?? \"unknown\";\n      sessionManager.recordActivity(instance.sessionId!, {\n        type: \"tool\",\n        summary: `Tool: ${toolName}`,\n        details: {\n          toolName,\n          args: typedPart.toolInvocation?.args,\n          status: typedPart.toolInvocation?.state,\n        },\n      });\n      instance.toolCount = (instance.toolCount ?? 0) + 1;\n    }\n\n    // Text message events\n    if (partType === \"text\" && events.includes(\"message\")) {\n      const text = typedPart.text ?? \"\";\n      const preview = text.slice(0, 100) + (text.length > 100 ? \"...\" : \"\");\n      sessionManager.recordActivity(instance.sessionId!, {\n        type: \"message\",\n        summary: `${role === \"user\" ? \"User\" : \"Assistant\"}: ${preview}`,\n        details: { role, text },\n      });\n    }\n\n    // Error events\n    if (partType === \"error\" && events.includes(\"error\")) {\n      const error = typedPart.error ?? \"Unknown error\";\n      sessionManager.recordActivity(instance.sessionId!, {\n        type: \"error\",\n        summary: `Error: ${error}`,\n        details: { error },\n      });\n      sessionManager.updateStatus(instance.sessionId!, \"error\", String(error));\n    }\n\n    // Progress/thinking events\n    if (partType === \"reasoning\" && events.includes(\"progress\")) {\n      sessionManager.recordActivity(instance.sessionId!, {\n        type: \"progress\",\n        summary: \"Thinking...\",\n        details: { content: typedPart.reasoning?.content },\n      });\n    }\n  }\n\n  // Check for completion\n  if (role === \"assistant\" && events.includes(\"complete\")) {\n    const hasToolPending = parts.some((p) => {\n      if (!asRecord(p)) return false;\n      const typedPart = p as MessagePart;\n      return typedPart.type === \"tool-invocation\" && typedPart.toolInvocation?.state === \"pending\";\n    });\n    if (!hasToolPending) {\n      sessionManager.recordActivity(instance.sessionId!, {\n        type: \"complete\",\n        summary: \"Response complete\",\n        details: { messageId: msgId },\n      });\n    }\n  }\n}\n\n/**\n * Stop event forwarding for a worker instance.\n */\nexport function stopEventForwarding(instance: WorkerInstance): void {\n  if (instance.eventForwardingHandle) {\n    instance.eventForwardingHandle.stop();\n    instance.eventForwardingHandle = undefined;\n  }\n}\n"
  },
  {
    "path": "workers/index.ts",
    "content": "export type { EventForwardingConfig, EventForwardingHandle } from \"./event-forwarding\";\nexport { startEventForwarding, stopEventForwarding } from \"./event-forwarding\";\nexport type { WorkerManager, WorkerManagerConfig, WorkerManagerDeps } from \"./manager\";\nexport { createWorkerManager } from \"./manager\";\nexport { builtInProfiles, getAllProfiles, getProfile } from \"./profiles\";\nexport { createSessionManager, WorkerSessionManager } from \"./session-manager\";\nexport type { SessionActivity, SessionManagerEvent, TrackedSession } from \"./session-manager-types\";\n"
  },
  {
    "path": "workers/jobs.ts",
    "content": "import { randomUUID } from \"node:crypto\";\n\nexport type WorkerJobStatus = \"running\" | \"succeeded\" | \"failed\" | \"canceled\";\n\nexport type WorkerJobReport = {\n  summary?: string;\n  details?: string;\n  issues?: string[];\n  notes?: string;\n};\n\nexport type WorkerJob = {\n  id: string;\n  workerId: string;\n  message: string;\n  sessionId?: string;\n  requestedBy?: string;\n  status: WorkerJobStatus;\n  startedAt: number;\n  finishedAt?: number;\n  durationMs?: number;\n  responseText?: string;\n  error?: string;\n  report?: WorkerJobReport;\n};\n\nconst MAX_JOBS = 200;\nconst MAX_JOB_AGE_MS = 24 * 60 * 60 * 1000;\n\nexport class WorkerJobRegistry {\n  private jobs = new Map<string, WorkerJob>();\n  private waiters = new Map<string, Set<(job: WorkerJob) => void>>();\n\n  // biome-ignore lint/complexity/noUselessConstructor: coverage needs explicit constructor.\n  constructor() {\n    // Explicit constructor keeps coverage tooling from missing instantiation.\n  }\n\n  create(input: { workerId: string; message: string; sessionId?: string; requestedBy?: string }): WorkerJob {\n    const id = randomUUID();\n    const job: WorkerJob = {\n      id,\n      workerId: input.workerId,\n      message: input.message,\n      ...(input.sessionId ? { sessionId: input.sessionId } : {}),\n      ...(input.requestedBy ? { requestedBy: input.requestedBy } : {}),\n      status: \"running\",\n      startedAt: Date.now(),\n    };\n    this.jobs.set(id, job);\n    this.prune();\n    return job;\n  }\n\n  get(id: string): WorkerJob | undefined {\n    return this.jobs.get(id);\n  }\n\n  list(options?: { workerId?: string; limit?: number }): WorkerJob[] {\n    const limit = Math.max(1, options?.limit ?? 50);\n    const items: WorkerJob[] = [];\n    for (const job of this.jobs.values()) {\n      if (options?.workerId && job.workerId !== options.workerId) continue;\n      items.push(job);\n    }\n\n    for (let i = 1; i < items.length; i += 1) {\n      const current = items[i];\n      let j = i - 1;\n      while (j >= 0 && items[j].startedAt < current.startedAt) {\n        items[j + 1] = items[j];\n        j -= 1;\n      }\n      items[j + 1] = current;\n    }\n\n    return items.length > limit ? items.slice(0, limit) : items;\n  }\n\n  setResult(id: string, input: { responseText: string; report?: WorkerJobReport }): void {\n    const job = this.jobs.get(id);\n    if (!job || job.status !== \"running\") return;\n    job.status = \"succeeded\";\n    job.responseText = input.responseText;\n    job.report = input.report;\n    job.finishedAt = Date.now();\n    job.durationMs = job.finishedAt - job.startedAt;\n    this.notify(id, job);\n    this.prune();\n  }\n\n  setError(id: string, input: { error: string; report?: WorkerJobReport }): void {\n    const job = this.jobs.get(id);\n    if (!job || job.status !== \"running\") return;\n    job.status = \"failed\";\n    job.error = input.error;\n    job.report = input.report;\n    job.finishedAt = Date.now();\n    job.durationMs = job.finishedAt - job.startedAt;\n    this.notify(id, job);\n    this.prune();\n  }\n\n  attachReport(id: string, report: WorkerJobReport): void {\n    const job = this.jobs.get(id);\n    if (!job) return;\n    job.report = { ...(job.report ?? {}), ...report };\n    this.prune();\n  }\n\n  await(id: string, options?: { timeoutMs?: number }): Promise<WorkerJob> {\n    const existing = this.jobs.get(id);\n    if (!existing) return Promise.reject(new Error(`Unknown job \"${id}\"`));\n    if (existing.status !== \"running\") return Promise.resolve(existing);\n\n    const timeoutMs = options?.timeoutMs ?? 600_000;\n    const { promise, resolve, reject } = Promise.withResolvers<WorkerJob>();\n    /* c8 ignore next */\n    const timer = setTimeout(() => {\n      this.offWaiter(id, onDone);\n      reject(new Error(`Timed out waiting for job \"${id}\" after ${timeoutMs}ms`));\n    }, timeoutMs);\n    const onDone = (job: WorkerJob) => {\n      clearTimeout(timer);\n      resolve(job);\n    };\n    this.onWaiter(id, onDone);\n    return promise;\n  }\n\n  private onWaiter(id: string, cb: (job: WorkerJob) => void) {\n    const set = this.waiters.get(id) ?? new Set();\n    set.add(cb);\n    this.waiters.set(id, set);\n  }\n\n  private offWaiter(id: string, cb: (job: WorkerJob) => void) {\n    const set = this.waiters.get(id);\n    if (!set) return;\n    set.delete(cb);\n    if (set.size === 0) this.waiters.delete(id);\n  }\n\n  private notify(id: string, job: WorkerJob) {\n    const set = this.waiters.get(id);\n    if (!set) return;\n    this.waiters.delete(id);\n    for (const cb of set) {\n      cb(job);\n    }\n  }\n\n  private prune() {\n    const now = Date.now();\n    for (const [id, job] of this.jobs) {\n      if (job.status === \"running\") continue;\n      const ageMs = now - (job.finishedAt ?? job.startedAt);\n      if (ageMs <= MAX_JOB_AGE_MS) continue;\n      if (this.waiters.has(id)) continue;\n      this.jobs.delete(id);\n    }\n\n    if (this.jobs.size <= MAX_JOBS) return;\n    for (const [id, job] of this.jobs) {\n      if (this.jobs.size <= MAX_JOBS) break;\n      if (job.status === \"running\") continue;\n      if (this.waiters.has(id)) continue;\n      this.jobs.delete(id);\n    }\n  }\n}\n"
  },
  {
    "path": "workers/manager.ts",
    "content": "import type { ApiService } from \"../api\";\nimport type { CommunicationService } from \"../communication\";\nimport type { DatabaseService } from \"../db\";\nimport type { MemoryService } from \"../memory\";\nimport type { Factory, OrchestratorConfig, ServiceLifecycle, WorkerInstance, WorkerProfile } from \"../types\";\nimport { type WorkerJob, WorkerJobRegistry } from \"./jobs\";\nimport { killAllTrackedWorkers, trackWorkerPid, untrackWorkerPid } from \"./pid-tracker\";\nimport { WorkerRegistry } from \"./registry\";\nimport { sendWorkerMessage, type WorkerSendOptions } from \"./send\";\nimport { createSessionManager, type WorkerSessionManager } from \"./session-manager\";\nimport { cleanupWorkerInstance, type SpawnWorkerCallbacks, spawnWorker } from \"./spawn\";\n\nexport type WorkerManagerConfig = {\n  basePort: number;\n  timeout: number;\n  directory: string;\n  profiles: Record<string, WorkerProfile>;\n  modelSelection?: OrchestratorConfig[\"modelSelection\"];\n  modelAliases?: OrchestratorConfig[\"modelAliases\"];\n  integrations?: OrchestratorConfig[\"integrations\"];\n};\n\nexport type WorkerManagerDeps = {\n  api?: ApiService;\n  communication?: CommunicationService;\n  memory?: MemoryService;\n  db?: DatabaseService;\n  spawnWorker?: typeof spawnWorker;\n  cleanupWorkerInstance?: typeof cleanupWorkerInstance;\n  sendWorkerMessage?: typeof sendWorkerMessage;\n};\n\nexport type WorkerManager = ServiceLifecycle & {\n  getProfile: (id: string) => WorkerProfile | undefined;\n  listProfiles: () => WorkerProfile[];\n  spawn: (profile: WorkerProfile, options?: { parentSessionId?: string }) => Promise<WorkerInstance>;\n  spawnById: (profileId: string, options?: { parentSessionId?: string }) => Promise<WorkerInstance>;\n  stopWorker: (workerId: string) => Promise<boolean>;\n  send: (\n    workerId: string,\n    message: string,\n    options?: {\n      attachments?: import(\"./prompt\").WorkerAttachment[];\n      timeout?: number;\n      jobId?: string;\n      from?: string;\n      sessionId?: string;\n    },\n  ) => Promise<{ success: boolean; response?: string; error?: string }>;\n  getWorker: (id: string) => WorkerInstance | undefined;\n  listWorkers: () => WorkerInstance[];\n  getSummary: (options?: { maxWorkers?: number }) => string;\n  /** Session manager for tracking worker sessions and activity */\n  sessionManager: WorkerSessionManager;\n  jobs: {\n    create: (input: { workerId: string; message: string; sessionId?: string; requestedBy?: string }) => WorkerJob;\n    get: (id: string) => WorkerJob | undefined;\n    list: (options?: { workerId?: string; limit?: number }) => WorkerJob[];\n    await: (id: string, options?: { timeoutMs?: number }) => Promise<WorkerJob>;\n    attachReport: (id: string, report: WorkerJob[\"report\"]) => void;\n    setResult: (id: string, result: { responseText?: string; error?: string; report?: WorkerJob[\"report\"] }) => void;\n  };\n};\n\nexport const createWorkerManager: Factory<WorkerManagerConfig, WorkerManagerDeps, WorkerManager> = ({\n  config,\n  deps,\n}) => {\n  if (!deps.api) {\n    throw new Error(\"WorkerManager requires api dependency\");\n  }\n  const api = deps.api;\n  const communication = deps.communication;\n  const spawnWorkerFn = deps.spawnWorker ?? spawnWorker;\n  const cleanupWorkerFn = deps.cleanupWorkerInstance ?? cleanupWorkerInstance;\n  const sendWorkerMessageFn = deps.sendWorkerMessage ?? sendWorkerMessage;\n  const registry = new WorkerRegistry();\n  const jobs = new WorkerJobRegistry();\n  const inFlight = new Map<string, Promise<WorkerInstance>>();\n  const db = deps.db;\n\n  // Create session manager for centralized session tracking\n  const sessionManager = createSessionManager({\n    api,\n    communication: communication!,\n  });\n\n  const emitJobEvent = (job: WorkerJob | undefined, status: \"created\" | \"succeeded\" | \"failed\") => {\n    if (!communication || !job) return;\n    communication.emit(\n      \"orchestra.worker.job\",\n      { job, status },\n      { source: \"orchestrator\", workerId: job.workerId, jobId: job.id },\n    );\n  };\n\n  const spawn = async (profile: WorkerProfile, options?: { parentSessionId?: string }) => {\n    const existing = registry.get(profile.id);\n    if (existing) {\n      if (communication) {\n        communication.emit(\n          \"orchestra.worker.reused\",\n          { worker: existing },\n          { source: \"orchestrator\", workerId: existing.profile.id },\n        );\n      }\n      return existing;\n    }\n\n    const inFlightSpawn = inFlight.get(profile.id);\n    if (inFlightSpawn) return await inFlightSpawn;\n\n    const spawnPromise = spawnWorkerFn({\n      api,\n      registry,\n      directory: config.directory,\n      profile,\n      integrations: config.integrations,\n      modelSelection: config.modelSelection,\n      modelAliases: config.modelAliases,\n      timeoutMs: config.timeout,\n      callbacks: spawnCallbacks,\n      sessionManager,\n      communication,\n      parentSessionId: options?.parentSessionId,\n    });\n    inFlight.set(profile.id, spawnPromise);\n    try {\n      const instance = await spawnPromise;\n      // Track the worker PID for cleanup on shutdown\n      if (instance.port) {\n        void trackWorkerPid({\n          pid: process.pid, // We track the parent; actual server PID is internal to SDK\n          workerId: profile.id,\n          port: instance.port,\n        });\n      }\n      return instance;\n    } finally {\n      inFlight.delete(profile.id);\n    }\n  };\n\n  const forwardWorkerEvent = (event: string, instance: WorkerInstance) => {\n    if (!communication) return;\n    const meta = { source: \"orchestrator\" as const, workerId: instance.profile.id };\n    if (event === \"spawn\") {\n      communication.emit(\"orchestra.worker.spawned\", { worker: instance }, meta);\n      communication.emit(\"orchestra.worker.created\", { worker: instance }, meta);\n    }\n    if (event === \"ready\") communication.emit(\"orchestra.worker.ready\", { worker: instance }, meta);\n    if (event === \"busy\") communication.emit(\"orchestra.worker.busy\", { worker: instance }, meta);\n    if (event === \"error\") {\n      communication.emit(\"orchestra.worker.error\", { worker: instance, error: instance.error ?? \"unknown\" }, meta);\n    }\n    if (event === \"stop\") communication.emit(\"orchestra.worker.stopped\", { worker: instance }, meta);\n    if (event === \"update\") communication.emit(\"orchestra.worker.ready\", { worker: instance }, meta);\n  };\n\n  const onSpawn = (instance: WorkerInstance) => forwardWorkerEvent(\"spawn\", instance);\n  const onUpdate = (instance: WorkerInstance) => forwardWorkerEvent(\"update\", instance);\n  const onStop = (instance: WorkerInstance) => forwardWorkerEvent(\"stop\", instance);\n  const onError = (instance: WorkerInstance) => forwardWorkerEvent(\"error\", instance);\n  const onPersist = (instance: WorkerInstance) => persistWorkerState(instance);\n\n  const persistWorkerState = (instance: WorkerInstance) => {\n    if (!db) return;\n    try {\n      const lastResult = instance.lastResult\n        ? { ...instance.lastResult, at: instance.lastResult.at.toISOString() }\n        : null;\n      db.setWorkerState({\n        workerId: instance.profile.id,\n        profileName: instance.profile.name,\n        model: instance.profile.model,\n        serverUrl: instance.serverUrl ?? null,\n        sessionId: instance.sessionId ?? null,\n        uiSessionId: instance.uiSessionId ?? null,\n        status: instance.status,\n        sessionMode: instance.sessionMode ?? null,\n        parentSessionId: instance.parentSessionId ?? null,\n        startedAt: instance.startedAt,\n        lastActivity: instance.lastActivity ?? instance.startedAt,\n        currentTask: instance.currentTask ?? null,\n        lastResult,\n        lastResultAt: instance.lastResult?.at ?? null,\n        lastResultJobId: instance.lastResult?.jobId ?? null,\n        lastResultDurationMs: instance.lastResult?.durationMs ?? null,\n        error: instance.error ?? null,\n        warning: instance.warning ?? null,\n      });\n    } catch {\n      // ignore persistence errors\n    }\n  };\n\n  // Callbacks for model resolution events\n  const spawnCallbacks: SpawnWorkerCallbacks = {\n    onModelResolved: (change) => {\n      if (!communication) return;\n      communication.emit(\n        \"orchestra.model.resolved\",\n        { resolution: change },\n        { source: \"orchestrator\", workerId: change.profileId },\n      );\n    },\n    onModelFallback: (profileId, model, reason) => {\n      if (!communication) return;\n      communication.emit(\n        \"orchestra.model.fallback\",\n        { profileId, model, reason },\n        { source: \"orchestrator\", workerId: profileId },\n      );\n    },\n  };\n\n  const asRecord = (value: unknown): value is Record<string, unknown> => typeof value === \"object\" && value !== null;\n\n  const extractSessionId = (value: unknown): string | undefined => {\n    const data = asRecord(value) && \"data\" in value ? (value as { data?: unknown }).data : value;\n    if (!asRecord(data)) return undefined;\n    return typeof data.id === \"string\" ? data.id : undefined;\n  };\n\n  const formatWorkerResponse = (text: string): string => {\n    // Format long unbroken lines by adding line breaks for readability\n    const lines = text.split(\"\\n\");\n    const formatted: string[] = [];\n\n    for (const line of lines) {\n      if (line.length <= 80) {\n        formatted.push(line);\n        continue;\n      }\n\n      // Break long lines at natural points (periods, colons, semicolons)\n      let remaining = line;\n      while (remaining.length > 80) {\n        let breakAt = -1;\n        // Find a good break point within first 80 chars\n        for (let i = Math.min(79, remaining.length - 1); i >= 50; i--) {\n          const char = remaining[i];\n          if (char === \".\" || char === \":\" || char === \";\") {\n            breakAt = i + 1;\n            break;\n          }\n        }\n        // Fallback: break at comma or space\n        if (breakAt === -1) {\n          for (let i = Math.min(79, remaining.length - 1); i >= 40; i--) {\n            if (remaining[i] === \",\" || remaining[i] === \" \") {\n              breakAt = i + 1;\n              break;\n            }\n          }\n        }\n        // Last resort: hard break\n        if (breakAt === -1) breakAt = 80;\n\n        formatted.push(remaining.slice(0, breakAt).trimEnd());\n        remaining = remaining.slice(breakAt).trimStart();\n      }\n      if (remaining) formatted.push(remaining);\n    }\n\n    return formatted.join(\"\\n\");\n  };\n\n  const buildWorkerSummary = (instance: WorkerInstance, response?: string) => {\n    const profileName = instance.profile.name || instance.profile.id;\n    const body = response?.trim() ?? instance.lastResult?.response?.trim() ?? \"\";\n    const truncated = body.length > 1200 ? `${body.slice(0, 1197).trimEnd()}...` : body;\n    const formattedBody = formatWorkerResponse(truncated);\n\n    const lines: string[] = [\n      ` Worker \"${profileName}\" `,\n      ``,\n    ];\n\n    if (formattedBody) {\n      for (const line of formattedBody.split(\"\\n\")) {\n        lines.push(`  ${line}`);\n      }\n    } else {\n      lines.push(`  (no response)`);\n    }\n\n    lines.push(``);\n    lines.push(``);\n\n    return lines.join(\"\\n\");\n  };\n\n  return {\n    getProfile: (id) => config.profiles[id],\n    listProfiles: () => Object.values(config.profiles),\n    spawn,\n    spawnById: async (profileId, options) => {\n      const profile = config.profiles[profileId];\n      if (!profile) throw new Error(`Unknown worker profile: ${profileId}`);\n      if (profile.enabled === false) {\n        throw new Error(`Worker \"${profileId}\" is disabled by configuration.`);\n      }\n      return await spawn(profile, options);\n    },\n    stopWorker: async (workerId) => {\n      const instance = registry.get(workerId);\n      if (!instance) return false;\n      try {\n        // Clean up session manager and event forwarding\n        cleanupWorkerFn(instance, sessionManager);\n        await instance.shutdown?.();\n        // Remove from PID tracking\n        void untrackWorkerPid(workerId);\n      } finally {\n        instance.status = \"stopped\";\n        registry.updateStatus(workerId, \"stopped\");\n        registry.unregister(workerId);\n      }\n      return true;\n    },\n    send: async (workerId, message, options) => {\n      const sendOptions: WorkerSendOptions = {\n        attachments: options?.attachments,\n        timeoutMs: options?.timeout,\n        jobId: options?.jobId,\n        from: options?.from,\n        parentSessionId: options?.sessionId,\n        communication,\n      };\n      const instance = registry.get(workerId);\n      const memory = deps.memory;\n      const parentSessionId = options?.sessionId;\n\n      if (instance && parentSessionId) {\n        const needsNewUiSession = !instance.uiSessionId || instance.parentSessionId !== parentSessionId;\n        if (needsNewUiSession) {\n          try {\n            const res = await api.session.create({\n              body: { title: `Worker: ${instance.profile.name}`, parentID: parentSessionId },\n            });\n            const uiSessionId = extractSessionId(res);\n            if (uiSessionId) {\n              instance.uiSessionId = uiSessionId;\n              instance.parentSessionId = parentSessionId;\n              persistWorkerState(instance);\n            }\n          } catch {\n            // ignore UI session failures\n          }\n        } else if (!instance.parentSessionId) {\n          instance.parentSessionId = parentSessionId;\n          persistWorkerState(instance);\n        }\n\n        const activeSessionId = instance.uiSessionId ?? instance.sessionId;\n        if (communication && activeSessionId) {\n          communication.emit(\n            \"orchestra.subagent.active\",\n            {\n              subagent: {\n                workerId: instance.profile.id,\n                sessionId: activeSessionId,\n                parentSessionId,\n                profile: { id: instance.profile.id, name: instance.profile.name, model: instance.profile.model },\n                serverUrl: instance.serverUrl,\n                status: instance.status,\n              },\n            },\n            { source: \"orchestrator\", workerId: instance.profile.id, sessionId: activeSessionId },\n          );\n        }\n      }\n      const beforePrompt = async () => {\n        if (!instance || !memory?.enabled) return;\n        if (instance.client && instance.sessionId) {\n          await memory.inject({\n            client: instance.client,\n            sessionId: instance.sessionId,\n            directory: instance.directory,\n          });\n        }\n        if (instance.sessionId) {\n          void memory.record({\n            text: message,\n            sessionId: instance.sessionId,\n            role: \"user\",\n            userId: sendOptions.from ?? \"orchestrator\",\n          });\n        }\n      };\n\n      const result = await sendWorkerMessageFn({\n        registry,\n        workerId,\n        message,\n        options: sendOptions,\n        beforePrompt,\n      });\n\n      if (memory?.enabled && result.success && result.response && instance?.sessionId) {\n        void memory.record({\n          text: result.response,\n          sessionId: instance.sessionId,\n          role: \"assistant\",\n          userId: workerId,\n        });\n      }\n\n      if (communication && instance) {\n        if (result.success) {\n          communication.emit(\n            \"orchestra.worker.completed\",\n            { worker: instance, jobId: options?.jobId, response: result.response ?? \"\" },\n            { source: \"orchestrator\", workerId: instance.profile.id, jobId: options?.jobId },\n          );\n        }\n\n        const activeSessionId = instance.uiSessionId ?? instance.sessionId;\n        if (activeSessionId) {\n          communication.emit(\n            \"orchestra.subagent.closed\",\n            {\n              subagent: {\n                workerId: instance.profile.id,\n                sessionId: activeSessionId,\n                parentSessionId: instance.parentSessionId,\n                profile: { id: instance.profile.id, name: instance.profile.name, model: instance.profile.model },\n                serverUrl: instance.serverUrl,\n                status: instance.status,\n              },\n              result: result.success\n                ? { summary: buildWorkerSummary(instance, result.response) }\n                : { error: result.error ?? \"Worker request failed\" },\n            },\n            { source: \"orchestrator\", workerId: instance.profile.id, sessionId: activeSessionId },\n          );\n        }\n      }\n\n      if (result.success && parentSessionId) {\n        const summary = instance ? buildWorkerSummary(instance, result.response) : `Worker ${workerId} completed.`;\n        void api.session\n          .prompt({\n            path: { id: parentSessionId },\n            body: {\n              noReply: true,\n              parts: [{ type: \"text\", text: summary }],\n            },\n          })\n          .catch(() => {});\n      }\n      return { success: result.success, response: result.response, error: result.error };\n    },\n    getWorker: (id) => registry.get(id),\n    listWorkers: () => registry.list(),\n    getSummary: (options) => registry.getSummary(options),\n    sessionManager,\n    jobs: {\n      create: (input) => {\n        const job = jobs.create(input);\n        emitJobEvent(job, \"created\");\n        return job;\n      },\n      get: (id) => jobs.get(id),\n      list: (options) => jobs.list(options),\n      await: (id, options) => jobs.await(id, options),\n      attachReport: (id, report) => jobs.attachReport(id, report!),\n      setResult: (id, result) => {\n        if (result.error) {\n          jobs.setError(id, { error: result.error, report: result.report });\n          emitJobEvent(jobs.get(id), \"failed\");\n          return;\n        }\n        jobs.setResult(id, { responseText: result.responseText ?? \"\", report: result.report });\n        emitJobEvent(jobs.get(id), \"succeeded\");\n      },\n    },\n    start: async () => {\n      registry.on(\"spawn\", onSpawn);\n      registry.on(\"update\", onUpdate);\n      registry.on(\"stop\", onStop);\n      registry.on(\"error\", onError);\n      registry.on(\"update\", onPersist);\n    },\n    stop: async () => {\n      registry.off(\"spawn\", onSpawn);\n      registry.off(\"update\", onUpdate);\n      registry.off(\"stop\", onStop);\n      registry.off(\"error\", onError);\n      registry.off(\"update\", onPersist);\n      // Kill all tracked workers spawned by this process\n      await killAllTrackedWorkers();\n    },\n    health: async () => ({ ok: true }),\n  };\n};\n"
  },
  {
    "path": "workers/pid-tracker.ts",
    "content": "import { execSync } from \"node:child_process\";\nimport { homedir, tmpdir } from \"node:os\";\nimport { join } from \"node:path\";\n\ntype PidTrackerDeps = {\n  platform?: string;\n  execSync?: typeof execSync;\n  homedir?: typeof homedir;\n  tmpdir?: typeof tmpdir;\n};\n\nconst resolveHomeDir = (deps?: PidTrackerDeps): string => {\n  const platform = deps?.platform ?? process.platform;\n  const homedirFn = deps?.homedir ?? homedir;\n  const tmpdirFn = deps?.tmpdir ?? tmpdir;\n  const fallbackDir = tmpdirFn();\n  if (platform === \"win32\") {\n    return process.env.USERPROFILE || homedirFn() || fallbackDir;\n  }\n  const candidate = process.env.HOME || homedirFn();\n  if (!candidate || candidate === \"/\") return fallbackDir;\n  return candidate;\n};\n\nconst getPidDir = (deps?: PidTrackerDeps): string => join(resolveHomeDir(deps), \".opencode\");\nconst getPidFile = (deps?: PidTrackerDeps): string => join(getPidDir(deps), \"worker-pids.json\");\n\ntype PidEntry = {\n  pid: number;\n  workerId: string;\n  port?: number;\n  createdAt: number;\n  parentPid: number;\n};\n\ntype PidStore = {\n  entries: PidEntry[];\n  updatedAt: number;\n};\n\nasync function ensurePidDir(deps?: PidTrackerDeps): Promise<void> {\n  const dirPath = getPidDir(deps);\n  const dir = Bun.file(dirPath);\n  if (!(await dir.exists())) {\n    await Bun.write(join(dirPath, \".keep\"), \"\");\n  }\n}\n\nasync function readPidStore(deps?: PidTrackerDeps): Promise<PidStore> {\n  try {\n    const file = Bun.file(getPidFile(deps));\n    if (await file.exists()) {\n      const data = await file.json();\n      if (data && Array.isArray(data.entries)) {\n        return data as PidStore;\n      }\n    }\n  } catch {\n    // Corrupted file, start fresh\n  }\n  return { entries: [], updatedAt: Date.now() };\n}\n\nasync function writePidStore(store: PidStore, deps?: PidTrackerDeps): Promise<void> {\n  await ensurePidDir(deps);\n  store.updatedAt = Date.now();\n  await Bun.write(getPidFile(deps), JSON.stringify(store, null, 2));\n}\n\n/**\n * Track a spawned worker's PID for cleanup.\n */\nexport async function trackWorkerPid(input: {\n  pid: number;\n  workerId: string;\n  port?: number;\n  deps?: PidTrackerDeps;\n}): Promise<void> {\n  const store = await readPidStore(input.deps);\n\n  // Remove any existing entry for this worker (in case of restart)\n  store.entries = store.entries.filter((e) => e.workerId !== input.workerId);\n\n  store.entries.push({\n    pid: input.pid,\n    workerId: input.workerId,\n    port: input.port,\n    createdAt: Date.now(),\n    parentPid: process.pid,\n  });\n\n  await writePidStore(store, input.deps);\n}\n\n/**\n * Remove a worker from PID tracking (called on graceful shutdown).\n */\nexport async function untrackWorkerPid(workerId: string, deps?: PidTrackerDeps): Promise<void> {\n  const store = await readPidStore(deps);\n  store.entries = store.entries.filter((e) => e.workerId !== workerId);\n  await writePidStore(store, deps);\n}\n\n/**\n * Check if a process is still running.\n */\nfunction isProcessAlive(pid: number): boolean {\n  try {\n    process.kill(pid, 0);\n    return true;\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Check if a port is in use (indicates worker server is running).\n * More reliable than PID checking since we track orchestrator PID, not worker PID.\n */\nfunction isPortInUse(port: number, deps?: PidTrackerDeps): boolean {\n  if (!port || port === 0) return false;\n  try {\n    const platform = deps?.platform ?? process.platform;\n    const exec = deps?.execSync ?? execSync;\n    if (platform === \"win32\") {\n      const result = exec(`netstat -ano | findstr :${port}`, {\n        encoding: \"utf8\",\n        stdio: [\"pipe\", \"pipe\", \"pipe\"],\n      });\n      return result.includes(`:${port}`);\n    } else {\n      // Unix-like: use lsof which is more reliable\n      const result = exec(`lsof -i :${port} -t 2>/dev/null || true`, {\n        encoding: \"utf8\",\n        stdio: [\"pipe\", \"pipe\", \"pipe\"],\n      });\n      return result.trim().length > 0;\n    }\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Kill a process gracefully, then forcefully if needed.\n */\nasync function killProcess(pid: number): Promise<boolean> {\n  try {\n    // Try SIGTERM first\n    process.kill(pid, \"SIGTERM\");\n\n    // Wait up to 2 seconds for graceful shutdown\n    for (let i = 0; i < 20; i++) {\n      await new Promise((r) => setTimeout(r, 100));\n      if (!isProcessAlive(pid)) return true;\n    }\n\n    // Force kill if still alive\n    process.kill(pid, \"SIGKILL\");\n    return true;\n  } catch {\n    // Process already dead or permission denied\n    return false;\n  }\n}\n\n/**\n * Clean up stale worker process entries on startup.\n * IMPORTANT: This only removes stale ENTRIES from tracking, it does NOT kill processes.\n * We cannot safely kill processes by port because another application (like Chrome)\n * may have taken over the port since the worker was last running.\n */\nexport async function cleanupStaleWorkers(options?: {\n  maxAgeMs?: number;\n  dryRun?: boolean;\n  deps?: PidTrackerDeps;\n}): Promise<{ killed: string[]; removed: string[] }> {\n  const maxAgeMs = options?.maxAgeMs ?? 24 * 60 * 60 * 1000; // 24 hours default\n  const dryRun = options?.dryRun ?? false;\n  const deps = options?.deps;\n\n  const store = await readPidStore(deps);\n  const removed: string[] = [];\n  const alive: PidEntry[] = [];\n\n  for (const entry of store.entries) {\n    const isStale = Date.now() - entry.createdAt > maxAgeMs;\n    const parentDead = !isProcessAlive(entry.parentPid);\n    const portActive = entry.port ? isPortInUse(entry.port, deps) : false;\n\n    if (!portActive && !isProcessAlive(entry.pid)) {\n      // Neither port nor process active, safe to remove from tracking\n      removed.push(entry.workerId);\n      continue;\n    }\n\n    if (isStale || parentDead) {\n      // Entry is stale/orphaned - remove from tracking but DO NOT kill the process\n      // The port may now be used by a different application (e.g., browser)\n      removed.push(entry.workerId);\n      continue;\n    }\n\n    // Keep tracking this one\n    alive.push(entry);\n  }\n\n  if (!dryRun) {\n    store.entries = alive;\n    await writePidStore(store, deps);\n  }\n\n  // Return empty killed array - we no longer kill processes on cleanup\n  return { killed: [], removed };\n}\n\n/**\n * Kill process(es) listening on a specific port.\n */\n/** @internal */\nexport async function killProcessOnPort(\n  port: number,\n  deps?: PidTrackerDeps,\n  options?: { skipPid?: number },\n): Promise<boolean> {\n  const skipPid = options?.skipPid;\n  try {\n    const platform = deps?.platform ?? process.platform;\n    const exec = deps?.execSync ?? execSync;\n    if (platform === \"win32\") {\n      // Windows: find PID and kill it\n      const result = exec(`netstat -ano | findstr :${port}`, {\n        encoding: \"utf8\",\n        stdio: [\"pipe\", \"pipe\", \"pipe\"],\n      });\n      const pids = new Set<number>();\n      for (const line of result.split(\"\\n\")) {\n        const match = line.match(/\\s+(\\d+)\\s*$/);\n        if (match) pids.add(parseInt(match[1], 10));\n      }\n      let killedAny = false;\n      for (const pid of pids) {\n        if (skipPid && pid === skipPid) continue;\n        await killProcess(pid);\n        killedAny = true;\n      }\n      return killedAny;\n    } else {\n      // Unix: use lsof to find and kill\n      const result = exec(`lsof -i :${port} -t 2>/dev/null || true`, {\n        encoding: \"utf8\",\n        stdio: [\"pipe\", \"pipe\", \"pipe\"],\n      });\n      const pids = result\n        .trim()\n        .split(\"\\n\")\n        .filter(Boolean)\n        .map((p) => parseInt(p, 10));\n      let killedAny = false;\n      for (const pid of pids) {\n        if (Number.isNaN(pid)) continue;\n        if (skipPid && pid === skipPid) continue;\n        await killProcess(pid);\n        killedAny = true;\n      }\n      return killedAny;\n    }\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Kill all tracked workers (called on shutdown).\n */\nexport async function killAllTrackedWorkers(deps?: PidTrackerDeps): Promise<string[]> {\n  const store = await readPidStore(deps);\n  const killed: string[] = [];\n\n  // Only kill workers spawned by this process\n  const myWorkers = store.entries.filter((e) => e.parentPid === process.pid);\n\n  for (const entry of myWorkers) {\n    if (entry.pid === process.pid) {\n      if (entry.port) {\n        const killedPort = await killProcessOnPort(entry.port, deps, { skipPid: process.pid });\n        if (killedPort) killed.push(entry.workerId);\n      }\n      continue;\n    }\n    if (isProcessAlive(entry.pid)) {\n      await killProcess(entry.pid);\n      killed.push(entry.workerId);\n    }\n  }\n\n  // Remove our workers from the store\n  store.entries = store.entries.filter((e) => e.parentPid !== process.pid);\n  await writePidStore(store, deps);\n\n  return killed;\n}\n\n/**\n * Get all currently tracked workers.\n */\nexport async function getTrackedWorkers(deps?: PidTrackerDeps): Promise<PidEntry[]> {\n  const store = await readPidStore(deps);\n  return store.entries;\n}\n\n/**\n * Clear all PID tracking (for testing or manual cleanup).\n */\nexport async function clearPidTracking(deps?: PidTrackerDeps): Promise<void> {\n  await writePidStore({ entries: [], updatedAt: Date.now() }, deps);\n}\n"
  },
  {
    "path": "workers/profiles/index.ts",
    "content": "/**\n * Worker Profile Factory\n *\n * Profiles (skills) are loaded from:\n * 1. .opencode/skill/{id}/SKILL.md (primary source)\n * 2. orchestrator.json profiles[] (optional overrides)\n *\n * No hardcoded profiles - everything is defined in SKILL.md files.\n */\n\nimport { resolveProfileInheritance, type WorkerProfileDefinition } from \"../../config/profile-inheritance\";\nimport { skillToProfile } from \"../../skills/convert\";\nimport { loadAllSkills } from \"../../skills/loader\";\nimport type { WorkerProfile } from \"../../types\";\n\n/**\n * Get all profiles from skills directory.\n * This is the primary source of truth for worker profiles.\n */\ntype ProfileLoaderDeps = {\n  loadAllSkills?: typeof loadAllSkills;\n};\n\nexport async function loadSubagentProfiles(\n  projectDir?: string,\n  deps?: ProfileLoaderDeps,\n): Promise<Record<string, WorkerProfile>> {\n  const loader = deps?.loadAllSkills ?? loadAllSkills;\n  const skills = await loader(projectDir);\n  const profiles: Record<string, WorkerProfile> = {};\n\n  for (const [id, skill] of skills) {\n    profiles[id] = skillToProfile(skill);\n  }\n\n  return profiles;\n}\n\n/**\n * Apply config overrides from orchestrator.json profiles[].\n * This allows runtime customization without editing SKILL.md files.\n */\nexport function applyProfileOverrides(\n  baseProfiles: Record<string, WorkerProfile>,\n  overrides?: Array<Partial<WorkerProfile> & { id: string }>,\n): Record<string, WorkerProfile> {\n  if (!overrides || overrides.length === 0) return baseProfiles;\n\n  const result = { ...baseProfiles };\n\n  for (const override of overrides) {\n    if (!override.id) continue;\n\n    const base = result[override.id];\n    if (base) {\n      // Merge override into existing profile\n      result[override.id] = {\n        ...base,\n        ...override,\n        // Preserve nested objects with merge\n        tools: { ...base.tools, ...override.tools },\n        permissions: override.permissions ?? base.permissions,\n        tags: override.tags ?? base.tags,\n      };\n    } else {\n      // Create new profile from override (must have required fields)\n      if (override.name && override.model && override.purpose && override.whenToUse) {\n        result[override.id] = override as WorkerProfile;\n      }\n    }\n  }\n\n  return result;\n}\n\n/**\n * Get a single profile by ID.\n */\nexport function getProfile(id: string, profiles: Record<string, WorkerProfile>): WorkerProfile | undefined {\n  return profiles[id];\n}\n\n/**\n * Validate that a profile has all required fields.\n */\nexport function validateProfile(profile: Partial<WorkerProfile>): string[] {\n  const errors: string[] = [];\n\n  if (!profile.id) errors.push(\"id is required\");\n  if (!profile.name) errors.push(\"name is required\");\n  if (!profile.model) errors.push(\"model is required\");\n  if (!profile.purpose) errors.push(\"purpose is required\");\n  if (!profile.whenToUse) errors.push(\"whenToUse is required\");\n\n  return errors;\n}\n\n/**\n * Main entry point: Load all profiles with inheritance resolution.\n *\n * @param projectDir - Project directory for project-scoped skills\n * @param configOverrides - Optional overrides from orchestrator.json profiles[]\n */\nexport async function getAllProfiles(\n  projectDir?: string,\n  configOverrides?: Array<Partial<WorkerProfile> & { id: string }>,\n  deps?: ProfileLoaderDeps,\n): Promise<Record<string, WorkerProfile>> {\n  // 1. Load base profiles from skills\n  const baseProfiles = await loadSubagentProfiles(projectDir, deps);\n\n  // 2. Apply config overrides\n  const withOverrides = applyProfileOverrides(baseProfiles, configOverrides);\n\n  // 3. Resolve inheritance (extends/compose)\n  const definitions: Record<string, WorkerProfileDefinition> = {};\n  for (const [id, profile] of Object.entries(withOverrides)) {\n    if (profile.extends || profile.compose) {\n      definitions[id] = profile;\n    }\n  }\n\n  if (Object.keys(definitions).length === 0) {\n    return withOverrides;\n  }\n\n  // Separate base profiles (no inheritance) from those needing resolution\n  const builtIns: Record<string, WorkerProfile> = {};\n  for (const [id, profile] of Object.entries(withOverrides)) {\n    if (!profile.extends && !profile.compose) {\n      builtIns[id] = profile;\n    }\n  }\n\n  return resolveProfileInheritance({ builtIns, definitions });\n}\n\n/**\n * List available profile IDs.\n */\nexport async function listProfileIds(projectDir?: string, deps?: ProfileLoaderDeps): Promise<string[]> {\n  const profiles = await loadSubagentProfiles(projectDir, deps);\n  return Object.keys(profiles).sort();\n}\n\n// =============================================================================\n// Legacy compatibility exports (deprecated, will be removed)\n// =============================================================================\n\n/** @deprecated Use getAllProfiles() instead */\nexport const builtInProfiles: Record<string, WorkerProfile> = {};\n\n/** @deprecated Use getAllProfiles() instead */\nexport async function getAllProfilesWithSkills(\n  projectDir?: string,\n  _baseProfiles?: Record<string, WorkerProfile>,\n): Promise<Record<string, WorkerProfile>> {\n  return getAllProfiles(projectDir);\n}\n\n/** @deprecated Use applyProfileOverrides() instead */\nexport function mergeProfile(baseId: string, _: Partial<WorkerProfile>): WorkerProfile {\n  throw new Error(\n    `mergeProfile() is deprecated. Profiles are now loaded from .opencode/skill/. ` +\n      `Create a SKILL.md file for \"${baseId}\" or use orchestrator.json profiles[] for overrides.`,\n  );\n}\n"
  },
  {
    "path": "workers/prompt.ts",
    "content": "import { basename, extname, resolve as resolvePath } from \"node:path\";\nimport { pathToFileURL } from \"node:url\";\nimport type { FilePartInput, TextPartInput } from \"@opencode-ai/sdk\";\n\nexport type WorkerAttachment = {\n  type: \"image\" | \"file\";\n  path?: string;\n  base64?: string;\n  mimeType?: string;\n};\n\nfunction inferImageMimeType(filePath: string): string {\n  const ext = extname(filePath).toLowerCase();\n  if (ext === \".jpg\" || ext === \".jpeg\") return \"image/jpeg\";\n  if (ext === \".webp\") return \"image/webp\";\n  if (ext === \".gif\") return \"image/gif\";\n  return \"image/png\";\n}\n\nexport function normalizeBase64Image(input: string): string {\n  // Allow passing data URLs.\n  const match = input.match(/^data:.*?;base64,(.*)$/);\n  return match ? match[1] : input;\n}\n\ntype PromptPart = TextPartInput | FilePartInput;\n\nexport async function buildPromptParts(input: {\n  message: string;\n  attachments?: WorkerAttachment[];\n}): Promise<PromptPart[]> {\n  const parts: PromptPart[] = [{ type: \"text\", text: input.message }];\n\n  if (!input.attachments || input.attachments.length === 0) return parts;\n\n  for (const attachment of input.attachments) {\n    if (attachment.type !== \"image\") continue;\n\n    const mimeType = attachment.mimeType ?? (attachment.path ? inferImageMimeType(attachment.path) : \"image/png\");\n    const filename = attachment.path ? basename(attachment.path) : undefined;\n\n    // OpenCode message inputs accept images as FilePartInput:\n    // { type: \"file\", mime, url: \"file://...\" } or a data: URL.\n    if (attachment.path) {\n      const url = attachment.path.startsWith(\"file://\")\n        ? attachment.path\n        : pathToFileURL(resolvePath(attachment.path)).toString();\n      parts.push({ type: \"file\", mime: mimeType, url, ...(filename ? { filename } : {}) });\n      continue;\n    }\n\n    const base64 = attachment.base64 ? normalizeBase64Image(attachment.base64) : undefined;\n    if (!base64) continue;\n    parts.push({\n      type: \"file\",\n      mime: mimeType,\n      url: `data:${mimeType};base64,${base64}`,\n      ...(filename ? { filename } : {}),\n    });\n  }\n\n  return parts;\n}\n\nexport function extractTextFromPromptResponse(data: unknown): { text: string; debug?: string } {\n  const asObj = (v: unknown): v is Record<string, unknown> => typeof v === \"object\" && v !== null;\n  const readParts = (v: unknown): Record<string, unknown>[] | undefined => {\n    if (!asObj(v)) return undefined;\n    const parts = v.parts;\n    if (Array.isArray(parts)) return parts.filter(asObj);\n    return undefined;\n  };\n\n  const message = asObj(data) ? data.message : undefined;\n  const parts = readParts(data) ?? readParts(message) ?? [];\n  if (!Array.isArray(parts) || parts.length === 0) return { text: \"\", debug: \"no_parts\" };\n\n  let text = \"\";\n  let reasoning = \"\";\n  const partTypes: string[] = [];\n  for (const part of parts) {\n    if (!asObj(part)) continue;\n    const type = typeof part.type === \"string\" ? part.type : \"unknown\";\n    partTypes.push(type);\n    if (type === \"text\" && typeof part.text === \"string\") text += part.text;\n    if (type === \"reasoning\" && typeof part.text === \"string\") reasoning += part.text;\n  }\n\n  const output = text.length > 0 ? text : reasoning;\n  const debug = output.length > 0 ? undefined : `parts:${[...new Set(partTypes)].join(\",\")}`;\n  return { text: output, debug };\n}\n"
  },
  {
    "path": "workers/registry.ts",
    "content": "import type { WorkerInstance, WorkerStatus } from \"../types\";\n\nexport type WorkerRegistryEvent =\n  | \"starting\"\n  | \"spawn\"\n  | \"ready\"\n  | \"busy\"\n  | \"error\"\n  | \"stop\"\n  | \"update\"\n  | \"dead\"\n  | \"stopped\";\nexport type WorkerRegistryCallback = (instance: WorkerInstance) => void;\n\nexport class WorkerRegistry {\n  private workers = new Map<string, WorkerInstance>();\n  private listeners = new Map<WorkerRegistryEvent, Set<WorkerRegistryCallback>>();\n\n  // biome-ignore lint/complexity/noUselessConstructor: coverage needs explicit constructor.\n  constructor() {\n    // Explicit constructor keeps coverage tooling from missing instantiation.\n  }\n\n  register(instance: WorkerInstance): void {\n    this.workers.set(instance.profile.id, instance);\n    this.emit(\"spawn\", instance);\n    this.emit(\"update\", instance);\n  }\n\n  unregister(id: string): void {\n    const instance = this.workers.get(id);\n    if (!instance) return;\n    this.workers.delete(id);\n    this.emit(\"stop\", instance);\n  }\n\n  get(id: string): WorkerInstance | undefined {\n    return this.workers.get(id);\n  }\n\n  list(): WorkerInstance[] {\n    return Array.from(this.workers.values());\n  }\n\n  getWorkersByStatus(status: WorkerStatus): WorkerInstance[] {\n    const result: WorkerInstance[] = [];\n    for (const worker of this.workers.values()) {\n      if (worker.status === status) result.push(worker);\n    }\n    return result;\n  }\n\n  getWorkersByCapability(capability: string): WorkerInstance[] {\n    const result: WorkerInstance[] = [];\n    for (const worker of this.workers.values()) {\n      if (capability === \"vision\" && worker.profile.supportsVision) {\n        result.push(worker);\n        continue;\n      }\n      if (capability === \"web\" && worker.profile.supportsWeb) {\n        result.push(worker);\n      }\n    }\n    return result;\n  }\n\n  getVisionWorkers(): WorkerInstance[] {\n    return this.getWorkersByCapability(\"vision\");\n  }\n\n  getActiveWorkers(): WorkerInstance[] {\n    const result: WorkerInstance[] = [];\n    for (const worker of this.workers.values()) {\n      if (worker.status === \"ready\" || worker.status === \"busy\") result.push(worker);\n    }\n    return result;\n  }\n\n  updateStatus(id: string, status: WorkerStatus, error?: string): void {\n    const instance = this.workers.get(id);\n    if (!instance) return;\n    instance.status = status;\n    if (error) instance.error = error;\n    this.emit(status === \"error\" ? \"error\" : status, instance);\n    this.emit(\"update\", instance);\n  }\n\n  waitForStatus(workerId: string, status: WorkerStatus, timeoutMs: number): Promise<boolean> {\n    const existing = this.get(workerId);\n    if (existing?.status === status) return Promise.resolve(true);\n\n    const { promise, resolve } = Promise.withResolvers<boolean>();\n    /* c8 ignore next */\n    const timeout = setTimeout(() => {\n      this.off(\"update\", onUpdate);\n      resolve(false);\n    }, timeoutMs);\n\n    const onUpdate = (instance: WorkerInstance) => {\n      if (instance.profile.id !== workerId) return;\n      if (instance.status !== status) return;\n      clearTimeout(timeout);\n      this.off(\"update\", onUpdate);\n      resolve(true);\n    };\n\n    this.on(\"update\", onUpdate);\n    return promise;\n  }\n\n  on(event: WorkerRegistryEvent, callback: WorkerRegistryCallback): () => void {\n    const set = this.listeners.get(event) ?? new Set();\n    set.add(callback);\n    this.listeners.set(event, set);\n    return () => this.off(event, callback);\n  }\n\n  off(event: WorkerRegistryEvent, callback: WorkerRegistryCallback): void {\n    const set = this.listeners.get(event);\n    if (!set) return;\n    set.delete(callback);\n    if (set.size === 0) this.listeners.delete(event);\n  }\n\n  toJSON(): Array<Record<string, unknown>> {\n    const rows: Array<Record<string, unknown>> = [];\n    for (const w of this.workers.values()) {\n      rows.push({\n        id: w.profile.id,\n        name: w.profile.name,\n        model: w.profile.model,\n        modelResolution: w.modelResolution,\n        purpose: w.profile.purpose,\n        whenToUse: w.profile.whenToUse,\n        profile: w.profile,\n        status: w.status,\n        port: w.port,\n        pid: w.pid,\n        serverUrl: w.serverUrl,\n        sessionId: w.sessionId,\n        uiSessionId: w.uiSessionId,\n        supportsVision: Boolean(w.profile.supportsVision),\n        supportsWeb: Boolean(w.profile.supportsWeb),\n        lastActivity: w.lastActivity?.toISOString(),\n        currentTask: w.currentTask,\n        error: w.error,\n        warning: w.warning,\n        lastResult: w.lastResult\n          ? {\n              ...w.lastResult,\n              at: w.lastResult.at.toISOString(),\n            }\n          : undefined,\n      });\n    }\n    return rows;\n  }\n\n  getSummary(options: { maxWorkers?: number } = {}): string {\n    const maxWorkers = options.maxWorkers ?? 12;\n    const workers = Array.from(this.workers.values()).slice(0, Math.max(0, maxWorkers));\n    if (workers.length === 0) return \"No workers currently registered.\";\n\n    const total = this.workers.size;\n    const lines = [\"## Available Workers\", \"\"];\n    if (total > workers.length) lines.push(`(showing ${workers.length} of ${total})`, \"\");\n    for (const w of workers) {\n      lines.push(`- ${w.profile.id} (${w.profile.name})  ${w.status}`);\n    }\n    lines.push(\"\", \"Use ask_worker({ workerId: <id>, message: <text> }) to message a worker.\");\n    return lines.join(\"\\n\");\n  }\n\n  private emit(event: WorkerRegistryEvent, instance: WorkerInstance): void {\n    const set = this.listeners.get(event);\n    if (!set) return;\n    for (const cb of set) {\n      cb(instance);\n    }\n  }\n}\n"
  },
  {
    "path": "workers/send.ts",
    "content": "import type { CommunicationService } from \"../communication\";\nimport type { WorkerInstance } from \"../types\";\nimport { prepareWorkerAttachments } from \"./attachments\";\nimport type { WorkerAttachment } from \"./prompt\";\nimport { buildPromptParts, extractTextFromPromptResponse } from \"./prompt\";\nimport type { WorkerRegistry } from \"./registry\";\n\nexport type WorkerSendOptions = {\n  attachments?: WorkerAttachment[];\n  timeoutMs?: number;\n  jobId?: string;\n  from?: string;\n  parentSessionId?: string;\n  /** Optional communication service to emit streaming events */\n  communication?: CommunicationService;\n  /** Enable turbo polling for real-time visibility (default: true) */\n  turboPolling?: boolean;\n};\n\nexport type WorkerSendResult = {\n  success: boolean;\n  response?: string;\n  error?: string;\n  durationMs?: number;\n};\n\nconst DEFAULT_TIMEOUT_MS = 600_000;\nconst READY_WAIT_CAP_MS = 5 * 60_000;\n\ntype WorkerClient = NonNullable<WorkerInstance[\"client\"]>;\ntype SessionPromptArgs = Parameters<WorkerClient[\"session\"][\"prompt\"]>[0] & { throwOnError?: false };\n\nconst asRecord = (value: unknown): value is Record<string, unknown> => typeof value === \"object\" && value !== null;\n\nconst extractSdkError = (value: unknown): unknown | undefined => {\n  if (asRecord(value) && \"error\" in value) return (value as { error?: unknown }).error;\n  return undefined;\n};\n\nconst extractSdkData = (value: unknown): unknown => {\n  if (asRecord(value) && \"data\" in value) return (value as { data?: unknown }).data ?? value;\n  return value;\n};\n\nconst extractSdkErrorMessage = (value: unknown): string => {\n  if (value instanceof Error) return value.message;\n  if (typeof value === \"string\") return value;\n  if (asRecord(value)) {\n    const data = value.data;\n    if (asRecord(data) && typeof data.message === \"string\") return data.message;\n    if (typeof value.message === \"string\") return value.message;\n  }\n  try {\n    return JSON.stringify(value);\n  } catch {\n    return String(value);\n  }\n};\n\nasync function withTimeout<T>(promise: Promise<T>, timeoutMs: number, abort?: AbortController): Promise<T> {\n  let timer: ReturnType<typeof setTimeout> | undefined;\n  const timeout = new Promise<never>((_, reject) => {\n    timer = setTimeout(() => {\n      abort?.abort(new Error(\"worker prompt timed out\"));\n      reject(new Error(\"worker prompt timed out\"));\n    }, timeoutMs);\n  });\n\n  return Promise.race([promise, timeout]).finally(() => {\n    if (timer) clearTimeout(timer);\n  }) as Promise<T>;\n}\n\nfunction buildTaskText(message: string, options?: { jobId?: string; from?: string }): string {\n  const sourceFrom = options?.from ?? \"orchestrator\";\n  const jobIdStr = options?.jobId ?? \"none\";\n  const sourceInfo =\n    `<message-source from=\"${sourceFrom}\" jobId=\"${jobIdStr}\">\\n` +\n    `This message was sent by ${sourceFrom === \"orchestrator\" ? \"the orchestrator\" : `worker \"${sourceFrom}\"`}.\n` +\n    `</message-source>\\n\\n`;\n\n  let taskText = sourceInfo + message;\n  if (options?.jobId) {\n    taskText +=\n      `\\n\\n<orchestrator-job id=\"${options.jobId}\">\\n` +\n      `IMPORTANT: Reply with your full answer as plain text.\\n` +\n      `</orchestrator-job>`;\n  } else {\n    taskText +=\n      \"\\n\\n<orchestrator-sync>\\n\" + \"IMPORTANT: Reply with your final answer as plain text.\\n\" + \"</orchestrator-sync>\";\n  }\n\n  return taskText;\n}\n\nexport async function sendWorkerMessage(input: {\n  registry: WorkerRegistry;\n  workerId: string;\n  message: string;\n  options?: WorkerSendOptions;\n  beforePrompt?: (instance: WorkerInstance) => Promise<void>;\n}): Promise<WorkerSendResult> {\n  const instance = input.registry.get(input.workerId);\n  if (!instance) return { success: false, error: `Worker \"${input.workerId}\" not found` };\n\n  if (instance.status === \"error\" || instance.status === \"stopped\") {\n    return { success: false, error: `Worker \"${input.workerId}\" is ${instance.status}` };\n  }\n\n  const timeoutMs = input.options?.timeoutMs ?? DEFAULT_TIMEOUT_MS;\n\n  if (instance.status !== \"ready\") {\n    const waitMs = Math.min(timeoutMs, READY_WAIT_CAP_MS);\n    const ready = await input.registry.waitForStatus(input.workerId, \"ready\", waitMs);\n    if (!ready) {\n      return { success: false, error: `Worker \"${input.workerId}\" did not become ready within ${waitMs}ms` };\n    }\n  }\n\n  if (!instance.client || !instance.sessionId) {\n    return { success: false, error: `Worker \"${input.workerId}\" not properly initialized` };\n  }\n\n  const startedAt = Date.now();\n  input.registry.updateStatus(input.workerId, \"busy\");\n  instance.currentTask = input.message.slice(0, 140);\n\n  let cleanupAttachments: (() => Promise<void>) | undefined;\n  try {\n    if (input.beforePrompt) {\n      try {\n        await input.beforePrompt(instance);\n      } catch (error) {\n        const msg = error instanceof Error ? error.message : String(error);\n        instance.warning = `Pre-prompt hook failed: ${msg}`;\n      }\n    }\n\n    const taskText = buildTaskText(input.message, { jobId: input.options?.jobId, from: input.options?.from });\n\n    const prepared = await prepareWorkerAttachments({\n      attachments: input.options?.attachments,\n      baseDir: instance.directory ?? process.cwd(),\n      workerId: input.workerId,\n    });\n    cleanupAttachments = prepared.cleanup;\n\n    const parts = await buildPromptParts({ message: taskText, attachments: prepared.attachments });\n\n    const abort = new AbortController();\n    const promptArgs: SessionPromptArgs = {\n      path: { id: instance.sessionId },\n      body: { parts },\n      query: { directory: instance.directory ?? process.cwd() },\n      signal: abort.signal,\n      throwOnError: false,\n    };\n\n    const communication = input.options?.communication;\n    const emitStreamChunk = (chunk: string, final = false) => {\n      if (!communication) return;\n      communication.emit(\n        \"orchestra.worker.stream\",\n        {\n          chunk: {\n            workerId: input.workerId,\n            jobId: input.options?.jobId,\n            chunk,\n            timestamp: Date.now(),\n            final,\n          },\n        },\n        { source: \"worker\", workerId: input.workerId, jobId: input.options?.jobId },\n      );\n    };\n\n    // Emit start event\n    emitStreamChunk(\"\", false);\n\n    // Enable turbo mode for real-time visibility during the request\n    const useTurbo = input.options?.turboPolling !== false;\n    if (useTurbo && instance.eventForwardingHandle?.setTurboMode) {\n      instance.eventForwardingHandle.setTurboMode(true);\n    }\n\n    const result = await withTimeout(instance.client.session.prompt(promptArgs), timeoutMs, abort);\n\n    const sdkError = extractSdkError(result);\n    if (sdkError) {\n      const msg = extractSdkErrorMessage(sdkError);\n      instance.warning = `Last request failed: ${msg}`;\n      emitStreamChunk(`Error: ${msg}`, true);\n      throw new Error(msg);\n    }\n\n    const promptData = extractSdkData(result);\n    const extracted = extractTextFromPromptResponse(promptData);\n    const responseText = extracted.text.trim();\n\n    // Emit the full response as a stream chunk (SDK doesn't support true streaming yet)\n    emitStreamChunk(responseText, true);\n\n    // Disable turbo mode after completion\n    if (useTurbo && instance.eventForwardingHandle?.setTurboMode) {\n      instance.eventForwardingHandle.setTurboMode(false);\n    }\n\n    instance.lastResult = {\n      at: new Date(),\n      jobId: input.options?.jobId,\n      response: responseText,\n      durationMs: Date.now() - startedAt,\n    };\n    instance.lastActivity = new Date();\n    input.registry.updateStatus(input.workerId, \"ready\");\n\n    return {\n      success: true,\n      response: responseText,\n      durationMs: Date.now() - startedAt,\n    };\n  } catch (error) {\n    const errorMsg = error instanceof Error ? error.message : String(error);\n    instance.error = errorMsg;\n    input.registry.updateStatus(input.workerId, \"error\", errorMsg);\n    return { success: false, error: errorMsg };\n  } finally {\n    // Always disable turbo mode when done\n    if (instance.eventForwardingHandle?.setTurboMode) {\n      instance.eventForwardingHandle.setTurboMode(false);\n    }\n    try {\n      await cleanupAttachments?.();\n    } catch {\n      // ignore\n    }\n  }\n}\n"
  },
  {
    "path": "workers/session-manager-types.ts",
    "content": "import type { WorkerForwardEvent, WorkerSessionMode } from \"../types/worker\";\n\n/**\n * Represents a tracked worker session with activity data.\n */\nexport interface TrackedSession {\n  /** Worker ID */\n  workerId: string;\n  /** Session ID */\n  sessionId: string;\n  /** Session mode */\n  mode: WorkerSessionMode;\n  /** Parent session ID (for child sessions) */\n  parentSessionId?: string;\n  /** Server URL (for isolated/linked sessions) */\n  serverUrl?: string;\n  /** When the session was created */\n  createdAt: Date;\n  /** Last activity timestamp */\n  lastActivity: Date;\n  /** Current status */\n  status: \"active\" | \"idle\" | \"busy\" | \"error\" | \"closed\";\n  /** Message count */\n  messageCount: number;\n  /** Tool execution count */\n  toolCount: number;\n  /** Recent activity log (circular buffer) */\n  recentActivity: SessionActivity[];\n  /** Error if any */\n  error?: string;\n}\n\n/**\n * A single activity event from a worker session.\n */\nexport interface SessionActivity {\n  /** Unique activity ID */\n  id: string;\n  /** Activity type */\n  type: WorkerForwardEvent;\n  /** Timestamp */\n  timestamp: Date;\n  /** Activity summary */\n  summary: string;\n  /** Full details (optional) */\n  details?: unknown;\n}\n\n/**\n * Event emitted when session state changes.\n */\nexport interface SessionManagerEvent {\n  type: \"session.created\" | \"session.activity\" | \"session.status\" | \"session.closed\" | \"session.error\";\n  session: TrackedSession;\n  activity?: SessionActivity;\n}\n\nexport type SessionManagerEventHandler = (event: SessionManagerEvent) => void;\n\n/**\n * Serialized session for API responses.\n */\nexport interface SerializedSession {\n  workerId: string;\n  sessionId: string;\n  mode: WorkerSessionMode;\n  parentSessionId?: string;\n  serverUrl?: string;\n  createdAt: string;\n  lastActivity: string;\n  status: TrackedSession[\"status\"];\n  messageCount: number;\n  toolCount: number;\n  recentActivityCount: number;\n  error?: string;\n}\n"
  },
  {
    "path": "workers/session-manager.ts",
    "content": "import type { ApiService } from \"../api\";\nimport type { CommunicationService } from \"../communication\";\nimport type { WorkerSessionMode } from \"../types/worker\";\nimport type {\n  SerializedSession,\n  SessionActivity,\n  SessionManagerEvent,\n  SessionManagerEventHandler,\n  TrackedSession,\n} from \"./session-manager-types\";\n\nconst MAX_RECENT_ACTIVITY = 50;\n/** Maximum number of sessions to track before cleanup */\nconst MAX_SESSIONS = 1000;\n/** Session TTL in milliseconds (1 hour) - sessions inactive longer than this are cleaned up */\nconst SESSION_TTL_MS = 60 * 60 * 1000;\n/** Cleanup interval in milliseconds (5 minutes) */\nconst CLEANUP_INTERVAL_MS = 5 * 60 * 1000;\n\n/**\n * Central manager for tracking all worker sessions.\n * Provides a single point of visibility into all orchestrator activity.\n */\nexport class WorkerSessionManager {\n  private sessions = new Map<string, TrackedSession>();\n  private workerToSession = new Map<string, string>();\n  private listeners = new Set<SessionManagerEventHandler>();\n  private activityCounter = 0;\n  private cleanupTimer: ReturnType<typeof setInterval> | undefined;\n\n  constructor(\n    private deps: {\n      api: ApiService;\n      communication: CommunicationService;\n    },\n  ) {\n    // Start periodic cleanup of stale sessions\n    this.cleanupTimer = setInterval(() => this.cleanupStaleSessions(), CLEANUP_INTERVAL_MS);\n    // Prevent timer from keeping the process alive\n    if (this.cleanupTimer.unref) {\n      this.cleanupTimer.unref();\n    }\n  }\n\n  /**\n   * Stop the cleanup timer. Call this when shutting down.\n   */\n  dispose(): void {\n    if (this.cleanupTimer) {\n      clearInterval(this.cleanupTimer);\n      this.cleanupTimer = undefined;\n    }\n  }\n\n  /**\n   * Clean up stale sessions that exceed TTL or when session count exceeds max.\n   */\n  private cleanupStaleSessions(): void {\n    const now = Date.now();\n    const sessionsToRemove: string[] = [];\n\n    // Find sessions that exceed TTL\n    for (const [sessionId, session] of this.sessions) {\n      const inactiveMs = now - session.lastActivity.getTime();\n      const isStale = inactiveMs > SESSION_TTL_MS;\n      const isClosed = session.status === \"closed\" || session.status === \"error\";\n\n      // Remove stale sessions or closed/error sessions older than 5 minutes\n      if (isStale || (isClosed && inactiveMs > 5 * 60 * 1000)) {\n        sessionsToRemove.push(sessionId);\n      }\n    }\n\n    // If still over limit after TTL cleanup, remove oldest sessions\n    if (this.sessions.size - sessionsToRemove.length > MAX_SESSIONS) {\n      const sortedSessions = Array.from(this.sessions.entries())\n        .filter(([id]) => !sessionsToRemove.includes(id))\n        .sort((a, b) => a[1].lastActivity.getTime() - b[1].lastActivity.getTime());\n\n      const excessCount = this.sessions.size - sessionsToRemove.length - MAX_SESSIONS;\n      for (let i = 0; i < excessCount && i < sortedSessions.length; i++) {\n        sessionsToRemove.push(sortedSessions[i][0]);\n      }\n    }\n\n    // Remove sessions\n    for (const sessionId of sessionsToRemove) {\n      const session = this.sessions.get(sessionId);\n      if (session) {\n        this.sessions.delete(sessionId);\n        this.workerToSession.delete(session.workerId);\n      }\n    }\n  }\n\n  /**\n   * Register a new worker session.\n   */\n  registerSession(input: {\n    workerId: string;\n    sessionId: string;\n    mode: WorkerSessionMode;\n    parentSessionId?: string;\n    serverUrl?: string;\n  }): TrackedSession {\n    const session: TrackedSession = {\n      workerId: input.workerId,\n      sessionId: input.sessionId,\n      mode: input.mode,\n      parentSessionId: input.parentSessionId,\n      serverUrl: input.serverUrl,\n      createdAt: new Date(),\n      lastActivity: new Date(),\n      status: \"active\",\n      messageCount: 0,\n      toolCount: 0,\n      recentActivity: [],\n    };\n\n    this.sessions.set(input.sessionId, session);\n    this.workerToSession.set(input.workerId, input.sessionId);\n\n    this.emit({ type: \"session.created\", session });\n    this.deps.communication.emit(\n      \"orchestra.session.created\",\n      { session: this.serializeSession(session) },\n      { source: \"session-manager\" },\n    );\n\n    return session;\n  }\n\n  /**\n   * Record activity on a session.\n   */\n  recordActivity(sessionId: string, activity: Omit<SessionActivity, \"id\" | \"timestamp\">): void {\n    const session = this.sessions.get(sessionId);\n    if (!session) return;\n\n    const fullActivity: SessionActivity = {\n      ...activity,\n      id: `act-${++this.activityCounter}`,\n      timestamp: new Date(),\n    };\n\n    session.lastActivity = fullActivity.timestamp;\n    session.recentActivity.push(fullActivity);\n\n    // Keep circular buffer size\n    if (session.recentActivity.length > MAX_RECENT_ACTIVITY) {\n      session.recentActivity.shift();\n    }\n\n    // Update counts\n    if (activity.type === \"message\") session.messageCount++;\n    if (activity.type === \"tool\") session.toolCount++;\n\n    this.emit({ type: \"session.activity\", session, activity: fullActivity });\n    this.deps.communication.emit(\n      \"orchestra.session.activity\",\n      {\n        sessionId,\n        workerId: session.workerId,\n        activity: {\n          id: fullActivity.id,\n          type: fullActivity.type,\n          timestamp: fullActivity.timestamp.toISOString(),\n          summary: fullActivity.summary,\n        },\n      },\n      { source: \"session-manager\" },\n    );\n  }\n\n  /**\n   * Update session status.\n   */\n  updateStatus(sessionId: string, status: TrackedSession[\"status\"], error?: string): void {\n    const session = this.sessions.get(sessionId);\n    if (!session) return;\n\n    session.status = status;\n    session.lastActivity = new Date();\n    if (error) session.error = error;\n\n    this.emit({ type: \"session.status\", session });\n    this.deps.communication.emit(\n      \"orchestra.session.status\",\n      {\n        sessionId,\n        workerId: session.workerId,\n        status,\n        error,\n      },\n      { source: \"session-manager\" },\n    );\n  }\n\n  /**\n   * Close and unregister a session.\n   */\n  closeSession(sessionId: string): void {\n    const session = this.sessions.get(sessionId);\n    if (!session) return;\n\n    session.status = \"closed\";\n    this.emit({ type: \"session.closed\", session });\n    this.deps.communication.emit(\n      \"orchestra.session.closed\",\n      { sessionId, workerId: session.workerId },\n      { source: \"session-manager\" },\n    );\n\n    this.sessions.delete(sessionId);\n    this.workerToSession.delete(session.workerId);\n  }\n\n  /**\n   * Get session by ID.\n   */\n  getSession(sessionId: string): TrackedSession | undefined {\n    return this.sessions.get(sessionId);\n  }\n\n  /**\n   * Get session by worker ID.\n   */\n  getSessionByWorker(workerId: string): TrackedSession | undefined {\n    const sessionId = this.workerToSession.get(workerId);\n    return sessionId ? this.sessions.get(sessionId) : undefined;\n  }\n\n  /**\n   * Get all tracked sessions.\n   */\n  getAllSessions(): TrackedSession[] {\n    return Array.from(this.sessions.values());\n  }\n\n  /**\n   * Get sessions by mode.\n   */\n  getSessionsByMode(mode: WorkerSessionMode): TrackedSession[] {\n    return this.getAllSessions().filter((s) => s.mode === mode);\n  }\n\n  /**\n   * Get active sessions (not closed/error).\n   */\n  getActiveSessions(): TrackedSession[] {\n    return this.getAllSessions().filter((s) => s.status !== \"closed\" && s.status !== \"error\");\n  }\n\n  /**\n   * Get session summary for API response.\n   */\n  getSummary(): {\n    total: number;\n    byMode: Record<WorkerSessionMode, number>;\n    byStatus: Record<TrackedSession[\"status\"], number>;\n    sessions: Array<SerializedSession>;\n  } {\n    const sessions = this.getAllSessions();\n    const byMode: Record<WorkerSessionMode, number> = {\n      child: 0,\n      isolated: 0,\n      linked: 0,\n    };\n    const byStatus: Record<TrackedSession[\"status\"], number> = {\n      active: 0,\n      idle: 0,\n      busy: 0,\n      error: 0,\n      closed: 0,\n    };\n\n    for (const session of sessions) {\n      byMode[session.mode]++;\n      byStatus[session.status]++;\n    }\n\n    return {\n      total: sessions.length,\n      byMode,\n      byStatus,\n      sessions: sessions.map((s) => this.serializeSession(s)),\n    };\n  }\n\n  /**\n   * Subscribe to session events.\n   */\n  on(handler: SessionManagerEventHandler): () => void {\n    this.listeners.add(handler);\n    return () => this.listeners.delete(handler);\n  }\n\n  /**\n   * Serialize session for API/external use.\n   */\n  private serializeSession(session: TrackedSession) {\n    return {\n      workerId: session.workerId,\n      sessionId: session.sessionId,\n      mode: session.mode,\n      parentSessionId: session.parentSessionId,\n      serverUrl: session.serverUrl,\n      createdAt: session.createdAt.toISOString(),\n      lastActivity: session.lastActivity.toISOString(),\n      status: session.status,\n      messageCount: session.messageCount,\n      toolCount: session.toolCount,\n      recentActivityCount: session.recentActivity.length,\n      error: session.error,\n    };\n  }\n\n  private emit(event: SessionManagerEvent): void {\n    for (const listener of this.listeners) {\n      try {\n        listener(event);\n      } catch {\n        // ignore listener errors\n      }\n    }\n  }\n}\n\n/**\n * Create a session manager instance.\n */\nexport function createSessionManager(deps: {\n  api: ApiService;\n  communication: CommunicationService;\n}): WorkerSessionManager {\n  return new WorkerSessionManager(deps);\n}\n"
  },
  {
    "path": "workers/spawn-bootstrap.ts",
    "content": "import type { ApiService } from \"../api\";\nimport type { WorkerProfile } from \"../types\";\n\ntype WorkerClient = ApiService[\"client\"];\ntype SessionPromptArgs = Parameters<WorkerClient[\"session\"][\"prompt\"]>[0] & { throwOnError?: false };\n\n/** Build the initial bootstrap prompt for a newly created worker session. */\nexport const buildBootstrapPromptArgs = (input: {\n  sessionId: string;\n  directory: string;\n  profile: WorkerProfile;\n  permissionSummary?: string;\n  repoContext?: string;\n}): SessionPromptArgs => {\n  const capabilitiesJson = JSON.stringify({\n    vision: Boolean(input.profile.supportsVision),\n    web: Boolean(input.profile.supportsWeb),\n  });\n\n  const repoContextSection = input.repoContext ? `\\n\\n${input.repoContext}\\n` : \"\";\n  const permissionsSection = input.permissionSummary\n    ? `<worker-permissions>\\n${input.permissionSummary}\\n</worker-permissions>\\n\\n`\n    : \"\";\n\n  return {\n    path: { id: input.sessionId },\n    body: {\n      noReply: true,\n      parts: [\n        {\n          type: \"text\",\n          text:\n            (input.profile.systemPrompt\n              ? `<system-context>\\n${input.profile.systemPrompt}\\n</system-context>\\n\\n`\n              : \"\") +\n            repoContextSection +\n            `<worker-identity>\\n` +\n            `You are worker \"${input.profile.id}\" (${input.profile.name}).\\n` +\n            `Your capabilities: ${capabilitiesJson}\\n` +\n            `</worker-identity>\\n\\n` +\n            permissionsSection +\n            `<orchestrator-instructions>\\n` +\n            `- Always reply with a direct plain-text answer.\\n` +\n            `- If a jobId is provided, include it in your response if relevant.\\n` +\n            `</orchestrator-instructions>`,\n        },\n      ],\n    },\n    query: { directory: input.directory },\n    throwOnError: false,\n  };\n};\n"
  },
  {
    "path": "workers/spawn-env.ts",
    "content": "/* c8 ignore file */\nimport type { SkillPermissions } from \"../types/permissions\";\nimport type { WorkerProfile, WorkerSessionMode } from \"../types\";\n\n/** Build environment variables for a worker based on profile settings. */\nexport const resolveWorkerEnv = (\n  profile: WorkerProfile,\n  integrationEnv?: Record<string, string>,\n): Record<string, string> => {\n  const env: Record<string, string> = {};\n\n  if (profile.envPrefixes && profile.envPrefixes.length > 0) {\n    for (const [key, value] of Object.entries(process.env)) {\n      if (!value) continue;\n      for (const prefix of profile.envPrefixes) {\n        if (key.startsWith(prefix)) {\n          env[key] = value;\n          break;\n        }\n      }\n    }\n  }\n\n  if (integrationEnv) {\n    Object.assign(env, integrationEnv);\n  }\n\n  if (profile.env) {\n    Object.assign(env, profile.env);\n  }\n\n  return env;\n};\n\n/** Resolve MCP configuration to pass down to a worker instance. */\nexport const resolveWorkerMcp = async (\n  profile: WorkerProfile,\n  parentConfig: Record<string, unknown>,\n): Promise<Record<string, unknown> | undefined> => {\n  const mcpConfig = profile.mcp;\n  if (!mcpConfig) return undefined;\n\n  const parentMcp = parentConfig.mcp as Record<string, unknown> | undefined;\n  if (!parentMcp) return undefined;\n\n  if (mcpConfig.inheritAll) {\n    return parentMcp;\n  }\n\n  if (mcpConfig.servers && mcpConfig.servers.length > 0) {\n    const filtered: Record<string, unknown> = {};\n    for (const serverName of mcpConfig.servers) {\n      if (parentMcp[serverName]) {\n        filtered[serverName] = parentMcp[serverName];\n      }\n    }\n    const resolved = Object.keys(filtered).length > 0 ? filtered : undefined;\n    if (resolved) return resolved;\n  }\n\n  return undefined;\n};\n\n/** Determine the default session mode for a profile. */\nexport const getDefaultSessionMode = (profile: WorkerProfile): WorkerSessionMode => {\n  if (profile.id === \"memory\" || profile.id === \"docs\") {\n    return \"linked\";\n  }\n  return \"linked\";\n};\n\n/**\n * Resolve skill permissions for a worker.\n *\n * This determines which skills a worker can access based on its profile config.\n * The result is used to configure OpenCode's permission.skill setting.\n *\n * Behavior:\n * - \"inherit\": Worker inherits all skills (for agents like orchestrator, memory)\n * - explicit object: Use the provided skill permission map\n * - undefined: Default isolation - only allow the worker's own skill, deny others\n *\n * @param profile - The worker profile\n * @param allSkillIds - List of all available skill IDs in the project\n * @returns Skill permissions object for OpenCode config, or undefined for inherit\n */\nexport const resolveWorkerSkillPermissions = (\n  profile: WorkerProfile,\n  _allSkillIds: string[] = [],\n): SkillPermissions | undefined => {\n  const skillPerms = profile.skillPermissions;\n\n  // \"inherit\" means no restrictions - worker gets all parent skills\n  if (skillPerms === \"inherit\") {\n    return undefined;\n  }\n\n  // Explicit skill permissions - use as-is\n  if (skillPerms && typeof skillPerms === \"object\") {\n    // Ensure deny-all fallback if not specified\n    if (!(\"*\" in skillPerms)) {\n      return { ...skillPerms, \"*\": \"deny\" };\n    }\n    return skillPerms;\n  }\n\n  // Default: isolate worker to only its own skill\n  // This prevents workers from accessing each other's skills\n  const permissions: SkillPermissions = {\n    [profile.id]: \"allow\", // Allow own skill\n    \"*\": \"deny\", // Deny all others\n  };\n\n  return permissions;\n};\n\n/**\n * Build the permission config object for OpenCode.\n * This combines skill permissions with any existing permission config.\n *\n * @param existingPermissions - Existing permission config from profile\n * @param skillPermissions - Resolved skill permissions\n * @returns Combined permission config for OpenCode\n */\nexport const buildPermissionConfig = (\n  existingPermissions?: Record<string, unknown>,\n  skillPermissions?: SkillPermissions,\n): Record<string, unknown> | undefined => {\n  if (!skillPermissions && !existingPermissions) {\n    return undefined;\n  }\n\n  const result: Record<string, unknown> = {};\n\n  // Copy existing permissions\n  if (existingPermissions) {\n    Object.assign(result, existingPermissions);\n  }\n\n  // Add skill permissions\n  if (skillPermissions) {\n    result.skill = skillPermissions;\n  }\n\n  return Object.keys(result).length > 0 ? result : undefined;\n};\n"
  },
  {
    "path": "workers/spawn-helpers.ts",
    "content": "/* c8 ignore file */\nconst asRecord = (value: unknown): value is Record<string, unknown> => typeof value === \"object\" && value !== null;\n\n/** Unwrap SDK responses that nest payloads under a data field. */\nexport const extractSdkData = (value: unknown): unknown => {\n  if (asRecord(value) && \"data\" in value) return (value as { data?: unknown }).data ?? value;\n  return value;\n};\n\n/** Normalize SDK error payloads into a human-readable message. */\nexport const extractSdkErrorMessage = (value: unknown): string | undefined => {\n  const sdkError = asRecord(value) && \"error\" in value ? (value as { error?: unknown }).error : value;\n  if (!sdkError) return undefined;\n  if (sdkError instanceof Error) return sdkError.message;\n  if (typeof sdkError === \"string\") return sdkError;\n  if (asRecord(sdkError)) {\n    const dataMessage = asRecord(sdkError.data) ? sdkError.data.message : undefined;\n    if (typeof dataMessage === \"string\" && dataMessage.trim()) return dataMessage;\n    if (typeof sdkError.message === \"string\" && sdkError.message.trim()) return sdkError.message;\n  }\n  try {\n    return JSON.stringify(sdkError);\n  } catch {\n    return String(sdkError);\n  }\n};\n\n/** Race a promise against a timeout and optionally abort. */\nexport const withTimeout = async <T>(promise: Promise<T>, timeoutMs: number, abort?: AbortController): Promise<T> => {\n  let timer: ReturnType<typeof setTimeout> | undefined;\n  const timeout = new Promise<never>((_, reject) => {\n    timer = setTimeout(() => {\n      abort?.abort(new Error(\"worker bootstrap timed out\"));\n      reject(new Error(\"worker bootstrap timed out\"));\n    }, timeoutMs);\n  });\n\n  return Promise.race([promise, timeout]).finally(() => {\n    if (timer) clearTimeout(timer);\n  }) as Promise<T>;\n};\n\n/** Validate that a numeric port is within the valid range. */\nexport const isValidPort = (value: unknown): value is number =>\n  typeof value === \"number\" && Number.isFinite(value) && value >= 0 && value <= 65535;\n"
  },
  {
    "path": "workers/spawn-model.ts",
    "content": "/* c8 ignore file */\nimport type { ApiService } from \"../api\";\nimport { hydrateProfileModelsFromOpencode, type ProfileModelHydrationChange } from \"../models/hydrate\";\nimport type { OrchestratorConfig, WorkerProfile } from \"../types\";\n\nexport type ModelResolutionResult = {\n  profile: WorkerProfile;\n  changes: ProfileModelHydrationChange[];\n  fallbackModel?: string;\n};\n\n/** Resolve a profile's model string into a concrete provider/model ID when needed. */\nexport const resolveProfileModel = async (input: {\n  api: ApiService;\n  directory: string;\n  profile: WorkerProfile;\n  modelSelection?: OrchestratorConfig[\"modelSelection\"];\n  modelAliases?: OrchestratorConfig[\"modelAliases\"];\n  deps?: {\n    hydrateProfileModelsFromOpencode?: typeof hydrateProfileModelsFromOpencode;\n  };\n}): Promise<ModelResolutionResult> => {\n  const modelSpec = input.profile.model.trim();\n  const isNodeTag = modelSpec.startsWith(\"auto\") || modelSpec.startsWith(\"node\");\n  const isExplicit = modelSpec.includes(\"/\");\n\n  if (!input.api?.client) {\n    if (isNodeTag || !isExplicit) {\n      throw new Error(\n        `Profile \"${input.profile.id}\" uses \"${input.profile.model}\", but model resolution is unavailable. ` +\n          `Set a concrete provider/model ID for this profile.`,\n      );\n    }\n    return { profile: input.profile, changes: [] };\n  }\n\n  if (!isNodeTag && isExplicit) return { profile: input.profile, changes: [] };\n\n  const hydrate = input.deps?.hydrateProfileModelsFromOpencode ?? hydrateProfileModelsFromOpencode;\n  const { profiles, changes, fallbackModel } = await hydrate({\n    client: input.api.client,\n    directory: input.directory,\n    profiles: { [input.profile.id]: input.profile },\n    modelAliases: input.modelAliases,\n    modelSelection: input.modelSelection,\n  });\n  return {\n    profile: profiles[input.profile.id] ?? input.profile,\n    changes,\n    fallbackModel,\n  };\n};\n"
  },
  {
    "path": "workers/spawn-plugin.ts",
    "content": "import { existsSync } from \"node:fs\";\nimport { dirname, join } from \"node:path\";\nimport { fileURLToPath } from \"node:url\";\n\n/** Locate the worker-bridge plugin path from env, dist, or repo scripts. */\nexport const resolveWorkerBridgePluginPath = (): string | undefined => {\n  if (process.env.OPENCODE_WORKER_PLUGIN_PATH) return process.env.OPENCODE_WORKER_PLUGIN_PATH;\n\n  try {\n    const baseDir = dirname(fileURLToPath(import.meta.url));\n    const distCandidate = join(baseDir, \"worker-bridge-plugin.mjs\");\n    if (existsSync(distCandidate)) return distCandidate;\n    const parentCandidate = join(baseDir, \"..\", \"worker-bridge-plugin.mjs\");\n    if (existsSync(parentCandidate)) return parentCandidate;\n  } catch {\n    // ignore path resolution issues\n  }\n\n  const repoCandidate = join(process.cwd(), \"scripts\", \"worker-bridge-plugin.mjs\");\n  if (existsSync(repoCandidate)) return repoCandidate;\n\n  return undefined;\n};\n\n/** Normalize file:// URLs to filesystem paths when needed. */\nexport const normalizePluginPath = (path: string | undefined): string | undefined => {\n  if (!path) return undefined;\n  if (!path.startsWith(\"file://\")) return path;\n  try {\n    return fileURLToPath(path);\n  } catch {\n    return path;\n  }\n};\n"
  },
  {
    "path": "workers/spawn-server.ts",
    "content": "import type { ApiService } from \"../api\";\nimport type { WorkerInstance } from \"../types\";\nimport { withTimeout } from \"./spawn-helpers\";\n\ntype WorkerClient = ApiService[\"client\"];\ntype SessionCreateArgs = Parameters<WorkerClient[\"session\"][\"create\"]>[0] & { throwOnError?: false };\ntype ServerBundle = Awaited<ReturnType<ApiService[\"createServer\"]>>;\ntype ServerConfig = NonNullable<Parameters<ApiService[\"createServer\"]>[0]>[\"config\"];\n\n/** Start an OpenCode server with worker isolation flags applied. */\nexport const startWorkerServer = async (input: {\n  api: ApiService;\n  hostname: string;\n  port: number;\n  timeoutMs: number;\n  config: Record<string, unknown>;\n  pluginPath?: string;\n}): Promise<ServerBundle> => {\n  const previousWorkerPluginPath = process.env.OPENCODE_WORKER_PLUGIN_PATH;\n  const previousWorkerFlag = process.env.OPENCODE_ORCHESTRATOR_WORKER;\n\n  process.env.OPENCODE_ORCHESTRATOR_WORKER = \"1\";\n\n  if (input.pluginPath) {\n    process.env.OPENCODE_WORKER_PLUGIN_PATH = input.pluginPath;\n  }\n\n  return await input.api\n    .createServer({\n      hostname: input.hostname,\n      port: input.port,\n      timeout: input.timeoutMs,\n      config: input.config as ServerConfig,\n    })\n    .finally(() => {\n      if (previousWorkerFlag === undefined) {\n        delete process.env.OPENCODE_ORCHESTRATOR_WORKER;\n      } else {\n        process.env.OPENCODE_ORCHESTRATOR_WORKER = previousWorkerFlag;\n      }\n      if (previousWorkerPluginPath === undefined) {\n        delete process.env.OPENCODE_WORKER_PLUGIN_PATH;\n      } else {\n        process.env.OPENCODE_WORKER_PLUGIN_PATH = previousWorkerPluginPath;\n      }\n    });\n};\n\n/** Create a worker session with a timeout guard. */\nexport const createWorkerSession = async (input: {\n  client: WorkerClient;\n  directory: string;\n  timeoutMs: number;\n  title: string;\n}): Promise<unknown> => {\n  const sessionAbort = new AbortController();\n  try {\n    const createArgs: SessionCreateArgs = {\n      body: { title: input.title },\n      query: { directory: input.directory },\n      signal: sessionAbort.signal,\n      throwOnError: false,\n    };\n    return await withTimeout(input.client.session.create(createArgs), input.timeoutMs, sessionAbort);\n  } catch (error) {\n    return { error };\n  }\n};\n\n/** Create a subagent session on the parent OpenCode server. */\nexport const createSubagentSession = async (input: {\n  api: ApiService;\n  timeoutMs: number;\n  title: string;\n  parentSessionId?: string;\n}): Promise<unknown> => {\n  const sessionAbort = new AbortController();\n  try {\n    const createArgs: SessionCreateArgs = {\n      body: { title: input.title, ...(input.parentSessionId ? { parentID: input.parentSessionId } : {}) },\n      signal: sessionAbort.signal,\n      throwOnError: false,\n    };\n    return await withTimeout(input.api.session.create(createArgs), input.timeoutMs, sessionAbort);\n  } catch (error) {\n    return { error };\n  }\n};\n\n/** Apply server connection info to a worker instance. */\nexport const applyServerBundleToInstance = (instance: WorkerInstance, bundle: ServerBundle) => {\n  const { client, server } = bundle;\n  instance.shutdown = async () => server.close();\n  instance.serverUrl = server.url;\n  try {\n    const u = new URL(server.url);\n    const actualPort = Number(u.port);\n    if (Number.isFinite(actualPort) && actualPort > 0) instance.port = actualPort;\n  } catch {\n    // ignore\n  }\n  instance.client = client;\n  return { client, server };\n};\n"
  },
  {
    "path": "workers/spawn.ts",
    "content": "/* c8 ignore file */\nimport type { ApiService } from \"../api\";\nimport type { CommunicationService } from \"../communication\";\nimport { loadOpenCodeConfig, mergeOpenCodeConfig } from \"../config/opencode\";\nimport { getIntegrationEnv } from \"../integrations/registry\";\nimport { resolveIntegrationsForProfile } from \"../integrations/selection\";\nimport type { ProfileModelHydrationChange } from \"../models/hydrate\";\nimport { buildToolConfigFromPermissions, summarizePermissions } from \"../permissions/validator\";\nimport type { OrchestratorConfig, WorkerInstance, WorkerProfile } from \"../types\";\nimport { getRepoContextForWorker } from \"../ux/repo-context\";\nimport { startEventForwarding, stopEventForwarding } from \"./event-forwarding\";\nimport type { WorkerRegistry } from \"./registry\";\nimport type { WorkerSessionManager } from \"./session-manager\";\nimport { buildBootstrapPromptArgs } from \"./spawn-bootstrap\";\nimport {\n  buildPermissionConfig,\n  getDefaultSessionMode,\n  resolveWorkerEnv,\n  resolveWorkerMcp,\n  resolveWorkerSkillPermissions,\n} from \"./spawn-env\";\nimport { extractSdkData, extractSdkErrorMessage, isValidPort, withTimeout } from \"./spawn-helpers\";\nimport { resolveProfileModel } from \"./spawn-model\";\nimport { normalizePluginPath, resolveWorkerBridgePluginPath } from \"./spawn-plugin\";\nimport {\n  applyServerBundleToInstance,\n  createSubagentSession,\n  createWorkerSession,\n  startWorkerServer,\n} from \"./spawn-server\";\n\nexport type { ModelResolutionResult } from \"./spawn-model\";\n\nexport type SpawnWorkerCallbacks = {\n  onModelResolved?: (change: ProfileModelHydrationChange) => void;\n  onModelFallback?: (profileId: string, model: string, reason: string) => void;\n};\n\nexport type SpawnWorkerDeps = {\n  resolveProfileModel?: typeof resolveProfileModel;\n  loadOpenCodeConfig?: typeof loadOpenCodeConfig;\n  mergeOpenCodeConfig?: typeof mergeOpenCodeConfig;\n  resolveIntegrationsForProfile?: typeof resolveIntegrationsForProfile;\n  getIntegrationEnv?: typeof getIntegrationEnv;\n  resolveWorkerEnv?: typeof resolveWorkerEnv;\n  resolveWorkerMcp?: typeof resolveWorkerMcp;\n  resolveWorkerSkillPermissions?: typeof resolveWorkerSkillPermissions;\n  buildPermissionConfig?: typeof buildPermissionConfig;\n  getDefaultSessionMode?: typeof getDefaultSessionMode;\n  getRepoContextForWorker?: typeof getRepoContextForWorker;\n  startEventForwarding?: typeof startEventForwarding;\n  stopEventForwarding?: typeof stopEventForwarding;\n  buildBootstrapPromptArgs?: typeof buildBootstrapPromptArgs;\n  extractSdkData?: typeof extractSdkData;\n  extractSdkErrorMessage?: typeof extractSdkErrorMessage;\n  withTimeout?: typeof withTimeout;\n  resolveWorkerBridgePluginPath?: typeof resolveWorkerBridgePluginPath;\n  normalizePluginPath?: typeof normalizePluginPath;\n  startWorkerServer?: typeof startWorkerServer;\n  createWorkerSession?: typeof createWorkerSession;\n  createSubagentSession?: typeof createSubagentSession;\n  applyServerBundleToInstance?: typeof applyServerBundleToInstance;\n};\n\n/** Spawn a new worker instance and bootstrap its session. */\nexport async function spawnWorker(input: {\n  api: ApiService;\n  registry: WorkerRegistry;\n  directory: string;\n  profile: WorkerProfile;\n  integrations?: OrchestratorConfig[\"integrations\"];\n  modelSelection?: OrchestratorConfig[\"modelSelection\"];\n  modelAliases?: OrchestratorConfig[\"modelAliases\"];\n  timeoutMs: number;\n  deps?: SpawnWorkerDeps;\n  callbacks?: SpawnWorkerCallbacks;\n  /** Session manager for tracking and event forwarding */\n  sessionManager?: WorkerSessionManager;\n  /** Communication service for event forwarding */\n  communication?: CommunicationService;\n  /** Parent session ID (for child mode) */\n  parentSessionId?: string;\n}): Promise<WorkerInstance> {\n  const deps = input.deps ?? {};\n  const resolveProfileModelFn = deps.resolveProfileModel ?? resolveProfileModel;\n  const loadOpenCodeConfigFn = deps.loadOpenCodeConfig ?? loadOpenCodeConfig;\n  const mergeOpenCodeConfigFn = deps.mergeOpenCodeConfig ?? mergeOpenCodeConfig;\n  const resolveIntegrationsForProfileFn = deps.resolveIntegrationsForProfile ?? resolveIntegrationsForProfile;\n  const getIntegrationEnvFn = deps.getIntegrationEnv ?? getIntegrationEnv;\n  const resolveWorkerEnvFn = deps.resolveWorkerEnv ?? resolveWorkerEnv;\n  const resolveWorkerMcpFn = deps.resolveWorkerMcp ?? resolveWorkerMcp;\n  const resolveWorkerSkillPermissionsFn = deps.resolveWorkerSkillPermissions ?? resolveWorkerSkillPermissions;\n  const buildPermissionConfigFn = deps.buildPermissionConfig ?? buildPermissionConfig;\n  const getDefaultSessionModeFn = deps.getDefaultSessionMode ?? getDefaultSessionMode;\n  const getRepoContextForWorkerFn = deps.getRepoContextForWorker ?? getRepoContextForWorker;\n  const startEventForwardingFn = deps.startEventForwarding ?? startEventForwarding;\n  const stopEventForwardingFn = deps.stopEventForwarding ?? stopEventForwarding;\n  const buildBootstrapPromptArgsFn = deps.buildBootstrapPromptArgs ?? buildBootstrapPromptArgs;\n  const extractSdkDataFn = deps.extractSdkData ?? extractSdkData;\n  const extractSdkErrorMessageFn = deps.extractSdkErrorMessage ?? extractSdkErrorMessage;\n  const withTimeoutFn = deps.withTimeout ?? withTimeout;\n  const resolveWorkerBridgePluginPathFn = deps.resolveWorkerBridgePluginPath ?? resolveWorkerBridgePluginPath;\n  const normalizePluginPathFn = deps.normalizePluginPath ?? normalizePluginPath;\n  const startWorkerServerFn = deps.startWorkerServer ?? startWorkerServer;\n  const createWorkerSessionFn = deps.createWorkerSession ?? createWorkerSession;\n  const createSubagentSessionFn = deps.createSubagentSession ?? createSubagentSession;\n  const applyServerBundleToInstanceFn = deps.applyServerBundleToInstance ?? applyServerBundleToInstance;\n\n  const {\n    profile: resolvedProfile,\n    changes,\n    fallbackModel,\n  } = await resolveProfileModelFn({\n    api: input.api,\n    directory: input.directory,\n    profile: input.profile,\n    modelSelection: input.modelSelection,\n    modelAliases: input.modelAliases,\n  });\n\n  // Notify about model changes\n  for (const change of changes) {\n    input.callbacks?.onModelResolved?.(change);\n  }\n  if (fallbackModel && resolvedProfile.model === fallbackModel) {\n    input.callbacks?.onModelFallback?.(resolvedProfile.id, fallbackModel, `fallback from ${input.profile.model}`);\n  }\n\n  const hostname = \"127.0.0.1\";\n  const fixedPort = isValidPort(resolvedProfile.port) ? resolvedProfile.port : undefined;\n  const requestedPort = fixedPort ?? 0;\n\n  const modelResolution =\n    input.profile.model.trim().startsWith(\"auto\") || input.profile.model.trim().startsWith(\"node\")\n      ? `resolved from ${input.profile.model.trim()}`\n      : resolvedProfile.model === input.profile.model\n        ? \"configured\"\n        : `resolved from ${input.profile.model.trim()}`;\n\n  const toolConfig = buildToolConfigFromPermissions({\n    permissions: resolvedProfile.permissions,\n    baseTools: resolvedProfile.tools,\n  });\n  const permissionSummary = summarizePermissions(resolvedProfile.permissions);\n\n  // Determine session mode\n  const sessionMode = resolvedProfile.sessionMode ?? getDefaultSessionModeFn(resolvedProfile);\n\n  const selectedIntegrations = resolveIntegrationsForProfileFn(resolvedProfile, input.integrations);\n  const integrationEnv = getIntegrationEnvFn(selectedIntegrations);\n\n  // Resolve env vars for this worker\n  const workerEnv = resolveWorkerEnvFn(resolvedProfile, integrationEnv);\n\n  // Load parent config for MCP resolution\n  const parentConfig = await loadOpenCodeConfigFn();\n  const workerMcp = await resolveWorkerMcpFn(resolvedProfile, parentConfig);\n  const baseConfig = { ...parentConfig };\n  delete (baseConfig as Record<string, unknown>).integrations;\n\n  // Resolve skill permissions for worker isolation\n  // This prevents workers from accessing each other's skills unless explicitly allowed\n  const skillPermissions = resolveWorkerSkillPermissionsFn(resolvedProfile);\n  const permissionConfig = buildPermissionConfigFn(\n    resolvedProfile.permissions as Record<string, unknown> | undefined,\n    skillPermissions,\n  );\n\n  const instance: WorkerInstance = {\n    profile: resolvedProfile,\n    status: \"starting\",\n    port: requestedPort,\n    directory: input.directory,\n    startedAt: new Date(),\n    modelResolution,\n    sessionMode,\n    parentSessionId: input.parentSessionId,\n    messageCount: 0,\n    toolCount: 0,\n  };\n\n  input.registry.register(instance);\n\n  // Set up worker env vars restoration function (defined outside try for catch access)\n  const previousEnvValues: Record<string, string | undefined> = {};\n  const restoreWorkerEnv = () => {\n    for (const [key, previousValue] of Object.entries(previousEnvValues)) {\n      if (previousValue === undefined) {\n        delete process.env[key];\n      } else {\n        process.env[key] = previousValue;\n      }\n    }\n  };\n\n  try {\n    const workerBridgePluginPath = normalizePluginPathFn(resolveWorkerBridgePluginPathFn());\n    const preferWorkerBridge =\n      process.env.OPENCODE_WORKER_BRIDGE === \"1\" || Boolean(process.env.OPENCODE_WORKER_PLUGIN_PATH);\n    const useWorkerBridge = Boolean(workerBridgePluginPath) && preferWorkerBridge;\n\n    const agentOverride =\n      resolvedProfile.temperature !== undefined\n        ? {\n            agent: {\n              general: {\n                model: resolvedProfile.model,\n                temperature: resolvedProfile.temperature,\n              },\n            },\n          }\n        : undefined;\n\n    const mergedConfig = await mergeOpenCodeConfigFn(\n      {\n        model: resolvedProfile.model,\n        plugin: [],\n        ...(Object.keys(selectedIntegrations).length > 0 && { integrations: selectedIntegrations }),\n        ...(agentOverride ?? {}),\n        ...(toolConfig && { tools: toolConfig }),\n        ...(permissionConfig && { permission: permissionConfig }),\n        ...(workerMcp && { mcp: workerMcp }),\n      },\n      {\n        dropOrchestratorPlugin: true,\n        appendPlugins: useWorkerBridge ? [workerBridgePluginPath as string] : undefined,\n        baseConfig,\n      },\n    );\n\n    // Inject worker env vars into process.env before starting server\n    for (const [key, value] of Object.entries(workerEnv)) {\n      previousEnvValues[key] = process.env[key];\n      process.env[key] = value;\n    }\n\n    const extractSession = (result: unknown) => extractSdkDataFn(result) as { id?: string } | undefined;\n\n    let serverBundle = await startWorkerServerFn({\n      api: input.api,\n      hostname,\n      port: requestedPort,\n      timeoutMs: input.timeoutMs,\n      config: mergedConfig,\n      pluginPath: useWorkerBridge ? (workerBridgePluginPath as string) : undefined,\n    });\n    let { client, server } = applyServerBundleToInstanceFn(instance, serverBundle);\n\n    let sessionResult = await createWorkerSessionFn({\n      client,\n      directory: input.directory,\n      timeoutMs: input.timeoutMs,\n      title: `Worker: ${resolvedProfile.name}`,\n    });\n    let session = extractSession(sessionResult);\n    if (!session?.id) {\n      const errMsg = extractSdkErrorMessageFn(sessionResult) ?? \"Failed to create session\";\n      const needsBridge = /stream_chunk|worker bridge|bridge tools/i.test(errMsg);\n      if (needsBridge && workerBridgePluginPath && !useWorkerBridge) {\n        await Promise.resolve(server.close());\n        const mergedWithBridge = await mergeOpenCodeConfigFn(\n          {\n            model: resolvedProfile.model,\n            plugin: [],\n            ...(Object.keys(selectedIntegrations).length > 0 && { integrations: selectedIntegrations }),\n            ...(agentOverride ?? {}),\n            ...(toolConfig && { tools: toolConfig }),\n            ...(permissionConfig && { permission: permissionConfig }),\n            ...(workerMcp && { mcp: workerMcp }),\n          },\n          {\n            dropOrchestratorPlugin: true,\n            appendPlugins: [workerBridgePluginPath],\n            baseConfig,\n          },\n        );\n        serverBundle = await startWorkerServerFn({\n          api: input.api,\n          hostname,\n          port: requestedPort,\n          timeoutMs: input.timeoutMs,\n          config: mergedWithBridge,\n          pluginPath: workerBridgePluginPath,\n        });\n        ({ client, server } = applyServerBundleToInstanceFn(instance, serverBundle));\n        sessionResult = await createWorkerSessionFn({\n          client,\n          directory: input.directory,\n          timeoutMs: input.timeoutMs,\n          title: `Worker: ${resolvedProfile.name}`,\n        });\n        session = extractSession(sessionResult);\n      }\n    }\n\n    if (!session?.id) {\n      const errMsg = extractSdkErrorMessageFn(sessionResult) ?? \"Failed to create session\";\n      throw new Error(errMsg);\n    }\n\n    instance.sessionId = session.id;\n\n    const repoContext = resolvedProfile.injectRepoContext\n      ? await getRepoContextForWorkerFn(input.directory).catch(() => undefined)\n      : undefined;\n\n    if (input.parentSessionId) {\n      const subagentResult = await createSubagentSessionFn({\n        api: input.api,\n        timeoutMs: input.timeoutMs,\n        title: `Worker: ${resolvedProfile.name}`,\n        parentSessionId: input.parentSessionId,\n      });\n      const subagent = extractSession(subagentResult);\n      if (subagent?.id) {\n        instance.uiSessionId = subagent.id;\n      }\n    }\n\n    const bootstrapAbort = new AbortController();\n    const bootstrapTimeoutMs = Math.min(input.timeoutMs, 15_000);\n    const bootstrapArgs = buildBootstrapPromptArgsFn({\n      sessionId: session.id,\n      directory: input.directory,\n      profile: resolvedProfile,\n      permissionSummary,\n      repoContext,\n    });\n    bootstrapArgs.signal = bootstrapAbort.signal;\n\n    void withTimeoutFn(client.session.prompt(bootstrapArgs), bootstrapTimeoutMs, bootstrapAbort).catch(() => {});\n\n    instance.status = \"ready\";\n    instance.lastActivity = new Date();\n    input.registry.updateStatus(resolvedProfile.id, \"ready\");\n\n    // Restore worker env vars\n    restoreWorkerEnv();\n\n    // Register session with session manager\n    if (input.sessionManager && instance.sessionId) {\n      input.sessionManager.registerSession({\n        workerId: resolvedProfile.id,\n        sessionId: instance.sessionId,\n        mode: sessionMode,\n        parentSessionId: input.parentSessionId,\n        serverUrl: instance.serverUrl,\n      });\n    }\n\n    // Start event forwarding for linked mode\n    if (sessionMode === \"linked\" && input.sessionManager && input.communication) {\n      const forwardEvents = resolvedProfile.forwardEvents ?? [\"tool\", \"message\", \"error\", \"complete\", \"progress\"];\n      instance.eventForwardingHandle = startEventForwardingFn(instance, input.sessionManager, input.communication, {\n        events: forwardEvents,\n      });\n    }\n\n    return instance;\n  } catch (error) {\n    // Restore worker env vars on error\n    restoreWorkerEnv();\n\n    const errorMsg = error instanceof Error ? error.message : String(error);\n    instance.status = \"error\";\n    instance.error = errorMsg;\n    input.registry.updateStatus(resolvedProfile.id, \"error\", errorMsg);\n\n    // Close session in session manager\n    if (input.sessionManager && instance.sessionId) {\n      input.sessionManager.closeSession(instance.sessionId);\n    }\n\n    // Stop event forwarding if started\n    stopEventForwardingFn(instance);\n\n    try {\n      await instance.shutdown?.();\n    } catch {\n      // ignore\n    }\n\n    // Unregister failed instance from registry to prevent zombie entries\n    input.registry.unregister(resolvedProfile.id);\n\n    throw error;\n  }\n}\n\n/**\n * Clean up a worker instance, stopping event forwarding and closing sessions.\n */\n/** Tear down a worker instance and related tracking resources. */\nexport function cleanupWorkerInstance(instance: WorkerInstance, sessionManager?: WorkerSessionManager): void {\n  stopEventForwarding(instance);\n  if (sessionManager && instance.sessionId) {\n    sessionManager.closeSession(instance.sessionId);\n  }\n}\n"
  },
  {
    "path": "workflows/builtins.ts",
    "content": "import type { WorkflowDefinition } from \"./types\";\n\nexport function buildBuiltinWorkflows(): WorkflowDefinition[] {\n  return [\n    {\n      id: \"bug-triage\",\n      name: \"Bug Triage\",\n      description: \"Collect context, propose a fix, and review for risks.\",\n      steps: [\n        {\n          id: \"triage-scan\",\n          title: \"Scan Context\",\n          workerId: \"explorer\",\n          prompt:\n            \"Scan the repo for context related to: {task}.\\n\" +\n            \"Return relevant files, symbols, and a brief summary of findings.\",\n          carry: true,\n        },\n        {\n          id: \"triage-fix\",\n          title: \"Propose Fix\",\n          workerId: \"coder\",\n          prompt:\n            \"Propose a fix for: {task}.\\n\" +\n            \"Use this context if helpful:\\n{carry}\\n\" +\n            \"Return a concise plan and any code-level guidance.\",\n          carry: true,\n        },\n        {\n          id: \"triage-review\",\n          title: \"Risk Review\",\n          workerId: \"reviewer\",\n          prompt:\n            \"Review the proposed fix for risks, regressions, or missing tests.\\n\" +\n            \"Context:\\n{carry}\\n\" +\n            \"Return actionable review feedback.\",\n        },\n      ],\n    },\n    {\n      id: \"security-audit\",\n      name: \"Security Audit\",\n      description: \"Identify security risks and recommend mitigations.\",\n      steps: [\n        {\n          id: \"security-findings\",\n          title: \"Threat Scan\",\n          workerId: \"security\",\n          prompt:\n            \"Analyze security risks for: {task}.\\n\" +\n            \"Identify threats, vulnerable patterns, and data exposure concerns.\",\n          carry: true,\n        },\n        {\n          id: \"security-review\",\n          title: \"Review Findings\",\n          workerId: \"reviewer\",\n          prompt:\n            \"Review the security findings for clarity and completeness.\\n\" +\n            \"Context:\\n{carry}\\n\" +\n            \"Suggest any missing risks or mitigations.\",\n          carry: true,\n        },\n        {\n          id: \"security-mitigations\",\n          title: \"Mitigation Plan\",\n          workerId: \"architect\",\n          prompt:\n            \"Propose a mitigation plan based on the security findings.\\n\" +\n            \"Context:\\n{carry}\\n\" +\n            \"Return prioritized mitigation steps.\",\n        },\n      ],\n    },\n    {\n      id: \"qa-regression\",\n      name: \"QA Regression\",\n      description: \"Design test plan, propose fixes, and verify outcomes.\",\n      steps: [\n        {\n          id: \"qa-plan\",\n          title: \"Test Plan\",\n          workerId: \"qa\",\n          prompt: \"Draft a focused regression test plan for: {task}.\\n\" + \"Include repro steps and expected outcomes.\",\n          carry: true,\n        },\n        {\n          id: \"qa-fix\",\n          title: \"Implementation Notes\",\n          workerId: \"coder\",\n          prompt:\n            \"Given this QA plan, propose implementation or fixes for: {task}.\\n\" +\n            \"Context:\\n{carry}\\n\" +\n            \"Return a concise plan.\",\n          carry: true,\n        },\n        {\n          id: \"qa-verify\",\n          title: \"Verification\",\n          workerId: \"qa\",\n          prompt:\n            \"Verify expected behavior based on the plan and notes.\\n\" +\n            \"Context:\\n{carry}\\n\" +\n            \"Return a checklist of verifications.\",\n        },\n      ],\n    },\n    {\n      id: \"spec-to-implementation\",\n      name: \"Spec to Implementation\",\n      description: \"Turn requirements into an implementation plan with review.\",\n      steps: [\n        {\n          id: \"spec\",\n          title: \"Requirements\",\n          workerId: \"product\",\n          prompt:\n            \"Turn this task into a short spec with acceptance criteria:\\n{task}\\n\" +\n            \"Be explicit about scope and edge cases.\",\n          carry: true,\n        },\n        {\n          id: \"architecture\",\n          title: \"Architecture Plan\",\n          workerId: \"architect\",\n          prompt:\n            \"Design an implementation approach for the spec.\\n\" +\n            \"Context:\\n{carry}\\n\" +\n            \"Return a high-level plan and risks.\",\n          carry: true,\n        },\n        {\n          id: \"implementation\",\n          title: \"Implementation Steps\",\n          workerId: \"coder\",\n          prompt:\n            \"Outline concrete implementation steps based on the plan.\\n\" +\n            \"Context:\\n{carry}\\n\" +\n            \"Include tests to add or update.\",\n          carry: true,\n        },\n        {\n          id: \"review\",\n          title: \"Review Plan\",\n          workerId: \"reviewer\",\n          prompt:\n            \"Review the implementation steps for gaps and missing tests.\\n\" +\n            \"Context:\\n{carry}\\n\" +\n            \"Return review notes.\",\n        },\n      ],\n    },\n    {\n      id: \"data-digest\",\n      name: \"Data Digest\",\n      description: \"Summarize metrics, research context, and validate insights.\",\n      steps: [\n        {\n          id: \"insights\",\n          title: \"Insights\",\n          workerId: \"analyst\",\n          prompt: \"Summarize the key insights for: {task}.\\n\" + \"Call out trends, anomalies, and likely drivers.\",\n          carry: true,\n        },\n        {\n          id: \"context\",\n          title: \"Context Research\",\n          workerId: \"docs\",\n          prompt:\n            \"Provide supporting context or references for the insights.\\n\" +\n            \"Context:\\n{carry}\\n\" +\n            \"Cite sources or internal references if available.\",\n          carry: true,\n        },\n        {\n          id: \"validation\",\n          title: \"Validation\",\n          workerId: \"reviewer\",\n          prompt:\n            \"Validate the insights for accuracy and missing data.\\n\" +\n            \"Context:\\n{carry}\\n\" +\n            \"Return any concerns or follow-ups.\",\n        },\n      ],\n    },\n  ];\n}\n"
  },
  {
    "path": "workflows/engine.ts",
    "content": "import type { WorkflowDefinition, WorkflowRunInput, WorkflowRunResult, WorkflowStepDefinition } from \"./types\";\n\nconst workflows = new Map<string, WorkflowDefinition>();\n\nexport type WorkflowRunDependencies = {\n  resolveWorker: (workerId: string, autoSpawn: boolean) => Promise<string>;\n  sendToWorker: (\n    workerId: string,\n    message: string,\n    options: { attachments?: WorkflowRunInput[\"attachments\"]; timeoutMs: number },\n  ) => Promise<{ success: boolean; response?: string; error?: string }>;\n};\n\nexport function registerWorkflow(def: WorkflowDefinition) {\n  workflows.set(def.id, def);\n}\n\nexport function listWorkflows(): WorkflowDefinition[] {\n  return [...workflows.values()].sort((a, b) => a.id.localeCompare(b.id));\n}\n\nexport function getWorkflow(id: string): WorkflowDefinition | undefined {\n  return workflows.get(id);\n}\n\nfunction applyTemplate(template: string, vars: Record<string, string>): string {\n  let out = template;\n  for (const [key, value] of Object.entries(vars)) {\n    out = out.replaceAll(`{${key}}`, value);\n  }\n  return out;\n}\n\nfunction appendCarry(existing: string, next: string, maxChars: number): string {\n  const combined = existing ? `${existing}\\n\\n${next}` : next;\n  if (combined.length <= maxChars) return combined;\n  return combined.slice(combined.length - maxChars);\n}\n\nfunction buildStepPrompt(step: WorkflowStepDefinition, task: string, carry: string): string {\n  const base = applyTemplate(step.prompt, { task, carry });\n  if (!step.carry || !carry) return base;\n  return base;\n}\n\nexport async function runWorkflow(input: WorkflowRunInput, deps: WorkflowRunDependencies): Promise<WorkflowRunResult> {\n  const workflow = getWorkflow(input.workflowId);\n  if (!workflow) {\n    throw new Error(`Unknown workflow \"${input.workflowId}\".`);\n  }\n\n  if (input.task.length > input.limits.maxTaskChars) {\n    throw new Error(`Task exceeds maxTaskChars (${input.limits.maxTaskChars}).`);\n  }\n\n  if (workflow.steps.length > input.limits.maxSteps) {\n    throw new Error(`Workflow has ${workflow.steps.length} steps (maxSteps=${input.limits.maxSteps}).`);\n  }\n\n  const startedAt = Date.now();\n  const steps: WorkflowRunResult[\"steps\"] = [];\n  let carry = \"\";\n\n  for (let i = 0; i < workflow.steps.length; i++) {\n    const step = workflow.steps[i];\n    const stepStarted = Date.now();\n    const workerId = await deps.resolveWorker(step.workerId, input.autoSpawn ?? true);\n    const prompt = buildStepPrompt(step, input.task, carry);\n    const res = await deps.sendToWorker(workerId, prompt, {\n      attachments: i === 0 ? input.attachments : undefined,\n      timeoutMs: input.limits.perStepTimeoutMs,\n    });\n    const stepFinished = Date.now();\n    if (!res.success) {\n      steps.push({\n        id: step.id,\n        title: step.title,\n        workerId,\n        status: \"error\",\n        error: res.error ?? \"unknown_error\",\n        startedAt: stepStarted,\n        finishedAt: stepFinished,\n        durationMs: stepFinished - stepStarted,\n      });\n      break;\n    }\n    const response = res.response ?? \"\";\n    steps.push({\n      id: step.id,\n      title: step.title,\n      workerId,\n      status: \"success\",\n      response,\n      startedAt: stepStarted,\n      finishedAt: stepFinished,\n      durationMs: stepFinished - stepStarted,\n    });\n\n    if (step.carry) {\n      const carryBlock = [`### ${step.title}`, response].join(\"\\n\");\n      carry = appendCarry(carry, carryBlock, input.limits.maxCarryChars);\n    }\n  }\n\n  return {\n    workflowId: workflow.id,\n    workflowName: workflow.name,\n    startedAt,\n    finishedAt: Date.now(),\n    steps,\n  };\n}\n"
  },
  {
    "path": "workflows/factory.ts",
    "content": "import type { Factory, ServiceLifecycle, WorkflowsConfig } from \"../types\";\nimport { buildBuiltinWorkflows } from \"./builtins\";\nimport type { WorkflowDefinition, WorkflowRunInput, WorkflowRunResult, WorkflowStepDefinition } from \"./types\";\n\nexport type WorkflowEngineConfig = WorkflowsConfig | undefined;\n\nexport type WorkflowRunDependencies = {\n  resolveWorker: (workerId: string, autoSpawn: boolean) => Promise<string>;\n  sendToWorker: (\n    workerId: string,\n    message: string,\n    options: { attachments?: WorkflowRunInput[\"attachments\"]; timeoutMs: number },\n  ) => Promise<{ success: boolean; response?: string; error?: string }>;\n};\n\nexport type WorkflowEngine = ServiceLifecycle & {\n  register: (def: WorkflowDefinition) => void;\n  list: () => WorkflowDefinition[];\n  get: (id: string) => WorkflowDefinition | undefined;\n  run: (input: WorkflowRunInput, deps: WorkflowRunDependencies) => Promise<WorkflowRunResult>;\n};\n\nfunction applyTemplate(template: string, vars: Record<string, string>): string {\n  let out = template;\n  for (const [key, value] of Object.entries(vars)) {\n    out = out.replaceAll(`{${key}}`, value);\n  }\n  return out;\n}\n\nfunction appendCarry(existing: string, next: string, maxChars: number): string {\n  const combined = existing ? `${existing}\\n\\n${next}` : next;\n  if (combined.length <= maxChars) return combined;\n  return combined.slice(combined.length - maxChars);\n}\n\nfunction buildStepPrompt(step: WorkflowStepDefinition, task: string, carry: string): string {\n  const base = applyTemplate(step.prompt, { task, carry });\n  if (!step.carry || !carry) return base;\n  return base;\n}\n\nexport const createWorkflowEngine: Factory<WorkflowEngineConfig, Record<string, never>, WorkflowEngine> = ({\n  config,\n}) => {\n  const workflows = new Map<string, WorkflowDefinition>();\n\n  const register = (def: WorkflowDefinition) => {\n    workflows.set(def.id, def);\n  };\n\n  const list = () => [...workflows.values()].sort((a, b) => a.id.localeCompare(b.id));\n\n  const get = (id: string) => workflows.get(id);\n\n  const run = async (input: WorkflowRunInput, deps: WorkflowRunDependencies): Promise<WorkflowRunResult> => {\n    const workflow = get(input.workflowId);\n    if (!workflow) throw new Error(`Unknown workflow \"${input.workflowId}\".`);\n\n    if (input.task.length > input.limits.maxTaskChars) {\n      throw new Error(`Task exceeds maxTaskChars (${input.limits.maxTaskChars}).`);\n    }\n\n    if (workflow.steps.length > input.limits.maxSteps) {\n      throw new Error(`Workflow has ${workflow.steps.length} steps (maxSteps=${input.limits.maxSteps}).`);\n    }\n\n    const startedAt = Date.now();\n    const steps: WorkflowRunResult[\"steps\"] = [];\n    let carry = \"\";\n\n    for (let i = 0; i < workflow.steps.length; i += 1) {\n      const step = workflow.steps[i];\n      const stepStarted = Date.now();\n      const workerId = await deps.resolveWorker(step.workerId, input.autoSpawn ?? true);\n      const prompt = buildStepPrompt(step, input.task, carry);\n      const res = await deps.sendToWorker(workerId, prompt, {\n        attachments: i === 0 ? input.attachments : undefined,\n        timeoutMs: input.limits.perStepTimeoutMs,\n      });\n      const stepFinished = Date.now();\n\n      if (!res.success) {\n        steps.push({\n          id: step.id,\n          title: step.title,\n          workerId,\n          status: \"error\",\n          error: res.error ?? \"unknown_error\",\n          startedAt: stepStarted,\n          finishedAt: stepFinished,\n          durationMs: stepFinished - stepStarted,\n        });\n        break;\n      }\n\n      const response = res.response ?? \"\";\n      steps.push({\n        id: step.id,\n        title: step.title,\n        workerId,\n        status: \"success\",\n        response,\n        startedAt: stepStarted,\n        finishedAt: stepFinished,\n        durationMs: stepFinished - stepStarted,\n      });\n\n      if (step.carry) {\n        const carryBlock = [`### ${step.title}`, response].join(\"\\n\");\n        carry = appendCarry(carry, carryBlock, input.limits.maxCarryChars);\n      }\n    }\n\n    return {\n      workflowId: workflow.id,\n      workflowName: workflow.name,\n      startedAt,\n      finishedAt: Date.now(),\n      steps,\n    };\n  };\n\n  const start = async () => {\n    const enabled = config?.enabled !== false;\n    if (!enabled) return;\n    for (const wf of buildBuiltinWorkflows()) register(wf);\n  };\n\n  return {\n    register,\n    list,\n    get,\n    run,\n    start,\n    stop: async () => {\n      workflows.clear();\n    },\n    health: async () => ({ ok: true }),\n  };\n};\n"
  },
  {
    "path": "workflows/index.ts",
    "content": "import type { OrchestratorConfig } from \"../types\";\nimport { buildBuiltinWorkflows } from \"./builtins\";\nimport { registerWorkflow } from \"./engine\";\nimport { buildRooCodeBoomerangWorkflow } from \"./roocode-boomerang\";\n\nlet loaded = false;\n\nexport function loadWorkflows(config: OrchestratorConfig) {\n  if (loaded) return;\n  loaded = true;\n\n  if (config.workflows?.enabled === false) return;\n\n  const roocode = config.workflows?.roocodeBoomerang;\n  if (roocode?.enabled !== false) {\n    registerWorkflow(buildRooCodeBoomerangWorkflow(roocode?.steps));\n  }\n\n  for (const workflow of buildBuiltinWorkflows()) {\n    registerWorkflow(workflow);\n  }\n}\n"
  },
  {
    "path": "workflows/roocode-boomerang.ts",
    "content": "import type { WorkflowStepConfig } from \"../types\";\nimport type { WorkflowDefinition, WorkflowStepDefinition } from \"./types\";\n\nconst defaultSteps: WorkflowStepDefinition[] = [\n  {\n    id: \"plan\",\n    title: \"Plan\",\n    workerId: \"architect\",\n    prompt:\n      \"You are the architect. Create a concise plan for the task.\\n\\n\" +\n      \"Task:\\n{task}\\n\\n\" +\n      \"Return a numbered checklist with 3-6 steps.\",\n    carry: true, // Must carry to pass plan to implement step\n  },\n  {\n    id: \"implement\",\n    title: \"Implement\",\n    workerId: \"coder\",\n    prompt:\n      \"You are the coder. Implement the plan for the task.\\n\\n\" +\n      \"Task:\\n{task}\\n\\n\" +\n      \"Plan:\\n{carry}\\n\\n\" +\n      \"Return what you changed and any important notes.\",\n    carry: true,\n  },\n  {\n    id: \"review\",\n    title: \"Review\",\n    workerId: \"architect\",\n    prompt:\n      \"You are the reviewer. Check the implementation for correctness, edge cases, and missing tests.\\n\\n\" +\n      \"Task:\\n{task}\\n\\n\" +\n      \"Implementation:\\n{carry}\\n\\n\" +\n      \"Return issues and recommended fixes (or say 'no issues').\",\n    carry: true,\n  },\n  {\n    id: \"fix\",\n    title: \"Fix\",\n    workerId: \"coder\",\n    prompt:\n      \"Apply fixes based on the review. If no fixes are needed, say 'No changes needed' and restate the final output.\\n\\n\" +\n      \"Task:\\n{task}\\n\\n\" +\n      \"Review:\\n{carry}\",\n    carry: true,\n  },\n];\n\nfunction resolveStep(base: WorkflowStepDefinition | undefined, override: WorkflowStepConfig): WorkflowStepDefinition {\n  const prompt = override.prompt ?? base?.prompt ?? \"Task:\\n{task}\";\n  return {\n    id: override.id,\n    title: override.title ?? base?.title ?? override.id,\n    workerId: override.workerId ?? base?.workerId ?? \"coder\",\n    prompt,\n    carry: typeof override.carry === \"boolean\" ? override.carry : (base?.carry ?? true),\n  };\n}\n\nexport function buildRooCodeBoomerangWorkflow(overrides?: WorkflowStepConfig[]): WorkflowDefinition {\n  let steps = defaultSteps;\n  if (overrides && overrides.length > 0) {\n    const byId = new Map(defaultSteps.map((s) => [s.id, s]));\n    steps = overrides.map((s) => resolveStep(byId.get(s.id), s));\n  }\n\n  return {\n    id: \"roocode-boomerang\",\n    name: \"RooCode Boomerang\",\n    description: \"Plan, implement, review, and fix in a tight loop with bounded carry.\",\n    steps,\n  };\n}\n"
  },
  {
    "path": "workflows/types.ts",
    "content": "export type WorkflowAttachment = {\n  type: \"image\" | \"file\";\n  path?: string;\n  base64?: string;\n  mimeType?: string;\n};\n\nexport type WorkflowStepDefinition = {\n  id: string;\n  title: string;\n  workerId: string;\n  prompt: string;\n  carry?: boolean;\n};\n\nexport type WorkflowDefinition = {\n  id: string;\n  name: string;\n  description: string;\n  steps: WorkflowStepDefinition[];\n};\n\nexport type WorkflowSecurityLimits = {\n  maxSteps: number;\n  maxTaskChars: number;\n  maxCarryChars: number;\n  perStepTimeoutMs: number;\n};\n\nexport type WorkflowRunInput = {\n  workflowId: string;\n  task: string;\n  attachments?: WorkflowAttachment[];\n  autoSpawn?: boolean;\n  limits: WorkflowSecurityLimits;\n};\n\nexport type WorkflowStepResult = {\n  id: string;\n  title: string;\n  workerId: string;\n  status: \"success\" | \"error\";\n  response?: string;\n  error?: string;\n  startedAt: number;\n  finishedAt: number;\n  durationMs: number;\n};\n\nexport type WorkflowRunResult = {\n  workflowId: string;\n  workflowName: string;\n  startedAt: number;\n  finishedAt: number;\n  steps: WorkflowStepResult[];\n};\n"
  }
]
} as const

export type RepositoryFile = typeof RepositoryBundle.files[number]
export type RepositoryBundle = typeof RepositoryBundle

export const getAllFiles = () => RepositoryBundle.files
export const getFileByPath = (path: string) => 
  RepositoryBundle.files.find(f => f.path === path)
export const searchFiles = (pattern: RegExp) =>
  RepositoryBundle.files.filter(f => pattern.test(f.content))
export const getFilesByExtension = (ext: string) =>
  RepositoryBundle.files.filter(f => f.path.endsWith(ext))

